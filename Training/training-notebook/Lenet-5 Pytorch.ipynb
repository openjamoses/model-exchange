{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43553be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e39fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1eaab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a58bd738",
   "metadata": {},
   "outputs": [],
   "source": [
    "numb_batch = 128\n",
    "training_round = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "040902f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usagers3/opmos/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "T = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "train_data = torchvision.datasets.MNIST('mnist_data', train=True, download=True, transform=T)\n",
    "val_data = torchvision.datasets.MNIST('mnist_data', train=False, download=True, transform=T)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_data, batch_size = numb_batch)\n",
    "val_dl = torch.utils.data.DataLoader(val_data, batch_size = numb_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "095e7ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {'train': train_dl, 'val':val_dl}\n",
    "dataset_sizes = {'train': len(train_dl.dataset.data), 'val': len(val_dl.dataset.data) }\n",
    "class_names = train_dl.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d2bc891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lenet():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 6, 5, padding=2),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(2, stride=2),\n",
    "        nn.Conv2d(6, 16, 5, padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(400, 120),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(120, 84),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(84, 10)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8fb820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        images = images.cuda()\n",
    "        x = model(images)\n",
    "        value, pred = torch.max(x,1)\n",
    "        pred = pred.data.cpu()\n",
    "        total += x.size(0)\n",
    "        correct += torch.sum(pred == labels)\n",
    "    return correct*100./total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06cda65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(numb_epoch=3, lr=1e-3, device=\"cpu\"):\n",
    "    accuracies = []\n",
    "    cnn = create_lenet().to(device)\n",
    "    cec = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(cnn.parameters(), lr=lr)\n",
    "    max_accuracy = 0\n",
    "    \n",
    "    for epoch in range(numb_epoch):\n",
    "        for i, (images, labels) in enumerate(train_dl):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = cnn(images)\n",
    "            loss = cec(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        accuracy = float(validate(cnn, val_dl))\n",
    "        accuracies.append(accuracy)\n",
    "        if accuracy > max_accuracy:\n",
    "            best_model = copy.deepcopy(cnn)\n",
    "            max_accuracy = accuracy\n",
    "            print(\"Saving Best Model with Accuracy: \", accuracy)\n",
    "        print('Epoch:', epoch+1, \"Accuracy :\", accuracy, '%')\n",
    "    plt.plot(accuracies)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3933d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "date = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54faa2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    data_file = open('./data/26-10-2021/Train1/pytorch/lenet5/torch_{}_{}_{}.csv'.format(model_name, date, training_round), mode='w+', newline='', encoding='utf-8')\n",
    "    data_writer = csv.writer(data_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer.writerow(['Model','type', 'Dataset', 'Epoch', 'criterion', 'optimizer', 'scheduler','Train_loss', 'Train_acc', \"val_loss\", \"Val_acc\", 'time','Elapse_time','date'])\n",
    "\n",
    "    val_acc_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        since_1 = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        #data_writer.writerow(['Model','type', 'Dataset', 'Train_loss', 'Train_acc', \"val_loss\", \"Val_acc\"])\n",
    "        rows = [model, 'pytorch','mnist','{}/{}'.format(epoch, num_epochs - 1) ,criterion, optimizer, scheduler]\n",
    "        #for phase in ['train', 'val']:\n",
    "        #for i, data in enumerate(trainloader, 0):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            #for inputs, labels in dataloaders[phase]:\n",
    "            for i, data in enumerate(dataloaders[phase], 0):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                #inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                   # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        #print(criterion)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    #outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    #loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    #model.bad_variable_used_across_loop.detach() # detach it\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                #print(\"      ------\",i, running_loss, running_corrects)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            rows.append(phase)\n",
    "            rows.append('Loss: {:.4f}'.format(epoch_loss))\n",
    "            rows.append('Acc: {:.4f}'.format(epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        time_elapsed_1 = time.time() - since_1\n",
    "        print()\n",
    "        rows.append(time.time())\n",
    "        rows.append('{:.0f}m {:.0f}s'.format(time_elapsed_1 // 60, time_elapsed_1 % 60))\n",
    "        data_writer.writerow(rows)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    data_writer.writerow(['','', '', '', '', '', \"\", 'Best val Acc: {:4f}'.format(best_acc), time.time(),'Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60),''])\n",
    "\n",
    "    data_file.close()\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "590f7b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No Cuda Available\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f98f2c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.4565 Acc: 0.8418\n",
      "val Loss: 0.0945 Acc: 0.9701\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.0772 Acc: 0.9764\n",
      "val Loss: 0.0692 Acc: 0.9769\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.0570 Acc: 0.9829\n",
      "val Loss: 0.0593 Acc: 0.9817\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.0446 Acc: 0.9864\n",
      "val Loss: 0.0612 Acc: 0.9809\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.0358 Acc: 0.9892\n",
      "val Loss: 0.0559 Acc: 0.9848\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.0292 Acc: 0.9909\n",
      "val Loss: 0.0659 Acc: 0.9826\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.0254 Acc: 0.9920\n",
      "val Loss: 0.0561 Acc: 0.9856\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.0146 Acc: 0.9953\n",
      "val Loss: 0.0343 Acc: 0.9900\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.0100 Acc: 0.9971\n",
      "val Loss: 0.0340 Acc: 0.9905\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.0084 Acc: 0.9977\n",
      "val Loss: 0.0345 Acc: 0.9908\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.0073 Acc: 0.9980\n",
      "val Loss: 0.0351 Acc: 0.9907\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.0065 Acc: 0.9983\n",
      "val Loss: 0.0357 Acc: 0.9905\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.0059 Acc: 0.9985\n",
      "val Loss: 0.0364 Acc: 0.9905\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.0053 Acc: 0.9987\n",
      "val Loss: 0.0369 Acc: 0.9904\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.0046 Acc: 0.9987\n",
      "val Loss: 0.0369 Acc: 0.9898\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.0045 Acc: 0.9989\n",
      "val Loss: 0.0370 Acc: 0.9899\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.0044 Acc: 0.9989\n",
      "val Loss: 0.0371 Acc: 0.9899\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.0044 Acc: 0.9989\n",
      "val Loss: 0.0371 Acc: 0.9899\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.0043 Acc: 0.9989\n",
      "val Loss: 0.0372 Acc: 0.9898\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.0043 Acc: 0.9990\n",
      "val Loss: 0.0373 Acc: 0.9898\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.0042 Acc: 0.9990\n",
      "val Loss: 0.0373 Acc: 0.9898\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.0042 Acc: 0.9990\n",
      "val Loss: 0.0373 Acc: 0.9898\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.0042 Acc: 0.9990\n",
      "val Loss: 0.0373 Acc: 0.9898\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9990\n",
      "val Loss: 0.0373 Acc: 0.9898\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9990\n",
      "val Loss: 0.0373 Acc: 0.9898\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9990\n",
      "val Loss: 0.0373 Acc: 0.9898\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9990\n",
      "val Loss: 0.0373 Acc: 0.9898\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9990\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9991\n",
      "val Loss: 0.0374 Acc: 0.9898\n",
      "\n",
      "Training complete in 8m 47s\n",
      "Best val Acc: 0.990800\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "model = create_lenet().to(device)\n",
    "num_epochs = 50\n",
    "model_name = 'lenet5-mnist'\n",
    "#optimizer = optim.Adam(cnn.parameters(), lr=lr)\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=1e-1, momentum=0.9)      \n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model, dataloaders_dict, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25254b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, './data/26-10-2021/Train1/pytorch/lenet5/torch_{}_{}_{}.pth'.format(model_name, date, training_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83d7a204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Best Model with Accuracy:  93.08999633789062\n",
      "Epoch: 1 Accuracy : 93.08999633789062 %\n",
      "Saving Best Model with Accuracy:  96.81999969482422\n",
      "Epoch: 2 Accuracy : 96.81999969482422 %\n",
      "Saving Best Model with Accuracy:  97.66000366210938\n",
      "Epoch: 3 Accuracy : 97.66000366210938 %\n",
      "Saving Best Model with Accuracy:  98.12000274658203\n",
      "Epoch: 4 Accuracy : 98.12000274658203 %\n",
      "Saving Best Model with Accuracy:  98.29000091552734\n",
      "Epoch: 5 Accuracy : 98.29000091552734 %\n",
      "Saving Best Model with Accuracy:  98.4800033569336\n",
      "Epoch: 6 Accuracy : 98.4800033569336 %\n",
      "Saving Best Model with Accuracy:  98.58999633789062\n",
      "Epoch: 7 Accuracy : 98.58999633789062 %\n",
      "Epoch: 8 Accuracy : 98.5199966430664 %\n",
      "Epoch: 9 Accuracy : 98.58000183105469 %\n",
      "Epoch: 10 Accuracy : 98.47000122070312 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenet = train(10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efa308ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dl(model, data):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        images = images.cuda()\n",
    "        x = model(images)\n",
    "        value, pred = torch.max(x, 1)\n",
    "        pred = pred.data.cpu()\n",
    "        y_pred.extend(list(pred.numpy()))\n",
    "        y_true.extend(list(labels.numpy()))\n",
    "    return np.array(y_pred), np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cad3cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        images = images.cuda()\n",
    "        x = model(images)\n",
    "        value, pred = torch.max(x,1)\n",
    "        pred = pred.data.cpu()\n",
    "        total += x.size(0)\n",
    "        correct += torch.sum(pred == labels)\n",
    "    return correct*100./total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c94873c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred, y_true = predict_dl(model_ft, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9b0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
