{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 1.0.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:TensorFlow version 2.5.0 detected. Last version known to be fully compatible is 2.3.1 .\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from pathlib import Path\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import coremltools\n",
    "import time\n",
    "import tf2onnx\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 300)\n",
      "x_test shape: (25000, 300)\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 300 # 80 #\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = 'keras'\n",
    "model_short_name = 'lstm'\n",
    "\n",
    "onnx_path = '/Volumes/Cisco/Summer2022/onnx-exchange/Train2/conversion2/onnx/'\n",
    "coreml_path = '/Volumes/Cisco/Summer2022/onnx-exchange/Train2/conversion2/coremltools/'\n",
    "error_path = '/Volumes/Cisco/Summer2022/onnx-exchange/Train2/miss-classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_category(y):\n",
    "    list_ = []\n",
    "    for i in y:\n",
    "        if i < 0.5:\n",
    "            val = 0\n",
    "        else:\n",
    "            val = 1\n",
    "        list_.append(val)\n",
    "    return np.array(list_).astype(np.float32)\n",
    "def model_scores(y_test, test_predict):\n",
    "    return np.sum(y_test == test_predict)\n",
    "def get_miss_classification(y1, y2):\n",
    "    val = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(y1, y2)\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                val = int(value.split('(')[0].split('/')[0].replace(' ', ''))\n",
    "                #print(val)\n",
    "                #miss_perc_val_test_runtime = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                break\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onnx(x, y):\n",
    "    \n",
    "    # Input to the model\n",
    "    #device_reset = cuda.get_current_device()\n",
    "    #device_reset.reset()\n",
    "    #x.cuda()\n",
    "    #print(\"converting for batch: \", i)\n",
    "    #y = np.argmax(y)\n",
    "    #torch.random.manual_seed(42)\n",
    "    #x = torch.randn(10000, 3, 32, 32, requires_grad=True)\n",
    "    \n",
    "    ### Original Model\n",
    "    since_1 = time.time()\n",
    "    #model = torch.load(path+model_name+'.pth')\n",
    "    try:\n",
    "        with tf.device('/cpu:0'): \n",
    "            k_predict = model.predict(x)\n",
    "    except Exception as e:\n",
    "        print('Error keras: ')\n",
    "        return None\n",
    "    inference_time_original = time.time() - since_1\n",
    "    y0 = convert_category(k_predict)\n",
    "    #correct_original = np.sum(y0 == y)\n",
    "    print(k_predict)\n",
    "    print(y0, y)\n",
    "    accuracy_original = model_scores(y, y0)\n",
    "    miss_test_original = get_miss_classification(y, y0)\n",
    "    \n",
    "    print('accuracy_original: ',accuracy_original, miss_test_original)\n",
    "    # ONNX Model\n",
    "    \n",
    "    t_elapsed_2 = time.time() - since_1\n",
    "    #since_1 = time.time()\n",
    "    #onnx_model = onnx.load(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    #load_time_onnx = time.time() - since_1\n",
    "    #onnx.checker.check_model(onnx_model)\n",
    "    #def to_numpy(tensor):\n",
    "    #    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    #ort_session = onnxruntime.InferenceSession(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    since_1 = time.time()\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: x}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    inference_time_onnx = time.time() - since_1\n",
    "    # compare ONNX Runtime and PyTorch results\n",
    "    #print(\"\\n*********\\n\\n\")\n",
    "    #time_diff = t_elapsed_0+t_elapsed_1, t_elapsed_2, t_elapsed_3\n",
    "    \n",
    "    ####### Mis-classification ONNX ######################################\n",
    "    y2 = convert_category(ort_outs[0])\n",
    "    #correct_onnx = np.sum(y2 == y)\n",
    "    accuracy_onnx = model_scores(y, y2)\n",
    "    miss_original_onnx = get_miss_classification(y0, y2)\n",
    "    miss_test_onnx = get_miss_classification(y, y2)\n",
    "    \n",
    "    print('accuracy_onnx: ',accuracy_onnx, miss_original_onnx)\n",
    "    \n",
    "    abs_err = np.absolute(k_predict-ort_outs[0])\n",
    "    rel_err = np.absolute(k_predict-ort_outs[0])/ np.absolute(ort_outs[0])\n",
    "    ####### End of mis-classification ONNX ###################################### \n",
    "    \n",
    "    \n",
    "    ## CoreML\n",
    "    \n",
    "    #since_1 = time.time()\n",
    "    #coreml_model = coremltools.models.MLModel(coreml_path+framework+\"/{}/{}.mlmodel\".format(model_short_name, model_name))\n",
    "    #load_time_coreml = time.time() - since_1\n",
    "    \n",
    "    #spec = coreml_model.get_spec()\n",
    "    #coreml_model = coremltools.models.MLModel(spec)\n",
    "    split_ = str(coreml_model.get_spec().description.input[0]).split('\\n')\n",
    "    name_1 = split_[0].replace('name: \"', '')\n",
    "    name_1 = name_1.replace('\"', '')\n",
    "    \n",
    "    since_1 = time.time()\n",
    "    output_dict_test = coreml_model.predict({name_1:x})\n",
    "    inference_time_coreml = time.time() - since_1\n",
    "    ####### Mis-classification coreML ######################################\n",
    "    y3 = convert_category(output_dict_test['Identity'])\n",
    "    #correct_coreml = np.sum(y3 == y)\n",
    "    accuracy_coreml = model_scores(y, y3)\n",
    "    miss_original_coreml = get_miss_classification(y0, y3)\n",
    "    miss_test_coreml = get_miss_classification(y, y3)\n",
    "    print('accuracy_coreml: ',accuracy_onnx, miss_original_coreml)\n",
    "    \n",
    "    abs_err2 = np.absolute(k_predict-output_dict_test['Identity'])\n",
    "    rel_err2 = np.absolute(k_predict-output_dict_test['Identity'])/ np.absolute(output_dict_test['Identity'])\n",
    "        \n",
    "    ####### End of mis-classification coreML ######################################\n",
    "    #return correct_original,correct_onnx,correct_coreml \n",
    "    list_val = [accuracy_original, accuracy_onnx, accuracy_coreml, miss_original_onnx, miss_original_coreml,inference_time_original, inference_time_onnx, inference_time_coreml,abs_err, rel_err, abs_err2, rel_err2]\n",
    "    return list_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "def _lets_convert(x_test, y_test, data_writer_run):\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    #y_test = x_test.astype(np.float32)\n",
    "    list_val = to_onnx(x_test,y_test)\n",
    "    accuracy_original = list_val[0]\n",
    "    accuracy_onnx = list_val[1]\n",
    "    accuracy_coreml = list_val[2]\n",
    "\n",
    "    miss_original_onnx = list_val[3]\n",
    "    miss_original_coreml = list_val[4]\n",
    "\n",
    "    inference_time_original = list_val[5]\n",
    "    inference_time_onnx = list_val[6]\n",
    "    inference_time_coreml = list_val[7]\n",
    "    \n",
    "    mean_abs_onnx = np.mean(list_val[8])\n",
    "    mean_abs_coreml = np.mean(list_val[10])\n",
    "    mean_rel_onnx = np.mean(list_val[9])\n",
    "    mean_rel_coreml = np.mean(list_val[11])\n",
    "    std_abs_onnx = np.std(list_val[8])\n",
    "    std_abs_coreml = np.std(list_val[10])\n",
    "    std_rel_onnx = np.std(list_val[9])\n",
    "    std_rel_coreml = np.std(list_val[11])\n",
    "    \n",
    "    total_ = np.sum(y_test == y_test)\n",
    "    total_datasets = y_test.shape[0]\n",
    "    \n",
    "    \n",
    "    print(list_val, total_, total_datasets)\n",
    "        \n",
    "    #time_elapsed = time.time() - since\n",
    "    time_elapsed_overal_time = time.time() - since_orinal_0\n",
    "    print('Conversion complete in {:.0f}m {:.0f}s'.format(time_elapsed_overal_time // 60, time_elapsed_overal_time % 60) )\n",
    "    #print(correct_original, correct_onnx, correct_coreml, total, correct_original*100./total, precision2, recall2, f1)\n",
    "    #return correct_original*100./total, correct_onnx*100./total, correct_coreml*100./total\n",
    "    \n",
    "    data_writer_run.writerow([model_short_name,training_id,framework,model_size_original, model_size_onnx, model_size_coreml, t_elapsed_conversion_onnx, t_elapsed_conversion_coreml, t_elapsed_saving_time_coreml, t_elapsed_original, load_time_onnx, load_time_coreml, round(accuracy_original*100/total_,4), round(accuracy_onnx*100/total_,4), round(accuracy_coreml*100/total_,4), round(miss_original_onnx*100/total_datasets,2),  round(miss_original_coreml*100/total_datasets,2),mean_abs_onnx,mean_abs_coreml, mean_rel_onnx, mean_rel_coreml,std_abs_onnx,std_abs_coreml, std_rel_onnx, std_rel_coreml, inference_time_original/total_datasets, inference_time_onnx/total_datasets, inference_time_coreml/total_datasets, '', '{:.0f}m {:.0f}s'.format(time_elapsed_overal_time // 60, time_elapsed_overal_time % 60)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running TensorFlow Graph Passes: 100%|██████████| 5/5 [00:00<00:00, 10.75 passes/s]\n",
      "Converting Frontend ==> MIL Ops:   0%|          | 0/50 [00:00<?, ? ops/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 14/14 [00:00<00:00, 12152.37 ops/s]\n",
      "\n",
      "Converting Frontend ==> MIL Ops:   0%|          | 0/94 [00:00<?, ? ops/s]\u001b[AWARNING:root:Input ls elem type unknown. Override with <class 'coremltools.converters.mil.mil.types.type_tensor.tensor.<locals>.tensor'>\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 94/94 [00:00<00:00, 1636.06 ops/s]\n",
      "\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 14/14 [00:00<00:00, 3782.79 ops/s]\n",
      "\n",
      "Converting Frontend ==> MIL Ops:   0%|          | 0/94 [00:00<?, ? ops/s]\u001b[AWARNING:root:Input ls elem type unknown. Override with <class 'coremltools.converters.mil.mil.types.type_tensor.tensor.<locals>.tensor'>\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 94/94 [00:00<00:00, 1144.16 ops/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 50/50 [00:00<00:00, 183.41 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 566.18 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 323.98 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops:  15%|█▌        | 11/72 [00:00<00:03, 18.16 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 1/1 [00:00<00:00, 529.99 ops/s]\n",
      "\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 59/59 [00:00<00:00, 1172.47 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 72/72 [00:00<00:00, 102.59 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  0\n",
      "[[9.8360914e-01]\n",
      " [1.0000000e+00]\n",
      " [6.0989481e-05]\n",
      " ...\n",
      " [9.6239694e-07]\n",
      " [2.3447871e-03]\n",
      " [9.9999380e-01]]\n",
      "[1. 1. 0. ... 0. 0. 1.] [0 1 1 ... 0 0 0]\n",
      "accuracy_original:  21062 3938\n",
      "accuracy_onnx:  21062 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "if not os.path.exists(onnx_path+framework+\"/{}\".format(model_short_name)):\n",
    "            os.makedirs(onnx_path+framework+\"/{}\".format(model_short_name))\n",
    "if not os.path.exists(coreml_path+framework+\"/{}\".format(model_short_name)):\n",
    "    os.makedirs(coreml_path+framework+\"/{}\".format(model_short_name))\n",
    "if not os.path.exists(error_path+framework+\"/\"):\n",
    "    os.makedirs(error_path+framework+\"/\")\n",
    "model_short_name = 'lstm'\n",
    "framework = 'keras'\n",
    "\n",
    "training_id = 3\n",
    "\n",
    "for round_ in range(1):\n",
    "    path = '/Volumes/Cisco/Summer2022/onnx-exchange/Train2/Amin/{}/{}/'.format(framework, model_short_name)\n",
    "    since_0 = time.time()\n",
    "    #model_path = 'tf_Lenet5_mnist_2021-08-24-10:35:35'\n",
    "    #model_name = 'tf_alexnet_cifar10_2021-08-27-17:05:27'\n",
    "    #model_name = 'tf_resnet18-cifar10_2021-10-29_{}'.format(training_id)\n",
    "    model_name = 'keras-amin-lstm-3'\n",
    "    since_orinal_0 = time.time()\n",
    "    #model_name = 'tf_gru-imdb_2021-10-29_{}'.format(training_id)\n",
    "    model = tf.keras.models.load_model(path+ model_name+'.h5')\n",
    "    t_elapsed_original = time.time() - since_0\n",
    "    model_size_original = os.path.getsize(path+ model_name+'.h5')\n",
    "    #model_size_original\n",
    "\n",
    "    since_1 = time.time()\n",
    "    model_proto, external_tensor_storage = tf2onnx.convert.from_keras(model,\n",
    "                input_signature=None, opset=11, custom_ops=None,\n",
    "                custom_op_handlers=None, custom_rewriter=None,\n",
    "                inputs_as_nchw=None, extra_opset=None, shape_override=None,\n",
    "                 target=None, large_model=False, output_path=onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "\n",
    "    t_elapsed_conversion_onnx = time.time() - since_1\n",
    "\n",
    "\n",
    "    since_1 = time.time()\n",
    "    onnx_model = onnx.load(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    load_time_onnx = time.time() - since_1\n",
    "    model_size_onnx = os.path.getsize(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    ort_session = onnxruntime.InferenceSession(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "\n",
    "\n",
    "    since_1 = time.time()\n",
    "    coreml_model = coremltools.convert(model)\n",
    "    t_elapsed_conversion_coreml = time.time() - since_1\n",
    "    since_1 = time.time()\n",
    "    coreml_model.save(coreml_path+framework+'/{}/{}.mlmodel'.format(model_short_name, model_name))\n",
    "    t_elapsed_saving_time_coreml = time.time() - since_1\n",
    "\n",
    "    model_size_coreml = os.path.getsize(coreml_path+framework+'/{}/{}.mlmodel'.format(model_short_name, model_name))\n",
    "\n",
    "    since_1 = time.time()\n",
    "    coreml_model = coremltools.models.MLModel(coreml_path+framework+\"/{}/{}.mlmodel\".format(model_short_name, model_name))\n",
    "    load_time_coreml = time.time() - since_1\n",
    "\n",
    "    if not os.path.exists(error_path+framework):\n",
    "        Path(error_path+framework).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print('round: ', round_)\n",
    "    flag = 0\n",
    "    if not os.path.exists(error_path+framework+\"/runtime_accuracy_{}-v2.csv\".format(model_short_name)):\n",
    "        data_file_run = open(error_path+framework+\"/runtime_accuracy_{}-v2.csv\".format(model_short_name), mode='w', newline='', encoding='utf-8')\n",
    "    else:\n",
    "        data_file_run = open(error_path+framework+\"/runtime_accuracy_{}-v2.csv\".format(model_short_name), mode='a+', newline='', encoding='utf-8')\n",
    "        flag = 1\n",
    "    data_writer_run = csv.writer(data_file_run, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    if flag == 0: \n",
    "        data_writer_run.writerow(['model','training_id','framework','original_size', 'onnx_size', 'coreml_size','onnx_conversion_time', 'coreml_conversion_time', 'coreml_saving_time', 'original_load_time', 'onnx_load_time', 'coreml_load_time', 'accuracy_original', 'accuracy_onnx', 'accuracy_coreml', 'miss_original_onnx', 'miss_original_coreml','mean_abs_onnx','mean_abs_coreml', 'mean_rel_onnx', 'mean_rel_coreml','std_abs_onnx','std_abs_coreml', 'std_rel_onnx', 'std_rel_coreml', 'inference_time_original', 'inference_time_onnx', 'inference_time_coreml', '', 'overral_time'])\n",
    "    _lets_convert(x_test, y_test, data_writer_run)\n",
    "    data_file_run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_test == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/Cisco/Summer2022/onnx-exchange/Train2/Amin/{}/{}/'.format(framework, model_short_name)\n",
    "since_0 = time.time()\n",
    "#model_path = 'tf_Lenet5_mnist_2021-08-24-10:35:35'\n",
    "#model_name = 'tf_alexnet_cifar10_2021-08-27-17:05:27'\n",
    "#model_name = 'tf_resnet18-cifar10_2021-10-29_{}'.format(training_id)\n",
    "model_name = 'amin-lstm'\n",
    "since_orinal_0 = time.time()\n",
    "#model_name = 'tf_gru-imdb_2021-10-29_{}'.format(training_id)\n",
    "model = tf.keras.models.load_model(path+ model_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_predict = model.predict(x_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = convert_category(k_predict)\n",
    "#correct_original = np.sum(y0 == y)\n",
    "accuracy_original = model_scores(y_test.astype(np.float32), y0)\n",
    "miss_test_original = get_miss_classification(y_test, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.956"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_original*100/np.sum(y_test == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4511"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_test_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "since_1 = time.time()\n",
    "onnx_model = onnx.load(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "load_time_onnx = time.time() - since_1\n",
    "model_size_onnx = os.path.getsize(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "onnx.checker.check_model(onnx_model)\n",
    "ort_session = onnxruntime.InferenceSession(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: embedding_2_input for the following indices\n index: 1 Got: 80 Expected: 300\n Please fix either the inputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6889dc5ce899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mort_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mort_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mort_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mort_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mort_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: embedding_2_input for the following indices\n index: 1 Got: 80 Expected: 300\n Please fix either the inputs or the model."
     ]
    }
   ],
   "source": [
    "ort_inputs = {ort_session.get_inputs()[0].name: x_test.astype(np.float32)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
