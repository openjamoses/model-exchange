{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    # to load dataset\n",
    "import numpy as np     # for mathematic equation\n",
    "from nltk.corpus import stopwords   # to get collection of stopwords\n",
    "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
    "from tensorflow.keras.models import Sequential     # the model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
    "from tensorflow.keras.models import load_model   # load saved model\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv( '/Volumes/Cisco/Fall2021/onnx-exchange/Training/IMDB Dataset.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews\n",
      "0        [one, reviewers, mentioned, watching, oz, epis...\n",
      "1        [a, wonderful, little, production, the, filmin...\n",
      "2        [i, thought, wonderful, way, spend, time, hot,...\n",
      "3        [basically, family, little, boy, jake, thinks,...\n",
      "4        [petter, mattei, love, time, money, visually, ...\n",
      "                               ...                        \n",
      "49995    [i, thought, movie, right, good, job, it, crea...\n",
      "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
      "49997    [i, catholic, taught, parochial, elementary, s...\n",
      "49998    [i, going, disagree, previous, comment, side, ...\n",
      "49999    [no, one, expects, star, trek, movies, high, a...\n",
      "Name: review, Length: 50000, dtype: object \n",
      "\n",
      "Sentiment\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        0\n",
      "4        1\n",
      "        ..\n",
      "49995    1\n",
      "49996    0\n",
      "49997    0\n",
      "49998    0\n",
      "49999    0\n",
      "Name: sentiment, Length: 50000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv('/Volumes/Cisco/Fall2021/onnx-exchange/Training/IMDB Dataset.csv')\n",
    "    x_data = df['review']       # Reviews/Input\n",
    "    y_data = df['sentiment']    # Sentiment/Output\n",
    "\n",
    "    # PRE-PROCESS REVIEW\n",
    "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
    "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
    "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
    "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
    "    \n",
    "    # ENCODE SENTIMENT -> 0 & 1\n",
    "    y_data = y_data.replace('positive', 1)\n",
    "    y_data = y_data.replace('negative', 0)\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "x_data, y_data = load_dataset()\n",
    "\n",
    "print('Reviews')\n",
    "print(x_data, '\\n')\n",
    "print('Sentiment')\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "37952    [this, really, one, star, many, clich, predict...\n",
      "40832    [i, first, came, across, my, tutor, friend, ac...\n",
      "10019    [possible, spoilers, although, done, better, m...\n",
      "22387    [dr, paul, flanner, richard, gere, successful,...\n",
      "35059    [if, seen, eva, longoria, tv, show, desperate,...\n",
      "                               ...                        \n",
      "33442    [this, made, tv, film, brilliant, one, this, p...\n",
      "31510    [first, i, want, say, people, give, poor, revi...\n",
      "18804    [of, ten, actors, portrayed, philo, vance, ser...\n",
      "24603    [just, finished, watching, say, i, impressed, ...\n",
      "48668    [i, christian, thought, movie, pretty, good, w...\n",
      "Name: review, Length: 40000, dtype: object \n",
      "\n",
      "32324    [the, remarkable, fact, participation, klaus, ...\n",
      "7724     [very, cliched, quite, corny, acting, gets, wo...\n",
      "43791    [this, movie, groundbreaking, former, soviet, ...\n",
      "33659    [ok, lets, see, what, funny, first, movie, i, ...\n",
      "30726    [intense, fascinating, drama, similarities, to...\n",
      "                               ...                        \n",
      "25655    [once, upon, time, theresa, russell, made, hal...\n",
      "4069     [after, opening, credits, black, sheet, paper,...\n",
      "41214    [the, thing, calling, house, dead, worst, movi...\n",
      "41078    [six, degrees, hooked, i, looked, forward, com...\n",
      "44072    [review, nunsploitation, films, they, around, ...\n",
      "Name: review, Length: 10000, dtype: object \n",
      "\n",
      "Test Set\n",
      "37952    0\n",
      "40832    1\n",
      "10019    1\n",
      "22387    1\n",
      "35059    1\n",
      "        ..\n",
      "33442    1\n",
      "31510    1\n",
      "18804    0\n",
      "24603    0\n",
      "48668    1\n",
      "Name: sentiment, Length: 40000, dtype: int64 \n",
      "\n",
      "32324    0\n",
      "7724     0\n",
      "43791    1\n",
      "33659    0\n",
      "30726    1\n",
      "        ..\n",
      "25655    0\n",
      "4069     0\n",
      "41214    0\n",
      "41078    1\n",
      "44072    0\n",
      "Name: sentiment, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "\n",
    "print('Train Set')\n",
    "print(x_train, '\\n')\n",
    "print(x_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for review in x_train:\n",
    "        review_length.append(len(review))\n",
    "\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[    8    15     5 ...     0     0     0]\n",
      " [    1    23   290 ... 17217  1674    75]\n",
      " [  534   977   165 ...    25  1294 18832]\n",
      " ...\n",
      " [  274   640    67 ...     0     0     0]\n",
      " [  452  1790    65 ...     0     0     0]\n",
      " [    1  1421    95 ...     0     0     0]] \n",
      "\n",
      "Encoded X Test\n",
      " [[    2  1723   103 ...     0     0     0]\n",
      " [  809  7461    86 ...     0     0     0]\n",
      " [    8     3  6716 ...     0     0     0]\n",
      " ...\n",
      " [    2    66  2343 ...     0     0     0]\n",
      " [ 1324  7384  3143 ...     0     0     0]\n",
      " [  624 23498    35 ...  1568   331   746]] \n",
      "\n",
      "Maximum review length:  131\n"
     ]
    }
   ],
   "source": [
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "max_length = get_max_length()\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 1.0.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:TensorFlow version 2.5.0 detected. Last version known to be fully compatible is 2.3.1 .\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "import coremltools\n",
    "import time\n",
    "import tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/onnx/'\n",
    "coreml_path = '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/coremltools/'\n",
    "error_path = '/Volumes/Cisco/Fall2021/onnx-exchange/miss-classification/v2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_category(y):\n",
    "    \n",
    "    #list_ = []\n",
    "    #for i in y:\n",
    "    #    val = 1\n",
    "    #    if i < 0.5:\n",
    "    #        val = 0\n",
    "    #    list_.append(val)\n",
    "    return np.argmax(y) #np.array(list_)\n",
    "#convert_category(k_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scores(y_test, test_predict):\n",
    "    correct_ = 0 #y_test = test_predict #np.sum(y_test == test_predict)\n",
    "    if y_test == test_predict:\n",
    "        correct_ = 1\n",
    "    accuracy  = correct_#*100./np.sum(y_test == y_test)\n",
    "    return accuracy\n",
    "def get_miss_classification(y1, y2):\n",
    "    miss_perc_val_original_coreml = 0\n",
    "    if y1 != y2:\n",
    "        miss_perc_val_original_coreml = 1\n",
    "    return miss_perc_val_original_coreml #, precision2, recall2, f12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onnx(i, x, y, batch_size):\n",
    "    \n",
    "    # Input to the model\n",
    "    #device_reset = cuda.get_current_device()\n",
    "    #device_reset.reset()\n",
    "    #x.cuda()\n",
    "    #print(\"converting for batch: \", i)\n",
    "    y = np.argmax(y)\n",
    "    #torch.random.manual_seed(42)\n",
    "    #x = torch.randn(10000, 3, 32, 32, requires_grad=True)\n",
    "    \n",
    "    ### Original Model\n",
    "    since_1 = time.time()\n",
    "    #model = torch.load(path+model_name+'.pth')\n",
    "    try:\n",
    "        with tf.device('/cpu:0'): \n",
    "            k_predict = model.predict(x)\n",
    "    except Exception as e:\n",
    "        print('Error keras: ')\n",
    "        return None\n",
    "    inference_time_original = time.time() - since_1\n",
    "    y0 = convert_category(k_predict)\n",
    "    correct_original = np.sum(y0 == y)\n",
    "    accuracy_original = model_scores(y, y0)\n",
    "    miss_test_original = get_miss_classification(y, y0)\n",
    "    # ONNX Model\n",
    "    \n",
    "    t_elapsed_2 = time.time() - since_1\n",
    "    #since_1 = time.time()\n",
    "    #onnx_model = onnx.load(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    #load_time_onnx = time.time() - since_1\n",
    "    #onnx.checker.check_model(onnx_model)\n",
    "    #def to_numpy(tensor):\n",
    "    #    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    #ort_session = onnxruntime.InferenceSession(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    since_1 = time.time()\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: x}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    inference_time_onnx = time.time() - since_1\n",
    "    # compare ONNX Runtime and PyTorch results\n",
    "    #print(\"\\n*********\\n\\n\")\n",
    "    #time_diff = t_elapsed_0+t_elapsed_1, t_elapsed_2, t_elapsed_3\n",
    "    \n",
    "    ####### Mis-classification ONNX ######################################\n",
    "    y2 = convert_category(ort_outs[0])\n",
    "    correct_onnx = np.sum(y2 == y)\n",
    "    accuracy_onnx = model_scores(y, y2)\n",
    "    miss_original_onnx = get_miss_classification(y0, y2)\n",
    "    miss_test_onnx = get_miss_classification(y, y2)\n",
    "    ####### End of mis-classification ONNX ###################################### \n",
    "    \n",
    "    \n",
    "    ## CoreML\n",
    "    \n",
    "    #since_1 = time.time()\n",
    "    #coreml_model = coremltools.models.MLModel(coreml_path+framework+\"/{}/{}.mlmodel\".format(model_short_name, model_name))\n",
    "    #load_time_coreml = time.time() - since_1\n",
    "    \n",
    "    #spec = coreml_model.get_spec()\n",
    "    #coreml_model = coremltools.models.MLModel(spec)\n",
    "    split_ = str(coreml_model.get_spec().description.input[0]).split('\\n')\n",
    "    name_1 = split_[0].replace('name: \"', '')\n",
    "    name_1 = name_1.replace('\"', '')\n",
    "    \n",
    "    since_1 = time.time()\n",
    "    output_dict_test = coreml_model.predict({name_1:x})\n",
    "    inference_time_coreml = time.time() - since_1\n",
    "    ####### Mis-classification coreML ######################################\n",
    "    y3 = convert_category(output_dict_test['Identity'])\n",
    "    correct_coreml = np.sum(y3 == y)\n",
    "    accuracy_coreml = model_scores(y, y3)\n",
    "    miss_original_coreml = get_miss_classification(y0, y3)\n",
    "    miss_test_coreml = get_miss_classification(y, y3)\n",
    "    \n",
    "    ####### End of mis-classification coreML ######################################\n",
    "    #return correct_original,correct_onnx,correct_coreml \n",
    "    list_val = [accuracy_original, accuracy_onnx, accuracy_coreml, miss_original_onnx, miss_original_coreml,inference_time_original, inference_time_onnx, inference_time_coreml]\n",
    "    return list_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "def _lets_convert(data, data_writer_run, batch_size):\n",
    "    since = time.time()\n",
    "    accuracy_original = 0.0\n",
    "    accuracy_onnx = 0.0\n",
    "    accuracy_coreml = 0.0\n",
    "    #miss_test_original = 0\n",
    "    miss_original_onnx = 0\n",
    "    #miss_test_onnx = 0\n",
    "    miss_original_coreml = 0\n",
    "    #miss_test_coreml = 0\n",
    "    \n",
    "    inference_time_original = 0.0\n",
    "    inference_time_onnx = 0.0\n",
    "    inference_time_coreml = 0.0\n",
    "    \n",
    "    total_ = 0.0\n",
    "    total_datasets = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(data):\n",
    "        inputs = to_numpy(inputs)\n",
    "        labels = to_numpy(labels)\n",
    "        list_val = to_onnx(i, inputs,labels, batch_size)\n",
    "        if i%50 == 0:\n",
    "            print(i, list_val)\n",
    "        if list_val != None:\n",
    "            accuracy_original += list_val[0]\n",
    "            accuracy_onnx += list_val[1]\n",
    "            accuracy_coreml += list_val[2]\n",
    "\n",
    "            miss_original_onnx += list_val[3]\n",
    "            miss_original_coreml += list_val[4]\n",
    "\n",
    "            inference_time_original += list_val[5]\n",
    "            inference_time_onnx += list_val[6]\n",
    "            inference_time_coreml += list_val[7]\n",
    "            total_ += np.sum(labels == labels)\n",
    "            total_datasets += labels.shape[0]\n",
    "        if i == 1000:\n",
    "            break\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Conversion complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60) )\n",
    "    #print(correct_original, correct_onnx, correct_coreml, total, correct_original*100./total, precision2, recall2, f1)\n",
    "    #return correct_original*100./total, correct_onnx*100./total, correct_coreml*100./total\n",
    "    data_writer_run.writerow([model_short_name,framework, training_id, model_name, round(accuracy_original*100/total_,2), round(accuracy_onnx*100/total_,2), round(accuracy_coreml*100/total_,2),  round(miss_original_onnx*100/total_datasets,2),  round(miss_original_coreml*100/total_datasets,2),'', inference_time_original/total_datasets, inference_time_onnx/total_datasets, inference_time_coreml/total_datasets, '',\n",
    "                              '{:.0f}m {:.0f}s'.format((inference_time_original/total_datasets) // 60, (inference_time_original/total_datasets) % 60),\n",
    "                              '{:.0f}m {:.0f}s'.format((inference_time_onnx/total_datasets) // 60, (inference_time_onnx/total_datasets) % 60),\n",
    "                              '{:.0f}m {:.0f}s'.format((inference_time_coreml/total_datasets) // 60, (inference_time_coreml/total_datasets) % 60),\n",
    "                              '{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  3\n",
      "0 [1, 1, 1, 0, 0, 4.074235916137695, 0.05910301208496094, 0.09341907501220703]\n",
      "50 [1, 1, 1, 0, 0, 0.0867609977722168, 0.03722810745239258, 0.03632187843322754]\n",
      "100 [1, 1, 1, 0, 0, 0.09136605262756348, 0.039283037185668945, 0.02864694595336914]\n",
      "150 [1, 1, 1, 0, 0, 3.508718967437744, 0.03668403625488281, 0.028325796127319336]\n",
      "200 [1, 1, 1, 0, 0, 0.09247303009033203, 0.03982210159301758, 0.04764389991760254]\n",
      "250 [1, 1, 1, 0, 0, 0.11222195625305176, 0.04260897636413574, 0.031039953231811523]\n",
      "300 [1, 1, 1, 0, 0, 0.11060190200805664, 0.04209113121032715, 0.029939889907836914]\n",
      "350 [1, 1, 1, 0, 0, 0.09514307975769043, 0.03307294845581055, 0.025784015655517578]\n",
      "400 [1, 1, 1, 0, 0, 0.08807182312011719, 0.039130210876464844, 0.02730584144592285]\n",
      "450 [1, 1, 1, 0, 0, 0.10570788383483887, 0.04256296157836914, 0.032002925872802734]\n",
      "500 [1, 1, 1, 0, 0, 0.08911609649658203, 0.04902911186218262, 0.039801836013793945]\n",
      "550 [1, 1, 1, 0, 0, 0.08852505683898926, 0.03406524658203125, 0.02770400047302246]\n",
      "600 [1, 1, 1, 0, 0, 0.10892486572265625, 0.04071998596191406, 0.024611711502075195]\n",
      "650 [1, 1, 1, 0, 0, 0.08937597274780273, 0.04353976249694824, 0.027866840362548828]\n",
      "Error keras: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c80a1d9b581d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m#train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0m_lets_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_writer_run2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mdata_file_run2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-eaf0869ff06f>\u001b[0m in \u001b[0;36m_lets_convert\u001b[0;34m(data, data_writer_run, batch_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mlist_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-f018fc5a9805>\u001b[0m in \u001b[0;36mto_onnx\u001b[0;34m(i, x, y, batch_size)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m#spec = coreml_model.get_spec()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m#coreml_model = coremltools.models.MLModel(spec)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0msplit_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoreml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mname_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name: \"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mname_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/models/model.py\u001b[0m in \u001b[0;36mget_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \"\"\"\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_deepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museCPUOnly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "#data_file_run = open(error_path+framework+\"/{}/runtime_miss-classification_{}.csv\".format(model_short_name,model_name), mode='w', newline='',\n",
    "#                                  encoding='utf-8')\n",
    "#data_writer_run = csv.writer(data_file_run, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#data_writer_run.writerow(['model','framework', 'training_id', 'model_full', \"batch_size\", 'round','runtime','original_load_time', 'original_infererence_time', 'runtime_load_time', \n",
    "#                          'runtime_inference_time',  'miss_classified_original_runtime_percentage','',  'encoded_miss_classified_original_runtime_percentage','encoded_miss_classified_original_test_runtime_percentage', '', 'accuracy_original', 'accuracy_runtime'])\n",
    "\n",
    "for round_ in [3,4,5,6,7,8,9,10]: #,3,4,5,6,7,8,9,10\n",
    "    training_id = round_\n",
    "    model_short_name = 'lstm'\n",
    "    framework = 'keras'\n",
    "    path = '/Volumes/Cisco/Fall2021/onnx-exchange/Training/{}/{}/'.format(framework, model_short_name)\n",
    "    since_0 = time.time()\n",
    "    #model_path = 'tf_Lenet5_mnist_2021-08-24-10:35:35'\n",
    "    #model_name = 'tf_alexnet_cifar10_2021-08-27-17:05:27'\n",
    "    #model_name = 'tf_resnet18-cifar10_2021-10-29_{}'.format(training_id)\n",
    "    model_name = 'tf_lstm-imdb_2021-10-30_{}'.format(training_id)\n",
    "    #model_name = 'tf_gru-imdb_2021-10-29_{}'.format(training_id)\n",
    "    model = tf.keras.models.load_model(path+ model_name+'.h5')\n",
    "    t_elapsed_0 = time.time() - since_0\n",
    "    size0 = os.path.getsize(path+ model_name+'.h5')\n",
    "    size0\n",
    "    \n",
    "    since_1 = time.time()\n",
    "    onnx_model = onnx.load(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    load_time_onnx = time.time() - since_1\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    ort_session = onnxruntime.InferenceSession(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    \n",
    "    \n",
    "    since_1 = time.time()\n",
    "    coreml_model = coremltools.models.MLModel(coreml_path+framework+\"/{}/{}.mlmodel\".format(model_short_name, model_name))\n",
    "    load_time_coreml = time.time() - since_1\n",
    "    \n",
    "    if not os.path.exists(error_path+framework):\n",
    "        Path(error_path+framework).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print('round: ', round_)\n",
    "    flag = 0\n",
    "    if not os.path.exists(error_path+framework+\"/runtime_accuracy_{}.csv\".format(model_short_name)):\n",
    "        data_file_run2 = open(error_path+framework+\"/runtime_accuracy_{}.csv\".format(model_short_name), mode='w', newline='', encoding='utf-8')\n",
    "    else:\n",
    "        data_file_run2 = open(error_path+framework+\"/runtime_accuracy_{}.csv\".format(model_short_name), mode='a+', newline='', encoding='utf-8')\n",
    "        flag = 1\n",
    "    data_writer_run2 = csv.writer(data_file_run2, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    if flag == 0: \n",
    "        data_writer_run2.writerow(['model','framework', 'training_id', 'model_full', 'accuracy_original', 'accuracy_onnx', 'accuracy_coreml', 'miss_original_onnx', 'miss_original_coreml','', 'inference_time_original', 'inference_time_onnx', 'inference_time_coreml', '', 'inference_time_original2', 'inference_time_onnx2', 'inference_time_coreml2', 'overral_time'])\n",
    "        \n",
    "    #train_data = TensorDataset(torch.as_tensor(np.array(x_train).astype('int32')), torch.as_tensor(np.array(y_train).astype('int32')))\n",
    "    valid_data = TensorDataset(torch.as_tensor(np.array(x_test).astype('int32')), torch.as_tensor(np.array(y_test).astype('int32')))\n",
    "\n",
    "    # dataloaders\n",
    "    batch_size = 1 \n",
    "\n",
    "    # make sure to SHUFFLE your data\n",
    "    #train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "    valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "    _lets_convert(valid_loader, data_writer_run2, batch_size)\n",
    "    data_file_run2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_id = 4\n",
    "model_short_name = 'lstm'\n",
    "framework = 'keras'\n",
    "path = '/Volumes/Cisco/Fall2021/onnx-exchange/Training/{}/{}/'.format(framework, model_short_name)\n",
    "since_0 = time.time()\n",
    "#model_path = 'tf_Lenet5_mnist_2021-08-24-10:35:35'\n",
    "#model_name = 'tf_alexnet_cifar10_2021-08-27-17:05:27'\n",
    "#model_name = 'tf_resnet18-cifar10_2021-10-29_{}'.format(training_id)\n",
    "model_name = 'tf_lstm-imdb_2021-10-30_{}'.format(training_id)\n",
    "#model_name = 'tf_gru-imdb_2021-10-29_{}'.format(training_id)\n",
    "model = tf.keras.models.load_model(path+ model_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32334384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Volumes/Cisco/Summer2022/onnx-exchange/Train2/trial/keras/lstm/'\n",
    "since_0 = time.time()\n",
    "#model_path = 'tf_Lenet5_mnist_2021-08-24-10:35:35'\n",
    "#model_name = 'tf_alexnet_cifar10_2021-08-27-17:05:27'\n",
    "#model_name = 'tf_resnet18-cifar10_2021-10-29_{}'.format(training_id)\n",
    "model_name = 'amin-lstm'\n",
    "#model_name = 'tf_gru-imdb_2021-10-29_{}'.format(training_id)\n",
    "model = tf.keras.models.load_model(path+ model_name+'.h5')\n",
    "t_elapsed_0 = time.time() - since_0\n",
    "size0 = os.path.getsize(path+ model_name+'.h5')\n",
    "size0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "valid_data = TensorDataset(torch.as_tensor(np.array(x_test).astype('int32')), torch.as_tensor(np.array(y_test).astype('int32')))\n",
    "\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "max_features = 20000\n",
    "maxlen = 80\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.34\n"
     ]
    }
   ],
   "source": [
    "#model = tf.keras.models.load_model(path+ model_name+'.h5')\n",
    "total_ = 0\n",
    "accuracy_original = 0\n",
    "k_predict = model.predict(x_test)\n",
    "\n",
    "k_predict_list = []\n",
    "for val in k_predict:\n",
    "    if val < 0.5:\n",
    "        k_predict_list.append(0)\n",
    "    else:\n",
    "        k_predict_list.append(1)\n",
    "k_predict_list = np.array(k_predict_list)\n",
    "correct = np.sum(y_test == k_predict_list)\n",
    "total_ = np.sum(y_test == y_test)\n",
    "print(round(correct*100/total_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.96\n"
     ]
    }
   ],
   "source": [
    "correct = np.sum(y_test == k_predict_list)\n",
    "total_ = np.sum(y_test == y_test)\n",
    "print(round(correct*100/total_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-71cb5b73789a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#y0 = convert_category(k_predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy_original\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_predict_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtotal_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_original\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-69bb56b5e019>\u001b[0m in \u001b[0;36mmodel_scores\u001b[0;34m(y_test, test_predict)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcorrect_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#y_test = test_predict #np.sum(y_test == test_predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mcorrect_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maccuracy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcorrect_\u001b[0m\u001b[0;31m#*100./np.sum(y_test == y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "#y0 = convert_category(k_predict)\n",
    "accuracy_original += model_scores(y_test, k_predict_list)\n",
    "total_ += np.sum(y_test == y_test)\n",
    "    \n",
    "print(round(accuracy_original*100/total_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nArrays are not equal\n\nMismatched elements: 12415 / 25000 (49.7%)\nMax absolute difference: 1\nMax relative difference: 1.\n x: array([0, 1, 1, ..., 0, 0, 0])\n y: array([1, 1, 1, ..., 1, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-688c4eb7ba23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_array_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_predict_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_equal\u001b[0;34m(x, y, err_msg, verbose)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Hide traceback for py.test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n\u001b[0;32m--> 931\u001b[0;31m                          verbose=verbose, header='Arrays are not equal')\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    838\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not equal\n\nMismatched elements: 12415 / 25000 (49.7%)\nMax absolute difference: 1\nMax relative difference: 1.\n x: array([0, 1, 1, ..., 0, 0, 0])\n y: array([1, 1, 1, ..., 1, 1, 1])"
     ]
    }
   ],
   "source": [
    "np.testing.assert_array_equal(y_test, k_predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12415\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    np.testing.assert_array_equal(y_test, k_predict_list)\n",
    "except Exception as e:\n",
    "    #print(e)\n",
    "    for line_ in str(e).split('\\n'):\n",
    "        #print(' ---- : ', line_)\n",
    "        if 'Mismatched elements' in line_:\n",
    "            value = line_.replace('Mismatched elements: ', '').strip()\n",
    "            val = value.split('(')[0].split('/')[0].replace(' ', '')\n",
    "            print(val)\n",
    "            #miss_perc_val_test_runtime = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "            #print(value, perc_val)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
