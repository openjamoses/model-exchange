{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "import tf2onnx\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (60000, 28, 28, 1)\n",
      "60000 training samples\n",
      "10000 test samples\n",
      "One-hot encoding: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 500 # Number of images processed at once\n",
    "nb_classes = 10  # 10 Digits from 0 to 9\n",
    "\n",
    "# Dimensionen of the input images (28x28 pixel)\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# Load image data with labels, split into test and training set \n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# reshape images in 4D tensor (N images, 28 rows, 28 columns, 1 channel) \n",
    "# rescale pixels range from [0, 255] to [0, 1]\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print(X_train.shape[0], \"training samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert digit labels (0-9) in one-hot encoded binary vectors. \n",
    "# These correspond to the training/test labels at the output of the net. \n",
    "Y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "print(\"One-hot encoding: {}\".format(Y_train[0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() ## for Lenet5\n",
    "#(x_train, y_train), (x_test, y_test) = K.datasets.cifar10.load_data() ## the res apart from LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.compat.v2.keras.utils.Sequence):\n",
    " \n",
    "    def __init__(self, X_data , y_data, batch_size, dim, n_classes,\n",
    "                 to_fit, shuffle = True):\n",
    "        self.batch_size = batch_size\n",
    "        self.X_data = X_data\n",
    "        self.labels = y_data\n",
    "        self.y_data = y_data\n",
    "        self.to_fit = to_fit\n",
    "        self.n_classes = n_classes\n",
    "        self.dim = dim\n",
    "        self.shuffle = shuffle\n",
    "        self.n = 0\n",
    "        self.list_IDs = np.arange(len(self.X_data))\n",
    "        self.on_epoch_end()\n",
    "    def __next__(self):\n",
    "        # Get one batch of data\n",
    "        data = self.__getitem__(self.n)\n",
    "        # Batch index\n",
    "        self.n += 1\n",
    "        \n",
    "        # If we have processed the entire dataset then\n",
    "        if self.n >= self.__len__():\n",
    "            self.on_epoch_end\n",
    "            self.n = 0\n",
    "        \n",
    "        return data\n",
    "    def __len__(self):\n",
    "        # Return the number of batches of the dataset\n",
    "        return math.ceil(len(self.indexes)/self.batch_size)\n",
    "    def __getitem__(self, index):\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:\n",
    "            (index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        X = self._generate_x(list_IDs_temp)\n",
    "        \n",
    "        if self.to_fit:\n",
    "            y = self._generate_y(list_IDs_temp)\n",
    "            return X, y\n",
    "        else:\n",
    "            return X\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        self.indexes = np.arange(len(self.X_data))\n",
    "        \n",
    "        if self.shuffle: \n",
    "            np.random.shuffle(self.indexes)\n",
    "    def _generate_x(self, list_IDs_temp):\n",
    "               \n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "            X[i,] = self.X_data[ID]\n",
    "            \n",
    "            # Normalize data\n",
    "            X = (X/255).astype('float32')\n",
    "            \n",
    "        return X[:,:,:, np.newaxis]\n",
    "    def _generate_y(self, list_IDs_temp):\n",
    "        \n",
    "        y = np.empty(self.batch_size)\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "            y[i] = self.y_data[ID]\n",
    "            \n",
    "        return keras.utils.to_categorical(y,num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "nb_classes = 10\n",
    "input_shape = (28, 28) #Lenet5\n",
    "#batch_size = 500 # Lenet\n",
    "batch_size = 500 # Lenet\n",
    "input_shape = (28, 28) #Lenet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = K.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=tf.data.Dataset.from_tensor_slices((train_images,train_labels))\n",
    "test_ds=tf.data.Dataset.from_tensor_slices((test_images,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image,label):\n",
    "    image=tf.image.per_image_standardization(image)\n",
    "    image=tf.image.resize(image,(64,64))\n",
    "    \n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 50000\n",
      "Test size: 10000\n"
     ]
    }
   ],
   "source": [
    "train_ds_size=tf.data.experimental.cardinality(train_ds).numpy()\n",
    "test_ds_size=tf.data.experimental.cardinality(test_ds).numpy()\n",
    "print('Train size:',train_ds_size)\n",
    "print('Test size:',test_ds_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=(train_ds\n",
    "          .map(process_image)\n",
    "          .shuffle(buffer_size=train_ds_size)\n",
    "          .batch(batch_size=batch_size,drop_remainder=True))\n",
    "test_ds=(test_ds\n",
    "          .map(process_image)\n",
    "          .shuffle(buffer_size=test_ds_size)\n",
    "          .batch(batch_size=batch_size,drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (500, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "for i, (images, labels) in enumerate(test_ds):\n",
    "    print (i, images.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((50000, 32, 32, 3), (50000, 10))\n",
      "((10000, 32, 32, 3), (10000, 10))\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 64, 64\n",
    "(x_train, y_train), (x_test, y_test) = K.datasets.cifar10.load_data()\n",
    "#x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32') \n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(x_test)\n",
    "\n",
    "\n",
    "print((x_train.shape,y_train.shape))\n",
    "#print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(x_train, y_train, batch_size = batch_size,\n",
    "                                dim = input_shape,\n",
    "                                n_classes=nb_classes, \n",
    "                                to_fit=True, shuffle=True)\n",
    "val_generator =  DataGenerator(x_test, y_test, batch_size=batch_size, \n",
    "                               dim = input_shape, \n",
    "                               n_classes= nb_classes, \n",
    "                               to_fit=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/23-08-2021/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601872"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "since_0 = time.time()\n",
    "#model_path = 'tf_Lenet5_mnist_2021-08-24-10:35:35'\n",
    "#model_name = 'tf_alexnet_cifar10_2021-08-27-17:05:27'\n",
    "model_name = 'tf_Lenet5_mnist_2021-08-24-10:35:35'\n",
    "model = tf.keras.models.load_model(path+ model_name+'.h5')\n",
    "t_elapsed_0 = time.time() - since_0\n",
    "size0 = os.path.getsize(path+ model_name+'.h5')\n",
    "size0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601872"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size1 = os.path.getsize(path+ model_name+'.h5')\n",
    "size1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size2 = os.stat(path+ model_name+'.h5').st_size\n",
    "#size2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onnx(i, x, abs_errors,rel_errors, t0_list, t1_list, t2_list, t3_list, s_list):\n",
    "    # Input to the model\n",
    "    #device_reset = cuda.get_current_device()\n",
    "    #device_reset.reset()\n",
    "    #x.cuda()\n",
    "   \n",
    "    print(\"converting for batch: \", i)\n",
    "    \n",
    "    #torch.random.manual_seed(42)\n",
    "    #x = torch.randn(10000, 3, 32, 32, requires_grad=True)\n",
    "    since_1 = time.time()\n",
    "    #model = torch.load(path+model_name+'.pth')\n",
    "    with tf.device('/cpu:0'): \n",
    "        k_predict = model.predict(x)\n",
    "    t_elapsed_1 = time.time() - since_1\n",
    "    # Export the model\n",
    "    since_1 = time.time()\n",
    "    model_proto, external_tensor_storage = tf2onnx.convert.from_keras(model,\n",
    "                input_signature=None, opset=11, custom_ops=None,\n",
    "                custom_op_handlers=None, custom_rewriter=None,\n",
    "                inputs_as_nchw=None, extra_opset=None, shape_override=None,\n",
    "                 target=None, large_model=False, output_path='./data/ONNX/keras/keras-{}.onnx'.format(model_name))\n",
    "    t_elapsed_2 = time.time() - since_1\n",
    "    \n",
    "    \n",
    "    onnx_model = onnx.load(\"./data/ONNX/keras/keras-{}.onnx\".format(model_name))\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    size2 = os.path.getsize(\"./data/ONNX/keras/keras-{}.onnx\".format(model_name))\n",
    "    s_list.append(size2)\n",
    "    #def to_numpy(tensor):\n",
    "    #    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    ort_session = onnxruntime.InferenceSession(\"./data/ONNX/keras/keras-{}.onnx\".format(model_name))\n",
    "    since_1 = time.time()\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: x}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    t_elapsed_3 = time.time() - since_1\n",
    "    # compare ONNX Runtime and PyTorch results\n",
    "    print(\"\\n*********\\n\\n\")\n",
    "    #time_diff = t_elapsed_0+t_elapsed_1, t_elapsed_2, t_elapsed_3\n",
    "    t0_list.append(t_elapsed_0)\n",
    "    t1_list.append(t_elapsed_1)\n",
    "    t2_list.append(t_elapsed_2)\n",
    "    t3_list.append(t_elapsed_3)\n",
    "    \n",
    "    abs_err = np.absolute(k_predict-ort_outs[0])\n",
    "    rel_err = np.absolute(k_predict-ort_outs[0])/ np.absolute(ort_outs[0])\n",
    "    abs_errors.append(abs_err)\n",
    "    rel_errors.append(rel_err)\n",
    "    \n",
    "    return (abs_err, rel_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lets_convert2(data, x, y, batch_size): # for cifar10 etc\n",
    "    since = time.time()\n",
    "    list_converted = []\n",
    "    t0_list = []\n",
    "    t1_list = []\n",
    "    t2_list = []\n",
    "    t3_list = []\n",
    "    s_list = []\n",
    "    abs_errors = []\n",
    "    rel_errors = []\n",
    "    \n",
    "    batches = 0\n",
    "    for x_batch, y_batch in data.flow(x, y, batch_size=batch_size):\n",
    "        list_converted.append(to_onnx(batches, x_batch, abs_errors,rel_errors, t0_list, t1_list, t2_list, t3_list, s_list))\n",
    "        batches += 1\n",
    "        if batches >= len(x_train) / batch_size:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "        if batches == 10:\n",
    "            break\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Conversion complete in {:.0f}m {:.0f}s,  Loading Pytorch: {}, Pytorch time: {:.4f}, conversion time: {:.4f}, onnx runtime: {:.4f}, onnx filesize: {}'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60, np.mean(np.array(t0_list)), np.mean(np.array(t1_list)), np.mean(np.array(t2_list)), np.mean(np.array(t3_list)), np.mean(np.array(s_list))) )\n",
    "    \n",
    "    #return list_converted\n",
    "    return list_converted, abs_errors, rel_errors, 'Conversion complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60), np.mean(np.array(t0_list)), np.mean(np.array(t1_list)), np.mean(np.array(t2_list)), np.mean(np.array(t3_list)), np.mean(np.array(s_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lets_convert(data):\n",
    "    since = time.time()\n",
    "    list_converted = []\n",
    "    t0_list = []\n",
    "    t1_list = []\n",
    "    t2_list = []\n",
    "    t3_list = []\n",
    "    s_list = []\n",
    "    abs_errors = []\n",
    "    rel_errors = []\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        #torch.cuda.empty_cache()\n",
    "        #images = images.cuda()\n",
    "        list_converted.append(to_onnx(i, images,abs_errors,rel_errors, t0_list, t1_list, t2_list, t3_list, s_list))\n",
    "        if i == 10:\n",
    "            break\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Conversion complete in {:.0f}m {:.0f}s,  Loading Pytorch: {}, Pytorch time: {:.4f}, conversion time: {:.4f}, onnx runtime: {:.4f}, onnx filesize: {}'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60, np.mean(np.array(t0_list)), np.mean(np.array(t1_list)), np.mean(np.array(t2_list)), np.mean(np.array(t3_list)), np.mean(np.array(s_list))) )\n",
    "    \n",
    "    #return list_converted\n",
    "    return list_converted, abs_errors, rel_errors, 'Conversion complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60), np.mean(np.array(t0_list)), np.mean(np.array(t1_list)), np.mean(np.array(t2_list)), np.mean(np.array(t3_list)), np.mean(np.array(s_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ Batch size:  1\n",
      "converting for batch:  0\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:424 call\n        return self._run_internal_graph(\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/layers/pooling.py:295 call\n        outputs = self.pool_function(\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py:4606 max_pool\n        return gen_nn_ops.max_pool(\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py:5327 max_pool\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n        ret = Operation(\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 2 from 1 for '{{node sequential_1/max_pooling2d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](sequential_1/batch_normalization_4/FusedBatchNormV3)' with input shapes: [?,1,1,256].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cc9f67a5af80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mlist_converted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lets_convert2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-c696fd373bc1>\u001b[0m in \u001b[0;36m_lets_convert2\u001b[0;34m(data, x, y, batch_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlist_converted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrel_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt3_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-bcae8eef48b8>\u001b[0m in \u001b[0;36mto_onnx\u001b[0;34m(i, x, abs_errors, rel_errors, t0_list, t1_list, t2_list, t3_list, s_list)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#model = torch.load(path+model_name+'.pth')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mk_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mt_elapsed_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msince_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Export the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:424 call\n        return self._run_internal_graph(\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/layers/pooling.py:295 call\n        outputs = self.pool_function(\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py:4606 max_pool\n        return gen_nn_ops.max_pool(\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py:5327 max_pool\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n        ret = Operation(\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 2 from 1 for '{{node sequential_1/max_pooling2d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](sequential_1/batch_normalization_4/FusedBatchNormV3)' with input shapes: [?,1,1,256].\n"
     ]
    }
   ],
   "source": [
    "#list_converted = _lets_convert(test_ds)\n",
    "model_name = 'Alexnet-keras'\n",
    "import pandas as pd \n",
    "for batch_size in [1, 5,10,20,30,40,50,60,70,80,90,100, 128,150,200, 250,300,350, 400, 450, 500]:\n",
    "    print(\"################ Batch size: \", batch_size)\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_test)\n",
    "\n",
    "    list_converted, abs_errors, rel_errors, total_time, t0, t1, t2, t3, file_size = _lets_convert2(datagen, x_test, y_test, batch_size)\n",
    "    for i in range(len(abs_errors)):\n",
    "        if i == 0:\n",
    "            abs_array = abs_errors[i]\n",
    "            rel_array = rel_errors[i]\n",
    "        else:\n",
    "            np.append(abs_array, abs_errors[i])\n",
    "            np.append(rel_array, rel_errors[i])\n",
    "            \n",
    "    abs_list = []\n",
    "    rel_list = []\n",
    "    model_list = []\n",
    "    batch_list = []\n",
    "    summary_list = ['Modelsize:{}, Conversion: {}, Loading: {}, t1: {}, conversion time: {}, onnx runtime: {}, onnx filesize: {}'.format(size0, total_time, t0, t1, t2, t3, file_size)]\n",
    "    for i in range(len(abs_array)):\n",
    "        abs_list.append(abs_array[i][0])\n",
    "        rel = rel_array[i][0]\n",
    "        if rel == np.inf or rel == -np.inf:\n",
    "            rel = 0.0\n",
    "        rel_list.append(rel)\n",
    "        batch_list.append(batch_size)\n",
    "        model_list.append(model_name)\n",
    "        if i >= len(summary_list):\n",
    "            summary_list.append('')\n",
    "    print(len(summary_list), len(rel_list))\n",
    "    data = pd.DataFrame({'model':model_list,'batch_size': batch_list, 'abs_errors':abs_list, 'rel_errors':rel_list, 'summary': summary_list})\n",
    "    data.to_csv('./data/errors/keras2/tf_errors_{}_{}.csv'.format(model_name, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ Batch size:  1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-7-d3ceb8c18f50>:3 process_image  *\n        image=tf.image.resize(image,(64,64))\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py:1641 resize_images_v2\n        return _resize_images_common(\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py:1320 _resize_images_common\n        raise ValueError('\\'images\\' must have either 3 or 4 dimensions.')\n\n    ValueError: 'images' must have either 3 or 4 dimensions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3a608cb80a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m450\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"################ Batch size: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     train_ds=(train_ds\n\u001b[0m\u001b[1;32m      6\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_ds_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     \"\"\"\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4201\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4203\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   4204\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3523\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3049\u001b[0m       \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[0;32m-> 3051\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   3052\u001b[0m         *args, **kwargs)\n\u001b[1;32m   3053\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3516\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3517\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3518\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3519\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3451\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3453\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3454\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3455\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-7-d3ceb8c18f50>:3 process_image  *\n        image=tf.image.resize(image,(64,64))\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py:1641 resize_images_v2\n        return _resize_images_common(\n    /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py:1320 _resize_images_common\n        raise ValueError('\\'images\\' must have either 3 or 4 dimensions.')\n\n    ValueError: 'images' must have either 3 or 4 dimensions.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Alexnet-keras'\n",
    "import pandas as pd \n",
    "for batch_size in [1, 5,10,20,30,40,50,60,70,80,90,100,128, 150,200, 250,300,350, 400, 450, 500]:\n",
    "    print(\"################ Batch size: \", batch_size)\n",
    "    train_ds=(train_ds\n",
    "          .map(process_image)\n",
    "          .shuffle(buffer_size=train_ds_size)\n",
    "          .batch(batch_size=batch_size,drop_remainder=True))\n",
    "    test_ds=(test_ds\n",
    "          .map(process_image)\n",
    "          .shuffle(buffer_size=test_ds_size)\n",
    "          .batch(batch_size=batch_size,drop_remainder=True))\n",
    "\n",
    "    list_converted, abs_errors, rel_errors, total_time, t0, t1, t2, t3, file_size = _lets_convert(test_ds)\n",
    "    for i in range(len(abs_errors)):\n",
    "        if i == 0:\n",
    "            abs_array = abs_errors[i]\n",
    "            rel_array = rel_errors[i]\n",
    "        else:\n",
    "            np.append(abs_array, abs_errors[i])\n",
    "            np.append(rel_array, rel_errors[i])\n",
    "            \n",
    "    abs_list = []\n",
    "    rel_list = []\n",
    "    model_list = []\n",
    "    batch_list = []\n",
    "    summary_list = ['Modelsize:{}, Conversion: {}, Loading: {}, t1: {}, conversion time: {}, onnx runtime: {}, onnx filesize: {}'.format(size0, total_time, t0, t1, t2, t3, file_size)]\n",
    "    for i in range(len(abs_array)):\n",
    "        abs_list.append(abs_array[i][0])\n",
    "        rel = rel_array[i][0]\n",
    "        if rel == np.inf or rel == -np.inf:\n",
    "            rel = 0.0\n",
    "        rel_list.append(rel)\n",
    "        batch_list.append(batch_size)\n",
    "        model_list.append(model_name)\n",
    "        if i >= len(summary_list):\n",
    "            summary_list.append('')\n",
    "    print(len(summary_list), len(rel_list))\n",
    "    data = pd.DataFrame({'model':model_list,'batch_size': batch_list, 'abs_errors':abs_list, 'rel_errors':rel_list, 'summary': summary_list})\n",
    "    data.to_csv('./data/errors/keras2/tf_errors_{}_{}.csv'.format(model_name, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ Batch size:  1\n",
      "converting for batch:  0\n",
      "WARNING:tensorflow:From /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tf2onnx/tf_loader.py:662: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 6s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0846, conversion time: 0.4108, onnx runtime: 0.0005, onnx filesize: 572909.1818181818\n",
      "1 1\n",
      "################ Batch size:  5\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 6s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0547, conversion time: 0.4297, onnx runtime: 0.0007, onnx filesize: 572913.0\n",
      "5 5\n",
      "################ Batch size:  10\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 5s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0563, conversion time: 0.4128, onnx runtime: 0.0010, onnx filesize: 572913.0\n",
      "10 10\n",
      "################ Batch size:  20\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 6s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0594, conversion time: 0.4297, onnx runtime: 0.0029, onnx filesize: 572923.6363636364\n",
      "20 20\n",
      "################ Batch size:  30\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 5s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0580, conversion time: 0.4109, onnx runtime: 0.0044, onnx filesize: 572925.0\n",
      "30 30\n",
      "################ Batch size:  40\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 6s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0850, conversion time: 0.4102, onnx runtime: 0.0046, onnx filesize: 572925.0\n",
      "40 40\n",
      "################ Batch size:  50\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 6s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0630, conversion time: 0.4097, onnx runtime: 0.0041, onnx filesize: 572925.0\n",
      "50 50\n",
      "################ Batch size:  60\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 6s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0645, conversion time: 0.4377, onnx runtime: 0.0056, onnx filesize: 572925.0\n",
      "60 60\n",
      "################ Batch size:  70\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 6s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0707, conversion time: 0.4097, onnx runtime: 0.0060, onnx filesize: 572925.0\n",
      "70 70\n",
      "################ Batch size:  80\n",
      "converting for batch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ee05b6317d1a>:60: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X = (X/255).astype('float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 6s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0958, conversion time: 0.4106, onnx runtime: 0.0064, onnx filesize: 572925.0\n",
      "80 80\n",
      "################ Batch size:  90\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 6s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0723, conversion time: 0.4087, onnx runtime: 0.0065, onnx filesize: 572925.0\n",
      "90 90\n",
      "################ Batch size:  100\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 6s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0773, conversion time: 0.4299, onnx runtime: 0.0064, onnx filesize: 572925.0\n",
      "100 100\n",
      "################ Batch size:  128\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 6s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0850, conversion time: 0.4107, onnx runtime: 0.0081, onnx filesize: 572925.0\n",
      "128 128\n",
      "################ Batch size:  150\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 6s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.0883, conversion time: 0.4282, onnx runtime: 0.0087, onnx filesize: 572925.0\n",
      "150 150\n",
      "################ Batch size:  200\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 7s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.1010, conversion time: 0.4125, onnx runtime: 0.0107, onnx filesize: 572925.0\n",
      "200 200\n",
      "################ Batch size:  250\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 7s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.1411, conversion time: 0.4108, onnx runtime: 0.0133, onnx filesize: 572925.0\n",
      "250 250\n",
      "################ Batch size:  300\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 8s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.1269, conversion time: 0.4113, onnx runtime: 0.0156, onnx filesize: 572925.0\n",
      "300 300\n",
      "################ Batch size:  350\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 9s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.1403, conversion time: 0.4364, onnx runtime: 0.0194, onnx filesize: 572925.0\n",
      "350 350\n",
      "################ Batch size:  400\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 9s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.1525, conversion time: 0.4195, onnx runtime: 0.0206, onnx filesize: 572925.0\n",
      "400 400\n",
      "################ Batch size:  450\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 10s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.1720, conversion time: 0.4472, onnx runtime: 0.0254, onnx filesize: 572925.0\n",
      "450 450\n",
      "################ Batch size:  500\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 10s,  Loading Pytorch: 1.5094027519226074, Pytorch time: 0.1791, conversion time: 0.4202, onnx runtime: 0.0270, onnx filesize: 572925.0\n",
      "500 500\n"
     ]
    }
   ],
   "source": [
    "model_name = 'letnet5-keras'\n",
    "import pandas as pd \n",
    "for batch_size in [1, 5,10,20,30,40,50,60,70,80,90,100,128, 150,200, 250,300,350, 400, 450, 500]:\n",
    "    print(\"################ Batch size: \", batch_size)\n",
    "    train_generator = DataGenerator(x_train, y_train, batch_size = batch_size,\n",
    "                                dim = input_shape,\n",
    "                                n_classes=nb_classes, \n",
    "                                to_fit=True, shuffle=True)\n",
    "    val_generator =  DataGenerator(x_test, y_test, batch_size=batch_size, \n",
    "                               dim = input_shape, \n",
    "                               n_classes= nb_classes, \n",
    "                               to_fit=True, shuffle=True)\n",
    "\n",
    "    list_converted, abs_errors, rel_errors, total_time, t0, t1, t2, t3, file_size = _lets_convert(val_generator)\n",
    "    for i in range(len(abs_errors)):\n",
    "        if i == 0:\n",
    "            abs_array = abs_errors[i]\n",
    "            rel_array = rel_errors[i]\n",
    "        else:\n",
    "            np.append(abs_array, abs_errors[i])\n",
    "            np.append(rel_array, rel_errors[i])\n",
    "            \n",
    "    abs_list = []\n",
    "    rel_list = []\n",
    "    model_list = []\n",
    "    batch_list = []\n",
    "    summary_list = ['Modelsize:{}, Conversion: {}, Loading: {}, t1: {}, conversion time: {}, onnx runtime: {}, onnx filesize: {}'.format(size0, total_time, t0, t1, t2, t3, file_size)]\n",
    "    for i in range(len(abs_array)):\n",
    "        abs_list.append(abs_array[i][0])\n",
    "        rel = rel_array[i][0]\n",
    "        if rel == np.inf or rel == -np.inf:\n",
    "            rel = 0.0\n",
    "        rel_list.append(rel)\n",
    "        batch_list.append(batch_size)\n",
    "        model_list.append(model_name)\n",
    "        if i >= len(summary_list):\n",
    "            summary_list.append('')\n",
    "    print(len(summary_list), len(rel_list))\n",
    "    data = pd.DataFrame({'model':model_list,'batch_size': batch_list, 'abs_errors':abs_list, 'rel_errors':rel_list, 'summary': summary_list})\n",
    "    data.to_csv('./data/errors/keras2/tf_errors_{}_{}.csv'.format(model_name, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to coreml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.24.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:TensorFlow version 2.4.1 detected. Last version known to be fully compatible is 2.3.1 .\n"
     ]
    }
   ],
   "source": [
    "import coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running TensorFlow Graph Passes: 100%|| 5/5 [00:00<00:00, 17.83 passes/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|| 31/31 [00:00<00:00, 147.61 ops/s]\n",
      "Running MIL Common passes: 100%|| 31/31 [00:00<00:00, 698.44 passes/s]\n",
      "Running MIL Clean up passes: 100%|| 8/8 [00:00<00:00, 383.44 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|| 54/54 [00:00<00:00, 1609.97 ops/s]\n"
     ]
    }
   ],
   "source": [
    "coreml_model = coremltools.convert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Model prediction is only supported on macOS version 10.13 or later.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9804776cd1b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcoreml_out_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoreml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/coremltools/models/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, useCPUOnly, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_macos_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 raise Exception(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"Model prediction is only supported on macOS version 10.13 or later.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 )\n",
      "\u001b[0;31mException\u001b[0m: Model prediction is only supported on macOS version 10.13 or later."
     ]
    }
   ],
   "source": [
    "coreml_out_dict = coreml_model..predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
