{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DY2rzDPTuXwW"
   },
   "source": [
    "# A Transfer learning with Keras using ResNet50\n",
    "\n",
    "**Trains a convolutional neural network to classify the CIFAR 10 dataset:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKQaAb-Xzqgo"
   },
   "source": [
    "**Abstract**\n",
    "\n",
    "In this tutorial we will provide a guide through for transfer learning with the main aspects to take into account in the process, some tips and an example implementation in Keras using ResNet50 as the trained model. The task is to transfer the learning of a ResNet50 trained with Imagenet to a model that identify images from CIFAR-10 dataset. Several methods were tested to achieve a greater accuracy which we provide to show the variety of options for a training. However with the final model of this blog we get an accuracy of 94% on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZbyUjVgz5vw"
   },
   "source": [
    "**Introducción**\n",
    "\n",
    "Learning something new takes time and practice but we find it easy to do similar tasks. This is thanks to human association involved in learning. We have the capability to identify patterns from previous knowledge an apply it into new learning.\n",
    "\n",
    "When we meet a person than is faster or better than us in something like a video game or coding it is almost certain that he has do it before or there is an association with a previous similar activity.\n",
    "\n",
    "If we know how to ride a bike, we don’t need to learn from zero how to ride a motorbike. If we know how to play football, we don’t need to learn from zero how to play futsal. If we know how to play the piano, we don’t need to learn from zero how to play another instrument.\n",
    "\n",
    "The same is applicable to machines, if we train a model with a database, it’s not necessary to retrain from zero all the model to adjust to a new similar dataset. Both Imagenet and CIFAR-10 have images that can train a model to classify images. Then, it is very promising if we can save time training a model (because it can really take long time) and start using the weights of a previously trained model. We are going through this concept of transfer learning with all what you need to also build a model on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZFQObha0HH7"
   },
   "source": [
    "**Materials and Methods**\n",
    "\n",
    "*Setting our environment*\n",
    "\n",
    "We are going to use Keras which is an open source library written in Python for neural networks. We work over it with tensorflow in a Google Colab, a Jupyter notebook environment that runs in the cloud.\n",
    "\n",
    "The first thing we do is importing the libraries needed with the line of code below. Running the version as 1.x is optional, without that first line it will run the last version of tensorflow for Colab. We also use numpy and a function of tensorflow but depending on how you build your own model is not necessary to import them.\n",
    "\n",
    "\n",
    "NOTE: To avoid the error \"AttributeError: 'str' object has no attribute 'decode'\". downgraded my h5py package with the following command, then Restarted my ipython kernel and it worked\n",
    "[SO: Post 53740577](https://stackoverflow.com/questions/53740577/does-any-one-got-attributeerror-str-object-has-no-attribute-decode-whi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7RGhYeKiEuc",
    "outputId": "afb2656b-6b55-4eaf-cd86-6a641615c491"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "path_output = \"./data/11-08-2021/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LladPdSDvdes"
   },
   "outputs": [],
   "source": [
    "#!pip install 'h5py==2.10.0' --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tmb4LqOlRuWm",
    "outputId": "709f4008-0836-41bf-cf47-01f95de7c87d"
   },
   "outputs": [],
   "source": [
    "#!pip uninstall tensorflow-gpu -y\n",
    "#!pip uninstall tensorflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install tensorflow-gpu -y\n",
    "#!pip install tensorflow\n",
    "#!conda update keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11713273532148542727\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10562532800\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1882367395494068085\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:af:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ww2FLY-ZOIPB",
    "outputId": "051ba68d-dc0d-4630-8d7b-8a6c3fe8eb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (1.10.1)\r\n",
      "Requirement already satisfied: six in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from onnx) (1.16.0)\r\n",
      "Requirement already satisfied: protobuf in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from onnx) (3.17.3)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from onnx) (1.20.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from onnx) (3.7.4.3)\r\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow\n",
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Hq-qR1S0uEuw"
   },
   "outputs": [],
   "source": [
    "#% tensorflow_version 1.x\n",
    "import tensorflow.keras as K\n",
    "import tensorflow as tf\n",
    "\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "#config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acNr1bAU5l1T"
   },
   "source": [
    "Training a model uses a lot of resources so we recommend using a GPU configuration in the Colab. This will speed up the process and allow more testing. We will talk about some other ways to improve computation soon.\n",
    "\n",
    "**Database**\n",
    "\n",
    "CIFAR-10 is a dataset with 60000 32x32 colour images grouped in 10 classes, that means 6000 images per class. This is a dataset of 50,000 32x32 color training images and 10,000 test images, labeled over 10 categories.\n",
    "The categories are airplane, automobile, beer, cat, deer, dog, frog, horse, ship, truck. We can take advantage of the fact that these categories and a lot more are into the Imagenet collection.\n",
    "To load a database with Keras, we use:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "tf.keras.datasets.cifar10.load_data()\n",
    "```\n",
    "\n",
    "\n",
    "**Preprocess**\n",
    "\n",
    "\n",
    "Now that the data is loaded, we are going to build a preprocess function for the data. We have X as a numpy array of shape (m, 32, 32, 3) where m is the number of images, 32 and 32 the dimensions, and 3 is because we use color images (RGB). \n",
    "\n",
    "We have a set of X for training and a set of X for validation. Y is a numpy array of shape (m, ) that we want to be our labels. Since we work with 10 different categories, we make use of one-hot encoding with a function of Keras that makes our Y into a shape of (m, 10). \n",
    "\n",
    "That also applies for the validation.\n",
    "As we said before, we are going to use ResNet50 but there are also many other models available with pre-trained weights such as VGG16, ResNet101, InceptionV3 and DenseNet121. Each one has its own preprocess function for the inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jM4iaXlXunnT"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, Y):\n",
    "    \"\"\"\n",
    "    a function that trains a convolutional neural network to classify the\n",
    "    CIFAR 10 dataset\n",
    "    :param X: X is a numpy.ndarray of shape (m, 32, 32, 3) containing the\n",
    "    CIFAR 10 data, where m is the number of data points\n",
    "    :param Y: Y is a numpy.ndarray of shape (m,) containing the CIFAR 10\n",
    "    labels for X\n",
    "    :return: X_p, Y_p\n",
    "        X_p is a numpy.ndarray containing the preprocessed X\n",
    "        Y_p is a numpy.ndarray containing the preprocessed Y\n",
    "    \"\"\"\n",
    "    X_p = K.applications.resnet50.preprocess_input(X)\n",
    "    Y_p = K.utils.to_categorical(Y, 10)\n",
    "    return X_p, Y_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odhz3ttQ6ElQ"
   },
   "source": [
    "Next, we are going to call our function with the parameters loaded from the CIFAR10 database. It’s important to get to know your data to monitor the steps and know how to build your model. Let’s print the shapes of our x_train and y_train before and after the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcn0GCH0unyx",
    "outputId": "be8ecb6e-b20d-42db-a2f7-24c4dd4cfbe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((50000, 32, 32, 3), (50000, 1))\n",
      "((50000, 32, 32, 3), (50000, 10))\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = K.datasets.cifar10.load_data()\n",
    "print((x_train.shape, y_train.shape))\n",
    "x_train, y_train = preprocess_data(x_train, y_train)\n",
    "x_test, y_test = preprocess_data(x_test, y_test)\n",
    "print((x_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTvTGiLr6NR5"
   },
   "source": [
    "**Using weights of a trained neural network**\n",
    "\n",
    "A pretrained model from the Keras Applications has the advantage of allow you to use weights that are already calibrated to make predictions. In this case, we use the weights from Imagenet and the network is a ResNet50. The option include_top=False allows feature extraction by removing the last dense layers. This let us control the output and input of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "P45PPOEkun3P"
   },
   "outputs": [],
   "source": [
    "#input_t = K.Input(shape=(32, 32, 3))\n",
    "input_t = K.Input(shape=(224, 224, 3))\n",
    "res_model = K.applications.ResNet50(include_top=False,\n",
    "                                        weights=\"imagenet\",\n",
    "                                        input_tensor=input_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('./data/11-08-2021/restored_keras_imagenet_resnet50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16KgfuOs6b2v"
   },
   "source": [
    "From this point it all comes to testing and a bit of creativity. The starting point is very advantageous since we have weights that already serve for image classification but since we are using it on a completely new dataset, there is a need for adjustments. Our objective is to build a model that has high accuracy in their classifications. In this case, if an image of a dog is presented, it successfully identifies it as a dog and not as a train, for example.\n",
    "\n",
    "Let’s say we want to achieve an accuracy of more than 88% on training data but we also wish that it doesn’t have overfitting. How do we get this? Well at this point our models may diverge, this is where we test what tools we can use for that objective. The important here is to learn about transfer learning and making robust models. We follow an example but we can run with different approaches that we will discuss.\n",
    "The two aproaches you can take in transfer learning are:\n",
    "\n",
    "*   Feature extraction\n",
    "*   Fine tuning\n",
    "\n",
    "\n",
    "This refers on how you use the layers of your pretrained model. We have already a very huge amount of parameters because of the number of layer of the ResNet50 but we have calibrated weights. We can choose to ‘freeze’ those layers (as many as you can) so those values doesn’t change, and by that way saving time and computational cost. However as the dataset is entirely different is not a bad idea to train all the model\n",
    "\n",
    "In this case, we ‘freeze’ all layers except for the last block of the ResNet50. The way to do this in Keras is with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VJYlVilkbjeo"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "#res_model = tf.keras.models.load_model('./data/11-08-2021/restored_keras_imagenet_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0S4X0Eh3un9h",
    "outputId": "4bc26abd-3be0-40dc-d265-e704871a4102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 - False\n",
      "1 conv1_pad - False\n",
      "2 conv1_conv - False\n",
      "3 conv1_bn - False\n",
      "4 conv1_relu - False\n",
      "5 pool1_pad - False\n",
      "6 pool1_pool - False\n",
      "7 conv2_block1_1_conv - False\n",
      "8 conv2_block1_1_bn - False\n",
      "9 conv2_block1_1_relu - False\n",
      "10 conv2_block1_2_conv - False\n",
      "11 conv2_block1_2_bn - False\n",
      "12 conv2_block1_2_relu - False\n",
      "13 conv2_block1_0_conv - False\n",
      "14 conv2_block1_3_conv - False\n",
      "15 conv2_block1_0_bn - False\n",
      "16 conv2_block1_3_bn - False\n",
      "17 conv2_block1_add - False\n",
      "18 conv2_block1_out - False\n",
      "19 conv2_block2_1_conv - False\n",
      "20 conv2_block2_1_bn - False\n",
      "21 conv2_block2_1_relu - False\n",
      "22 conv2_block2_2_conv - False\n",
      "23 conv2_block2_2_bn - False\n",
      "24 conv2_block2_2_relu - False\n",
      "25 conv2_block2_3_conv - False\n",
      "26 conv2_block2_3_bn - False\n",
      "27 conv2_block2_add - False\n",
      "28 conv2_block2_out - False\n",
      "29 conv2_block3_1_conv - False\n",
      "30 conv2_block3_1_bn - False\n",
      "31 conv2_block3_1_relu - False\n",
      "32 conv2_block3_2_conv - False\n",
      "33 conv2_block3_2_bn - False\n",
      "34 conv2_block3_2_relu - False\n",
      "35 conv2_block3_3_conv - False\n",
      "36 conv2_block3_3_bn - False\n",
      "37 conv2_block3_add - False\n",
      "38 conv2_block3_out - False\n",
      "39 conv3_block1_1_conv - False\n",
      "40 conv3_block1_1_bn - False\n",
      "41 conv3_block1_1_relu - False\n",
      "42 conv3_block1_2_conv - False\n",
      "43 conv3_block1_2_bn - False\n",
      "44 conv3_block1_2_relu - False\n",
      "45 conv3_block1_0_conv - False\n",
      "46 conv3_block1_3_conv - False\n",
      "47 conv3_block1_0_bn - False\n",
      "48 conv3_block1_3_bn - False\n",
      "49 conv3_block1_add - False\n",
      "50 conv3_block1_out - False\n",
      "51 conv3_block2_1_conv - False\n",
      "52 conv3_block2_1_bn - False\n",
      "53 conv3_block2_1_relu - False\n",
      "54 conv3_block2_2_conv - False\n",
      "55 conv3_block2_2_bn - False\n",
      "56 conv3_block2_2_relu - False\n",
      "57 conv3_block2_3_conv - False\n",
      "58 conv3_block2_3_bn - False\n",
      "59 conv3_block2_add - False\n",
      "60 conv3_block2_out - False\n",
      "61 conv3_block3_1_conv - False\n",
      "62 conv3_block3_1_bn - False\n",
      "63 conv3_block3_1_relu - False\n",
      "64 conv3_block3_2_conv - False\n",
      "65 conv3_block3_2_bn - False\n",
      "66 conv3_block3_2_relu - False\n",
      "67 conv3_block3_3_conv - False\n",
      "68 conv3_block3_3_bn - False\n",
      "69 conv3_block3_add - False\n",
      "70 conv3_block3_out - False\n",
      "71 conv3_block4_1_conv - False\n",
      "72 conv3_block4_1_bn - False\n",
      "73 conv3_block4_1_relu - False\n",
      "74 conv3_block4_2_conv - False\n",
      "75 conv3_block4_2_bn - False\n",
      "76 conv3_block4_2_relu - False\n",
      "77 conv3_block4_3_conv - False\n",
      "78 conv3_block4_3_bn - False\n",
      "79 conv3_block4_add - False\n",
      "80 conv3_block4_out - False\n",
      "81 conv4_block1_1_conv - False\n",
      "82 conv4_block1_1_bn - False\n",
      "83 conv4_block1_1_relu - False\n",
      "84 conv4_block1_2_conv - False\n",
      "85 conv4_block1_2_bn - False\n",
      "86 conv4_block1_2_relu - False\n",
      "87 conv4_block1_0_conv - False\n",
      "88 conv4_block1_3_conv - False\n",
      "89 conv4_block1_0_bn - False\n",
      "90 conv4_block1_3_bn - False\n",
      "91 conv4_block1_add - False\n",
      "92 conv4_block1_out - False\n",
      "93 conv4_block2_1_conv - False\n",
      "94 conv4_block2_1_bn - False\n",
      "95 conv4_block2_1_relu - False\n",
      "96 conv4_block2_2_conv - False\n",
      "97 conv4_block2_2_bn - False\n",
      "98 conv4_block2_2_relu - False\n",
      "99 conv4_block2_3_conv - False\n",
      "100 conv4_block2_3_bn - False\n",
      "101 conv4_block2_add - False\n",
      "102 conv4_block2_out - False\n",
      "103 conv4_block3_1_conv - False\n",
      "104 conv4_block3_1_bn - False\n",
      "105 conv4_block3_1_relu - False\n",
      "106 conv4_block3_2_conv - False\n",
      "107 conv4_block3_2_bn - False\n",
      "108 conv4_block3_2_relu - False\n",
      "109 conv4_block3_3_conv - False\n",
      "110 conv4_block3_3_bn - False\n",
      "111 conv4_block3_add - False\n",
      "112 conv4_block3_out - False\n",
      "113 conv4_block4_1_conv - False\n",
      "114 conv4_block4_1_bn - False\n",
      "115 conv4_block4_1_relu - False\n",
      "116 conv4_block4_2_conv - False\n",
      "117 conv4_block4_2_bn - False\n",
      "118 conv4_block4_2_relu - False\n",
      "119 conv4_block4_3_conv - False\n",
      "120 conv4_block4_3_bn - False\n",
      "121 conv4_block4_add - False\n",
      "122 conv4_block4_out - False\n",
      "123 conv4_block5_1_conv - False\n",
      "124 conv4_block5_1_bn - False\n",
      "125 conv4_block5_1_relu - False\n",
      "126 conv4_block5_2_conv - False\n",
      "127 conv4_block5_2_bn - False\n",
      "128 conv4_block5_2_relu - False\n",
      "129 conv4_block5_3_conv - False\n",
      "130 conv4_block5_3_bn - False\n",
      "131 conv4_block5_add - False\n",
      "132 conv4_block5_out - False\n",
      "133 conv4_block6_1_conv - False\n",
      "134 conv4_block6_1_bn - False\n",
      "135 conv4_block6_1_relu - False\n",
      "136 conv4_block6_2_conv - False\n",
      "137 conv4_block6_2_bn - False\n",
      "138 conv4_block6_2_relu - False\n",
      "139 conv4_block6_3_conv - False\n",
      "140 conv4_block6_3_bn - False\n",
      "141 conv4_block6_add - False\n",
      "142 conv4_block6_out - False\n",
      "143 conv5_block1_1_conv - True\n",
      "144 conv5_block1_1_bn - True\n",
      "145 conv5_block1_1_relu - True\n",
      "146 conv5_block1_2_conv - True\n",
      "147 conv5_block1_2_bn - True\n",
      "148 conv5_block1_2_relu - True\n",
      "149 conv5_block1_0_conv - True\n",
      "150 conv5_block1_3_conv - True\n",
      "151 conv5_block1_0_bn - True\n",
      "152 conv5_block1_3_bn - True\n",
      "153 conv5_block1_add - True\n",
      "154 conv5_block1_out - True\n",
      "155 conv5_block2_1_conv - True\n",
      "156 conv5_block2_1_bn - True\n",
      "157 conv5_block2_1_relu - True\n",
      "158 conv5_block2_2_conv - True\n",
      "159 conv5_block2_2_bn - True\n",
      "160 conv5_block2_2_relu - True\n",
      "161 conv5_block2_3_conv - True\n",
      "162 conv5_block2_3_bn - True\n",
      "163 conv5_block2_add - True\n",
      "164 conv5_block2_out - True\n",
      "165 conv5_block3_1_conv - True\n",
      "166 conv5_block3_1_bn - True\n",
      "167 conv5_block3_1_relu - True\n",
      "168 conv5_block3_2_conv - True\n",
      "169 conv5_block3_2_bn - True\n",
      "170 conv5_block3_2_relu - True\n",
      "171 conv5_block3_3_conv - True\n",
      "172 conv5_block3_3_bn - True\n",
      "173 conv5_block3_add - True\n",
      "174 conv5_block3_out - True\n",
      "0 input_1 - False\n",
      "1 conv1_pad - False\n",
      "2 conv1_conv - False\n",
      "3 conv1_bn - False\n",
      "4 conv1_relu - False\n",
      "5 pool1_pad - False\n",
      "6 pool1_pool - False\n",
      "7 conv2_block1_1_conv - False\n",
      "8 conv2_block1_1_bn - False\n",
      "9 conv2_block1_1_relu - False\n",
      "10 conv2_block1_2_conv - False\n",
      "11 conv2_block1_2_bn - False\n",
      "12 conv2_block1_2_relu - False\n",
      "13 conv2_block1_0_conv - False\n",
      "14 conv2_block1_3_conv - False\n",
      "15 conv2_block1_0_bn - False\n",
      "16 conv2_block1_3_bn - False\n",
      "17 conv2_block1_add - False\n",
      "18 conv2_block1_out - False\n",
      "19 conv2_block2_1_conv - False\n",
      "20 conv2_block2_1_bn - False\n",
      "21 conv2_block2_1_relu - False\n",
      "22 conv2_block2_2_conv - False\n",
      "23 conv2_block2_2_bn - False\n",
      "24 conv2_block2_2_relu - False\n",
      "25 conv2_block2_3_conv - False\n",
      "26 conv2_block2_3_bn - False\n",
      "27 conv2_block2_add - False\n",
      "28 conv2_block2_out - False\n",
      "29 conv2_block3_1_conv - False\n",
      "30 conv2_block3_1_bn - False\n",
      "31 conv2_block3_1_relu - False\n",
      "32 conv2_block3_2_conv - False\n",
      "33 conv2_block3_2_bn - False\n",
      "34 conv2_block3_2_relu - False\n",
      "35 conv2_block3_3_conv - False\n",
      "36 conv2_block3_3_bn - False\n",
      "37 conv2_block3_add - False\n",
      "38 conv2_block3_out - False\n",
      "39 conv3_block1_1_conv - False\n",
      "40 conv3_block1_1_bn - False\n",
      "41 conv3_block1_1_relu - False\n",
      "42 conv3_block1_2_conv - False\n",
      "43 conv3_block1_2_bn - False\n",
      "44 conv3_block1_2_relu - False\n",
      "45 conv3_block1_0_conv - False\n",
      "46 conv3_block1_3_conv - False\n",
      "47 conv3_block1_0_bn - False\n",
      "48 conv3_block1_3_bn - False\n",
      "49 conv3_block1_add - False\n",
      "50 conv3_block1_out - False\n",
      "51 conv3_block2_1_conv - False\n",
      "52 conv3_block2_1_bn - False\n",
      "53 conv3_block2_1_relu - False\n",
      "54 conv3_block2_2_conv - False\n",
      "55 conv3_block2_2_bn - False\n",
      "56 conv3_block2_2_relu - False\n",
      "57 conv3_block2_3_conv - False\n",
      "58 conv3_block2_3_bn - False\n",
      "59 conv3_block2_add - False\n",
      "60 conv3_block2_out - False\n",
      "61 conv3_block3_1_conv - False\n",
      "62 conv3_block3_1_bn - False\n",
      "63 conv3_block3_1_relu - False\n",
      "64 conv3_block3_2_conv - False\n",
      "65 conv3_block3_2_bn - False\n",
      "66 conv3_block3_2_relu - False\n",
      "67 conv3_block3_3_conv - False\n",
      "68 conv3_block3_3_bn - False\n",
      "69 conv3_block3_add - False\n",
      "70 conv3_block3_out - False\n",
      "71 conv3_block4_1_conv - False\n",
      "72 conv3_block4_1_bn - False\n",
      "73 conv3_block4_1_relu - False\n",
      "74 conv3_block4_2_conv - False\n",
      "75 conv3_block4_2_bn - False\n",
      "76 conv3_block4_2_relu - False\n",
      "77 conv3_block4_3_conv - False\n",
      "78 conv3_block4_3_bn - False\n",
      "79 conv3_block4_add - False\n",
      "80 conv3_block4_out - False\n",
      "81 conv4_block1_1_conv - False\n",
      "82 conv4_block1_1_bn - False\n",
      "83 conv4_block1_1_relu - False\n",
      "84 conv4_block1_2_conv - False\n",
      "85 conv4_block1_2_bn - False\n",
      "86 conv4_block1_2_relu - False\n",
      "87 conv4_block1_0_conv - False\n",
      "88 conv4_block1_3_conv - False\n",
      "89 conv4_block1_0_bn - False\n",
      "90 conv4_block1_3_bn - False\n",
      "91 conv4_block1_add - False\n",
      "92 conv4_block1_out - False\n",
      "93 conv4_block2_1_conv - False\n",
      "94 conv4_block2_1_bn - False\n",
      "95 conv4_block2_1_relu - False\n",
      "96 conv4_block2_2_conv - False\n",
      "97 conv4_block2_2_bn - False\n",
      "98 conv4_block2_2_relu - False\n",
      "99 conv4_block2_3_conv - False\n",
      "100 conv4_block2_3_bn - False\n",
      "101 conv4_block2_add - False\n",
      "102 conv4_block2_out - False\n",
      "103 conv4_block3_1_conv - False\n",
      "104 conv4_block3_1_bn - False\n",
      "105 conv4_block3_1_relu - False\n",
      "106 conv4_block3_2_conv - False\n",
      "107 conv4_block3_2_bn - False\n",
      "108 conv4_block3_2_relu - False\n",
      "109 conv4_block3_3_conv - False\n",
      "110 conv4_block3_3_bn - False\n",
      "111 conv4_block3_add - False\n",
      "112 conv4_block3_out - False\n",
      "113 conv4_block4_1_conv - False\n",
      "114 conv4_block4_1_bn - False\n",
      "115 conv4_block4_1_relu - False\n",
      "116 conv4_block4_2_conv - False\n",
      "117 conv4_block4_2_bn - False\n",
      "118 conv4_block4_2_relu - False\n",
      "119 conv4_block4_3_conv - False\n",
      "120 conv4_block4_3_bn - False\n",
      "121 conv4_block4_add - False\n",
      "122 conv4_block4_out - False\n",
      "123 conv4_block5_1_conv - False\n",
      "124 conv4_block5_1_bn - False\n",
      "125 conv4_block5_1_relu - False\n",
      "126 conv4_block5_2_conv - False\n",
      "127 conv4_block5_2_bn - False\n",
      "128 conv4_block5_2_relu - False\n",
      "129 conv4_block5_3_conv - False\n",
      "130 conv4_block5_3_bn - False\n",
      "131 conv4_block5_add - False\n",
      "132 conv4_block5_out - False\n",
      "133 conv4_block6_1_conv - False\n",
      "134 conv4_block6_1_bn - False\n",
      "135 conv4_block6_1_relu - False\n",
      "136 conv4_block6_2_conv - False\n",
      "137 conv4_block6_2_bn - False\n",
      "138 conv4_block6_2_relu - False\n",
      "139 conv4_block6_3_conv - False\n",
      "140 conv4_block6_3_bn - False\n",
      "141 conv4_block6_add - False\n",
      "142 conv4_block6_out - False\n",
      "143 conv5_block1_1_conv - False\n",
      "144 conv5_block1_1_bn - False\n",
      "145 conv5_block1_1_relu - False\n",
      "146 conv5_block1_2_conv - False\n",
      "147 conv5_block1_2_bn - False\n",
      "148 conv5_block1_2_relu - False\n",
      "149 conv5_block1_0_conv - False\n",
      "150 conv5_block1_3_conv - False\n",
      "151 conv5_block1_0_bn - False\n",
      "152 conv5_block1_3_bn - False\n",
      "153 conv5_block1_add - False\n",
      "154 conv5_block1_out - False\n",
      "155 conv5_block2_1_conv - False\n",
      "156 conv5_block2_1_bn - False\n",
      "157 conv5_block2_1_relu - False\n",
      "158 conv5_block2_2_conv - False\n",
      "159 conv5_block2_2_bn - False\n",
      "160 conv5_block2_2_relu - False\n",
      "161 conv5_block2_3_conv - False\n",
      "162 conv5_block2_3_bn - False\n",
      "163 conv5_block2_add - False\n",
      "164 conv5_block2_out - False\n",
      "165 conv5_block3_1_conv - False\n",
      "166 conv5_block3_1_bn - False\n",
      "167 conv5_block3_1_relu - False\n",
      "168 conv5_block3_2_conv - False\n",
      "169 conv5_block3_2_bn - False\n",
      "170 conv5_block3_2_relu - False\n",
      "171 conv5_block3_3_conv - False\n",
      "172 conv5_block3_3_bn - False\n",
      "173 conv5_block3_add - False\n",
      "174 conv5_block3_out - False\n"
     ]
    }
   ],
   "source": [
    "for layer in res_model.layers[:143]:\n",
    "    layer.trainable = False\n",
    "# Check the freezed was done ok\n",
    "for i, layer in enumerate(res_model.layers):\n",
    "    print(i, layer.name, \"-\", layer.trainable)\n",
    "#to_res = (224, 224)for layer in res_model.layers[:143]:\n",
    "    layer.trainable = False\n",
    "# Check the freezed was done ok\n",
    "for i, layer in enumerate(res_model.layers):\n",
    "    print(i, layer.name, \"-\", layer.trainable)\n",
    "#to_res = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYJY8iUXyP6H",
    "outputId": "cb4a9e2a-eb77-40e9-8a52-2618da9a8ff4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7T3fopH7DeM"
   },
   "source": [
    "Later, we need to connect our pretrained model with the new layers of our model. We can use global pooling or a flatten layer to connect the dimensions of the previous layers with the new layers. With just a flatten layer and a dense layer with softmax we can perform close the model and start making classification.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "model = K.models.Sequential()\n",
    "model.add(res_model)\n",
    "model.add(K.layers.Flatten())\n",
    "model.add(K.layers.Dense(10, activation='softmax'))\n",
    "```\n",
    "\n",
    "The final layers are below. However we explain some more aspects to improve the model and make a good classification. We present the main aspects taken into account to build the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "l8x-GOWLwl26"
   },
   "outputs": [],
   "source": [
    "model = K.models.Sequential()\n",
    "model.add(K.layers.Lambda(lambda image: tf.image.resize(image, (224, 224))))\n",
    "model.add(res_model)\n",
    "model.add(K.layers.Flatten())\n",
    "model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(256, activation='relu'))\n",
    "model.add(K.layers.Dropout(0.5))\n",
    "model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(128, activation='relu'))\n",
    "model.add(K.layers.Dropout(0.5))\n",
    "model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(64, activation='relu'))\n",
    "model.add(K.layers.Dropout(0.5))\n",
    "model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZVJzPtXX7OT_"
   },
   "outputs": [],
   "source": [
    "model = K.models.Sequential()\n",
    "model.add(K.layers.Lambda(lambda image: tf.image.resize(image, (224, 224))))\n",
    "model.add(res_model)\n",
    "model.add(K.layers.Flatten())\n",
    "model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(256, tf.keras.layers.Activation('relu')))\n",
    "model.add(K.layers.Dropout(0.5))\n",
    "model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(128, tf.keras.layers.Activation('relu')))\n",
    "model.add(K.layers.Dropout(0.5))\n",
    "model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(64, tf.keras.layers.Activation('relu')))\n",
    "model.add(K.layers.Dropout(0.5))\n",
    "model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(10, tf.keras.layers.Activation('softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McunKAvB7aGy"
   },
   "source": [
    "We have regularizers to help us avoid overfitting and optimizers to get a faster result. Each of them can also affect our accuracy, so we present what to take into account. The most important are:\n",
    "\n",
    "\n",
    "\n",
    "*   Batch size: It is recommended to use a number of batch size with powers of 2 (8, 16, 32, 64, 128, …) because it fits with the memory of the computer.\n",
    "*   Learning rate: For transfer learning it is recommended a very low learning rate because we don’t want to change too much what is previously learned.\n",
    "*   Number of layers: This depends on how much you relay from the layers of the pretrained model. We found that if we leave all the model for training just a flatten layer and a dense with softmax is enough but since we incorporated the feature extraction it was required more layers at the end.\n",
    "*   Optimization methods: We tested with SGD and RMSprop. SGD with a very low learning required more epochs (30) to complete a razonable training. We used RMSprop with 5 epochs to get our result.\n",
    "*  Regularization methods: To avoid overfitting we used Batch normalization and dropout in-between the dense layers.\n",
    "*  Callbacks: In Keras, we can use callbacks in our model to perform certain actions in the training such as weight saving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kgwnqS44uoDZ"
   },
   "outputs": [],
   "source": [
    "date = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')\n",
    "check_point = K.callbacks.ModelCheckpoint(filepath=\"./data/19-08-2021/resnet50-cifar10_{}.h5\".format(date),\n",
    "                                              monitor=\"val_acc\",\n",
    "                                              mode=\"max\",\n",
    "                                              save_best_only=True,\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rdR6-iqIuoHS"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=K.optimizers.RMSprop(lr=2e-5),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "arztcLnTzJPY"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "#config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuqNLLyLuoKi",
    "outputId": "87ba02e7-791a-4291-8939-923e5ee138de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 109s 62ms/step - loss: 2.1377 - accuracy: 0.2893 - val_loss: 0.7911 - val_accuracy: 0.8370\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 1.3611 - accuracy: 0.5445 - val_loss: 0.6037 - val_accuracy: 0.8733\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 1.1141 - accuracy: 0.6465 - val_loss: 0.4950 - val_accuracy: 0.8896\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.9509 - accuracy: 0.7084 - val_loss: 0.4271 - val_accuracy: 0.8984\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.8209 - accuracy: 0.7573 - val_loss: 0.3822 - val_accuracy: 0.9054\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 96s 62ms/step - loss: 0.7301 - accuracy: 0.7924 - val_loss: 0.3446 - val_accuracy: 0.9097\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.6446 - accuracy: 0.8186 - val_loss: 0.3246 - val_accuracy: 0.9111\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.5892 - accuracy: 0.8370 - val_loss: 0.3051 - val_accuracy: 0.9145\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.5462 - accuracy: 0.8493 - val_loss: 0.2917 - val_accuracy: 0.9158\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 95s 61ms/step - loss: 0.5074 - accuracy: 0.8587 - val_loss: 0.2825 - val_accuracy: 0.9165\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.4534 - accuracy: 0.8779 - val_loss: 0.2795 - val_accuracy: 0.9175\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.4263 - accuracy: 0.8810 - val_loss: 0.2727 - val_accuracy: 0.9193\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.3926 - accuracy: 0.8955 - val_loss: 0.2721 - val_accuracy: 0.9186\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.3600 - accuracy: 0.9014 - val_loss: 0.2678 - val_accuracy: 0.9209\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.3349 - accuracy: 0.9116 - val_loss: 0.2676 - val_accuracy: 0.9206\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.3160 - accuracy: 0.9156 - val_loss: 0.2687 - val_accuracy: 0.9216\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.2923 - accuracy: 0.9239 - val_loss: 0.2664 - val_accuracy: 0.9214\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.2776 - accuracy: 0.9276 - val_loss: 0.2686 - val_accuracy: 0.9202\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.2588 - accuracy: 0.9327 - val_loss: 0.2734 - val_accuracy: 0.9200\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 96s 62ms/step - loss: 0.2461 - accuracy: 0.9356 - val_loss: 0.2753 - val_accuracy: 0.9201\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.2252 - accuracy: 0.9404 - val_loss: 0.2746 - val_accuracy: 0.9197\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.2158 - accuracy: 0.9422 - val_loss: 0.2776 - val_accuracy: 0.9212\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.2019 - accuracy: 0.9465 - val_loss: 0.2826 - val_accuracy: 0.9209\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.2002 - accuracy: 0.9470 - val_loss: 0.2866 - val_accuracy: 0.9196\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 96s 62ms/step - loss: 0.1895 - accuracy: 0.9497 - val_loss: 0.2893 - val_accuracy: 0.9209\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1734 - accuracy: 0.9542 - val_loss: 0.2951 - val_accuracy: 0.9188\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1648 - accuracy: 0.9557 - val_loss: 0.3006 - val_accuracy: 0.9198\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1611 - accuracy: 0.9576 - val_loss: 0.3033 - val_accuracy: 0.9197\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1509 - accuracy: 0.9615 - val_loss: 0.3048 - val_accuracy: 0.9185\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1491 - accuracy: 0.9601 - val_loss: 0.3077 - val_accuracy: 0.9204\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 97s 62ms/step - loss: 0.1444 - accuracy: 0.9609 - val_loss: 0.3140 - val_accuracy: 0.9179\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 96s 62ms/step - loss: 0.1420 - accuracy: 0.9617 - val_loss: 0.3175 - val_accuracy: 0.9198\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1398 - accuracy: 0.9613 - val_loss: 0.3203 - val_accuracy: 0.9190\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1291 - accuracy: 0.9658 - val_loss: 0.3223 - val_accuracy: 0.9200\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1233 - accuracy: 0.9675 - val_loss: 0.3271 - val_accuracy: 0.9200\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1259 - accuracy: 0.9667 - val_loss: 0.3306 - val_accuracy: 0.9196\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1186 - accuracy: 0.9686 - val_loss: 0.3338 - val_accuracy: 0.9197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1161 - accuracy: 0.9689 - val_loss: 0.3402 - val_accuracy: 0.9199\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1224 - accuracy: 0.9653 - val_loss: 0.3451 - val_accuracy: 0.9168\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1237 - accuracy: 0.9651 - val_loss: 0.3489 - val_accuracy: 0.9180\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1132 - accuracy: 0.9687 - val_loss: 0.3459 - val_accuracy: 0.9188\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1108 - accuracy: 0.9700 - val_loss: 0.3463 - val_accuracy: 0.9193\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1037 - accuracy: 0.9729 - val_loss: 0.3467 - val_accuracy: 0.9195\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1020 - accuracy: 0.9716 - val_loss: 0.3546 - val_accuracy: 0.9170\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 96s 62ms/step - loss: 0.1035 - accuracy: 0.9714 - val_loss: 0.3557 - val_accuracy: 0.9184\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1046 - accuracy: 0.9712 - val_loss: 0.3543 - val_accuracy: 0.9171\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.1033 - accuracy: 0.9731 - val_loss: 0.3638 - val_accuracy: 0.9161\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.0973 - accuracy: 0.9731 - val_loss: 0.3614 - val_accuracy: 0.9177\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.0993 - accuracy: 0.9721 - val_loss: 0.3678 - val_accuracy: 0.9185\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.0969 - accuracy: 0.9731 - val_loss: 0.3669 - val_accuracy: 0.9182\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=[check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ugxY4HEGFuUU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "S85SQ31rFd4I"
   },
   "outputs": [],
   "source": [
    "def export_history_csv(history_, model_name):\n",
    "  since = time.time()\n",
    "  date = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')\n",
    "  data_file = open('./data/19-08-2021/tf_exp_train_{}_{}.csv'.format(model_name, date), mode='w+', newline='', encoding='utf-8')\n",
    "  data_writer = csv.writer(data_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "  data_writer.writerow(['Model','type', 'Dataset', 'Epoch', 'criterion', 'optimizer', 'scheduler','Train_loss', 'Train_acc', \"val_loss\", \"Val_acc\", 'time','Elapse_time','date'])\n",
    "  for epoch_ in history_.epoch:\n",
    "    data_writer.writerow([history_.model,'tensorflow', 'hymenoptera', epoch_, '', \n",
    "                          history_.model.optimizer, '',history_.history['loss'][epoch_], history_.history['accuracy'][epoch_], \n",
    "                          history_.history['val_loss'][epoch_], history_.history['val_accuracy'][epoch_], '','',date])\n",
    "  data_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history.history\n",
    "model_name = 'resnet50-cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dBALmsy7Fkz9"
   },
   "outputs": [],
   "source": [
    "export_history_csv(history, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7WjCmmquoNi",
    "outputId": "2b3ded72-8d09-4bb6-f198-4e53904e6118"
   },
   "outputs": [],
   "source": [
    "date = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')\n",
    "model.save(\"./data/19-08-2021/tf_resnet_cifar10_{}.h5\".format(date))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WxklwBqCuoVq"
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_name = 'resnet50'\n",
    "model_type = 'keras'\n",
    "def save_keras(model, model_type='direct'):\n",
    "  model_json = model.to_json()\n",
    "  with open(\"k_model_{}_{}.json\".format(model_name, model_type), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "  # serialize weights to HDF5\n",
    "  model.save_weights(\"k_model_{}_{}.h5\".format(model_name, model_type))\n",
    "  print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pIlIG_6cuogz",
    "outputId": "2f97c3ee-34f8-480d-df76-6c176183d466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "save_keras(model, 'trained_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HvgiAgjKW9vJ",
    "outputId": "98b3a01b-273d-4c9f-fddc-f0406bd8a8fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf2onnx\n",
      "  Using cached tf2onnx-1.9.1-py3-none-any.whl (398 kB)\n",
      "Requirement already satisfied: numpy>=1.14.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tf2onnx) (1.21.1)\n",
      "Requirement already satisfied: onnx>=1.4.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tf2onnx) (1.8.1)\n",
      "Requirement already satisfied: requests in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tf2onnx) (2.25.1)\n",
      "Collecting flatbuffers~=1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: six in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tf2onnx) (1.16.0)\n",
      "Requirement already satisfied: protobuf in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx>=1.4.1->tf2onnx) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx>=1.4.1->tf2onnx) (3.10.0.0)\n",
      "Requirement already satisfied: setuptools in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from protobuf->onnx>=1.4.1->tf2onnx) (52.0.0.post20210125)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from requests->tf2onnx) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from requests->tf2onnx) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from requests->tf2onnx) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from requests->tf2onnx) (2021.5.30)\n",
      "Installing collected packages: flatbuffers, tf2onnx\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 2.0\n",
      "    Uninstalling flatbuffers-2.0:\n",
      "      Successfully uninstalled flatbuffers-2.0\n",
      "Successfully installed flatbuffers-1.12 tf2onnx-1.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPJTHr4dd1hw",
    "outputId": "979346b9-bc59-46a0-ccea-8bd29d34245e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx==1.8.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (1.8.1)\n",
      "Requirement already satisfied: protobuf in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx==1.8.1) (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx==1.8.1) (1.21.1)\n",
      "Requirement already satisfied: six in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx==1.8.1) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx==1.8.1) (3.10.0.0)\n",
      "Requirement already satisfied: setuptools in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from protobuf->onnx==1.8.1) (52.0.0.post20210125)\n",
      "Requirement already satisfied: onnx_tf in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (1.8.0)\n",
      "Requirement already satisfied: PyYAML in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx_tf) (5.4.1)\n",
      "Requirement already satisfied: onnx>=1.8.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx_tf) (1.8.1)\n",
      "Requirement already satisfied: tensorflow-addons in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx_tf) (0.13.0)\n",
      "Requirement already satisfied: six in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx>=1.8.0->onnx_tf) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx>=1.8.0->onnx_tf) (1.21.1)\n",
      "Requirement already satisfied: protobuf in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx>=1.8.0->onnx_tf) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx>=1.8.0->onnx_tf) (3.10.0.0)\n",
      "Requirement already satisfied: setuptools in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from protobuf->onnx>=1.8.0->onnx_tf) (52.0.0.post20210125)\n",
      "Requirement already satisfied: typeguard>=2.7 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow-addons->onnx_tf) (2.12.1)\n",
      "Requirement already satisfied: onnx_pytorch in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (0.1.3)\n",
      "Collecting onnxruntime\n",
      "  Using cached onnxruntime-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "Requirement already satisfied: torch in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx_pytorch) (1.9.0)\n",
      "Requirement already satisfied: onnx in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx_pytorch) (1.8.1)\n",
      "Requirement already satisfied: numpy in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx_pytorch) (1.21.1)\n",
      "Requirement already satisfied: six in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx->onnx_pytorch) (1.16.0)\n",
      "Requirement already satisfied: protobuf in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx->onnx_pytorch) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx->onnx_pytorch) (3.10.0.0)\n",
      "Requirement already satisfied: flatbuffers in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnxruntime->onnx_pytorch) (1.12)\n",
      "Requirement already satisfied: setuptools in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from protobuf->onnx->onnx_pytorch) (52.0.0.post20210125)\n",
      "Installing collected packages: onnxruntime\n",
      "Successfully installed onnxruntime-1.8.1\n",
      "Requirement already satisfied: pytorch2keras in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (0.2.4)\n",
      "Requirement already satisfied: tensorflow in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from pytorch2keras) (2.2.0)\n",
      "Requirement already satisfied: onnx2keras in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from pytorch2keras) (0.0.24)\n",
      "Requirement already satisfied: keras in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from pytorch2keras) (2.6.0)\n",
      "Requirement already satisfied: torchvision in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from pytorch2keras) (0.10.0)\n",
      "Requirement already satisfied: torch in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from pytorch2keras) (1.9.0)\n",
      "Requirement already satisfied: numpy in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from pytorch2keras) (1.21.1)\n",
      "Requirement already satisfied: onnx in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from pytorch2keras) (1.8.1)\n",
      "Requirement already satisfied: six in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx->pytorch2keras) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx->pytorch2keras) (3.10.0.0)\n",
      "Requirement already satisfied: protobuf in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnx->pytorch2keras) (3.13.0)\n",
      "Requirement already satisfied: setuptools in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from protobuf->onnx->pytorch2keras) (52.0.0.post20210125)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (0.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (3.1.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (2.2.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (1.4.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (0.36.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (1.31.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (2.2.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (1.1.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorflow->pytorch2keras) (1.6.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (3.3.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (1.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (1.21.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (1.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (1.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->pytorch2keras) (3.1.0)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from torchvision->pytorch2keras) (8.3.1)\n",
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx==1.8.1\n",
    "!pip install onnx_tf\n",
    "!pip install onnx_pytorch\n",
    "!pip install pytorch2keras\n",
    "#%tensorflow_version 1.x\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e3iOz_DlfI4x"
   },
   "outputs": [],
   "source": [
    "#Import needed packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from onnx_tf.backend import prepare\n",
    "from __future__ import print_function, division\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.autograd import Variable\n",
    "#from pytorch2keras.converter import pytorch_to_keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Wy4WXBIdf-VW"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ceUlyLYbW948",
    "outputId": "c3335836-fc99-486f-c176-d39cede668d1"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown activation function: Activation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ea8d81d08bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2onnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/resnet_cifar10-v2.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m model_proto, external_tensor_storage = tf2onnx.convert.from_keras(model,\n\u001b[1;32m      4\u001b[0m                 \u001b[0minput_signature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mcustom_op_handlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_rewriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m       if (h5py is not None and\n\u001b[1;32m    205\u001b[0m           (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 206\u001b[0;31m         return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n\u001b[0m\u001b[1;32m    207\u001b[0m                                                 compile)\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     model = model_config_lib.model_from_config(model_config,\n\u001b[0m\u001b[1;32m    184\u001b[0m                                                custom_objects=custom_objects)\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     62\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    171\u001b[0m   \"\"\"\n\u001b[1;32m    172\u001b[0m   \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m   return generic_utils.deserialize_keras_object(\n\u001b[0m\u001b[1;32m    174\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'custom_objects'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         return cls.from_config(\n\u001b[0m\u001b[1;32m    355\u001b[0m             \u001b[0mcls_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             custom_objects=dict(\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m       layer = layer_module.deserialize(layer_config,\n\u001b[0m\u001b[1;32m    493\u001b[0m                                        custom_objects=custom_objects)\n\u001b[1;32m    494\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    171\u001b[0m   \"\"\"\n\u001b[1;32m    172\u001b[0m   \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m   return generic_utils.deserialize_keras_object(\n\u001b[0m\u001b[1;32m    174\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    358\u001b[0m                 list(custom_objects.items())))\n\u001b[1;32m    359\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \"\"\"\n\u001b[0;32m--> 720\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/activations.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/activations.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    530\u001b[0m       \u001b[0mdenote\u001b[0m \u001b[0many\u001b[0m \u001b[0mdefined\u001b[0m \u001b[0mTensorflow\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m   \"\"\"\n\u001b[0;32m--> 532\u001b[0;31m   return deserialize_keras_object(\n\u001b[0m\u001b[1;32m    533\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;31m# In this case we are dealing with a Keras config dictionary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0m\u001b[1;32m    347\u001b[0m         config, module_objects, custom_objects, printable_module_name)\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m   \u001b[0mcls_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown activation function: Activation"
     ]
    }
   ],
   "source": [
    "import tf2onnx\n",
    "model = tf.keras.models.load_model('./data/resnet_cifar10-v2.h5')\n",
    "model_proto, external_tensor_storage = tf2onnx.convert.from_keras(model,\n",
    "                input_signature=None, opset=None, custom_ops=None,\n",
    "                custom_op_handlers=None, custom_rewriter=None,\n",
    "                inputs_as_nchw=None, extra_opset=None, shape_override=None,\n",
    "                 target=None, large_model=False, output_path='keras-{}.onnx'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "whKiZFJSW-JP"
   },
   "outputs": [],
   "source": [
    "onnx_model_keras = onnx.load('keras-{}.onnx'.format(model_name))\n",
    "onnx.checker.check_model(onnx_model_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: onnxruntime 1.8.1\n",
      "Uninstalling onnxruntime-1.8.1:\n",
      "  Successfully uninstalled onnxruntime-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall onnxruntime -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwXuk-b-G1fI",
    "outputId": "26ba0d7e-8759-45c2-dfae-81054210152e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime-gpu\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/e9/20/d3abc772619353da99fef75602931fba0ef24cabea786a4fb8eac7e8794f/onnxruntime_gpu-1.8.1-cp38-cp38-manylinux2014_x86_64.whl\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/e9/20/d3abc772619353da99fef75602931fba0ef24cabea786a4fb8eac7e8794f/onnxruntime_gpu-1.8.1-cp38-cp38-manylinux2014_x86_64.whl\u001b[0m\n",
      "  Downloading onnxruntime_gpu-1.8.1-cp38-cp38-manylinux2014_x86_64.whl (31.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.3 MB 248 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnxruntime-gpu) (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnxruntime-gpu) (1.21.1)\n",
      "Requirement already satisfied: flatbuffers in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from onnxruntime-gpu) (1.12)\n",
      "Requirement already satisfied: six>=1.9 in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from protobuf->onnxruntime-gpu) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /store/travail/opmos/conda/envs/tf-env/lib/python3.8/site-packages (from protobuf->onnxruntime-gpu) (52.0.0.post20210125)\n",
      "Installing collected packages: onnxruntime-gpu\n",
      "Successfully installed onnxruntime-gpu-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxruntime_gpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c870db636efb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0monnxruntime_gpu\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msess_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSessionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime_gpu'"
     ]
    }
   ],
   "source": [
    "import onnxruntime_gpu as ort\n",
    "print(ort.get_device())\n",
    "\n",
    "sess_options = ort.SessionOptions()\n",
    "session = ort.InferenceSession(onnx_model_keras.SerializeToString(), sess_options)\n",
    "onnx_time = timeit.timeit(\"session.run( [session.get_outputs()[1].name], {session.get_inputs()[0].name: test_data} )\", number=7, setup=\"from __main__ import session, test_data\")\n",
    "print(\"LGBM->ONNX (GPU): {}\".format(onnx_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2wBfVp-gXSG"
   },
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession('keras-{}.onnx'.format(model_name))\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: x_test}\n",
    "ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "_c7HlEy29ADN"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # Specify an invalid GPU device\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    k_predict = model.predict(x_test)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFhBGA2TnemC",
    "outputId": "ef4b19f1-80ec-4c8b-e0ed-1305aac119ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.99335539e-05, 1.47037703e-04, 1.41063472e-04, ...,\n",
       "        1.54273861e-04, 1.37313955e-05, 9.70138281e-05],\n",
       "       [5.53062091e-05, 1.23364716e-05, 1.70311505e-05, ...,\n",
       "        2.31776539e-05, 9.99850631e-01, 6.55657595e-06],\n",
       "       [4.76072673e-05, 2.57226147e-05, 2.46316613e-05, ...,\n",
       "        3.05302528e-05, 9.99828339e-01, 9.95226219e-06],\n",
       "       ...,\n",
       "       [7.68784012e-05, 4.31562694e-05, 1.49180996e-04, ...,\n",
       "        5.48096199e-04, 3.66769673e-04, 5.86517308e-05],\n",
       "       [8.87418792e-05, 9.99115407e-01, 1.22546626e-04, ...,\n",
       "        5.05060525e-05, 4.29669053e-05, 1.53407236e-04],\n",
       "       [5.24530733e-05, 4.97290603e-05, 8.08762779e-05, ...,\n",
       "        9.98181343e-01, 1.90178092e-04, 1.80298433e-04]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx2pytorch\n",
      "  Downloading onnx2pytorch-0.3.0-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from onnx2pytorch) (1.9.0)\n",
      "Requirement already satisfied: onnx>=1.6.0 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from onnx2pytorch) (1.10.1)\n",
      "Requirement already satisfied: protobuf in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from onnx>=1.6.0->onnx2pytorch) (3.17.3)\n",
      "Requirement already satisfied: six in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from onnx>=1.6.0->onnx2pytorch) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from onnx>=1.6.0->onnx2pytorch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from onnx>=1.6.0->onnx2pytorch) (1.19.5)\n",
      "Installing collected packages: onnx2pytorch\n",
      "Successfully installed onnx2pytorch-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx2pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "jg2D3Dc7neXR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n"
     ]
    }
   ],
   "source": [
    "#onnx_model = onnx.load(path_to_onnx_model)\n",
    "from onnx2pytorch import ConvertModel\n",
    "pytorch_model = ConvertModel(onnx_model_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "jci0FGn0nd46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvertModel(\n",
       "  (Upsample_Upsample__14:0): Upsample()\n",
       "  (Conv_sequential_1/resnet50/conv1_bn/FusedBatchNormV3:0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (Relu_sequential_1/resnet50/conv1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Pad_sequential_1/resnet50/pool1_pad/Pad:0): Pad()\n",
       "  (MaxPool_sequential_1/resnet50/pool1_pool/MaxPool:0): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv_sequential_1/resnet50/conv2_block1_1_bn/FusedBatchNormV3:0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv2_block1_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv2_block1_2_bn/FusedBatchNormV3:0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv2_block1_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv2_block1_3_bn/FusedBatchNormV3:0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_sequential_1/resnet50/conv2_block1_0_bn/FusedBatchNormV3:0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv2_block1_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv2_block1_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv2_block2_1_bn/FusedBatchNormV3:0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv2_block2_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv2_block2_2_bn/FusedBatchNormV3:0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv2_block2_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv2_block2_3_bn/FusedBatchNormV3:0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv2_block2_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv2_block2_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv2_block3_1_bn/FusedBatchNormV3:0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv2_block3_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv2_block3_2_bn/FusedBatchNormV3:0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv2_block3_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv2_block3_3_bn/FusedBatchNormV3:0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv2_block3_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv2_block3_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv3_block1_1_bn/FusedBatchNormV3:0): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Relu_sequential_1/resnet50/conv3_block1_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv3_block1_2_bn/FusedBatchNormV3:0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv3_block1_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv3_block1_3_bn/FusedBatchNormV3:0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_sequential_1/resnet50/conv3_block1_0_bn/FusedBatchNormV3:0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Add_sequential_1/resnet50/conv3_block1_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv3_block1_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv3_block2_1_bn/FusedBatchNormV3:0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv3_block2_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv3_block2_2_bn/FusedBatchNormV3:0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv3_block2_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv3_block2_3_bn/FusedBatchNormV3:0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv3_block2_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv3_block2_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv3_block3_1_bn/FusedBatchNormV3:0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv3_block3_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv3_block3_2_bn/FusedBatchNormV3:0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv3_block3_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv3_block3_3_bn/FusedBatchNormV3:0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv3_block3_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv3_block3_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv3_block4_1_bn/FusedBatchNormV3:0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv3_block4_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv3_block4_2_bn/FusedBatchNormV3:0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv3_block4_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv3_block4_3_bn/FusedBatchNormV3:0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv3_block4_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv3_block4_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block1_1_bn/FusedBatchNormV3:0): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Relu_sequential_1/resnet50/conv4_block1_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block1_2_bn/FusedBatchNormV3:0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv4_block1_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block1_3_bn/FusedBatchNormV3:0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_sequential_1/resnet50/conv4_block1_0_bn/FusedBatchNormV3:0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Add_sequential_1/resnet50/conv4_block1_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv4_block1_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block2_1_bn/FusedBatchNormV3:0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv4_block2_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block2_2_bn/FusedBatchNormV3:0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv4_block2_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block2_3_bn/FusedBatchNormV3:0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv4_block2_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv4_block2_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block3_1_bn/FusedBatchNormV3:0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv4_block3_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block3_2_bn/FusedBatchNormV3:0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv4_block3_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block3_3_bn/FusedBatchNormV3:0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv4_block3_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv4_block3_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block4_1_bn/FusedBatchNormV3:0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv4_block4_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block4_2_bn/FusedBatchNormV3:0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv4_block4_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block4_3_bn/FusedBatchNormV3:0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv4_block4_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv4_block4_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block5_1_bn/FusedBatchNormV3:0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv4_block5_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block5_2_bn/FusedBatchNormV3:0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv4_block5_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block5_3_bn/FusedBatchNormV3:0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv4_block5_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv4_block5_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block6_1_bn/FusedBatchNormV3:0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv4_block6_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block6_2_bn/FusedBatchNormV3:0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv4_block6_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv4_block6_3_bn/FusedBatchNormV3:0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv4_block6_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv4_block6_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv5_block1_1_bn/FusedBatchNormV3:0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Relu_sequential_1/resnet50/conv5_block1_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv5_block1_2_bn/FusedBatchNormV3:0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv5_block1_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv5_block1_3_bn/FusedBatchNormV3:0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_sequential_1/resnet50/conv5_block1_0_bn/FusedBatchNormV3:0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Add_sequential_1/resnet50/conv5_block1_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv5_block1_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv5_block2_1_bn/FusedBatchNormV3:0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv5_block2_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv5_block2_2_bn/FusedBatchNormV3:0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv5_block2_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv5_block2_3_bn/FusedBatchNormV3:0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv5_block2_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv5_block2_out/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv5_block3_1_bn/FusedBatchNormV3:0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv5_block3_1_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv5_block3_2_bn/FusedBatchNormV3:0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Relu_sequential_1/resnet50/conv5_block3_2_relu/Relu:0): ReLU(inplace=True)\n",
       "  (Conv_sequential_1/resnet50/conv5_block3_3_bn/FusedBatchNormV3:0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Add_sequential_1/resnet50/conv5_block3_add/add:0): Add()\n",
       "  (Relu_sequential_1/resnet50/conv5_block3_out/Relu:0): ReLU(inplace=True)\n",
       "  (Reshape_sequential_1/flatten_1/Reshape:0): Reshape(shape=[    -1 100352])\n",
       "  (Add_sequential_1/batch_normalization_4/batchnorm/add_1:0): Add()\n",
       "  (MatMul_sequential_1/dense_4/BiasAdd:0): Linear(in_features=100352, out_features=256, bias=True)\n",
       "  (Relu_sequential_1/dense_4/activation/Relu:0): ReLU(inplace=True)\n",
       "  (Add_sequential_1/batch_normalization_5/batchnorm/add_1:0): Add()\n",
       "  (MatMul_sequential_1/dense_5/BiasAdd:0): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (Relu_sequential_1/dense_5/activation_1/Relu:0): ReLU(inplace=True)\n",
       "  (Add_sequential_1/batch_normalization_6/batchnorm/add_1:0): Add()\n",
       "  (MatMul_sequential_1/dense_6/BiasAdd:0): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (Relu_sequential_1/dense_6/activation_2/Relu:0): ReLU(inplace=True)\n",
       "  (Add_sequential_1/batch_normalization_7/batchnorm/add_1:0): Add()\n",
       "  (MatMul_sequential_1/dense_7/BiasAdd:0): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (Softmax_dense_7): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6xevfctndxi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0RyA18hndsH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoJdJKxondiG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-Jzy5R3ndSo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IqXmaFG1gXXr",
    "outputId": "85d64461-5321-4e42-8bc2-30a8c957a43e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Microsoft/MMdnn.git@master\n",
      "  Cloning https://github.com/Microsoft/MMdnn.git (to revision master) to /tmp/pip-req-build-pv5j2iim\n",
      "  Running command git clone -q https://github.com/Microsoft/MMdnn.git /tmp/pip-req-build-pv5j2iim\n",
      "  Resolved https://github.com/Microsoft/MMdnn.git to commit 19562a381c27545984a216eda7591430e274e518\n",
      "Requirement already satisfied: numpy>=1.15.0 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from mmdnn==0.3.1) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from mmdnn==0.3.1) (3.17.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from mmdnn==0.3.1) (1.15.0)\n",
      "Requirement already satisfied: pillow>=6.2.1 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from mmdnn==0.3.1) (8.3.1)\n",
      "Building wheels for collected packages: mmdnn\n",
      "  Building wheel for mmdnn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mmdnn: filename=mmdnn-0.3.1-py2.py3-none-any.whl size=319222 sha256=2dba62263c88e4c80f713448013b1552a122311c9873f1b830cc42d0cfba6bfd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-d93tqrfn/wheels/b5/9e/aa/a165e269d33fa3c6b45bd8f5577d9df11e6c785333cc476628\n",
      "Successfully built mmdnn\n",
      "Installing collected packages: mmdnn\n",
      "Successfully installed mmdnn-0.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/Microsoft/MMdnn.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_FY37ULgXeg",
    "outputId": "6d252ce9-24f4-45a8-a7bb-c20694004878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:168: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:175: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:180: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-08-07 07:50:20.578531: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-08-07 07:50:20.583016: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000194999 Hz\n",
      "2021-08-07 07:50:20.583242: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55971ef72a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-07 07:50:20.583273: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-08-07 07:50:20.586469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-07 07:50:20.762713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-07 07:50:20.764800: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55971ef73b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-07 07:50:20.764837: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2021-08-07 07:50:20.765752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-07 07:50:20.766476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-08-07 07:50:20.778073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-07 07:50:20.987850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-07 07:50:21.078018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-07 07:50:21.094506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-07 07:50:21.327175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-07 07:50:21.477495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-07 07:50:21.978618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-07 07:50:21.978807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-07 07:50:21.979539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-07 07:50:21.980075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-08-07 07:50:21.980152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-07 07:50:21.981337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-07 07:50:21.981368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-08-07 07:50:21.981380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-08-07 07:50:21.981496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-07 07:50:21.982072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-07 07:50:21.982659: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-08-07 07:50:21.982702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:184: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:193: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:200: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1801: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:127: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3661: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3665: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102858752/102853048 [==============================] - 2s 0us/step\n",
      "Keras model resnet50 is saved in [./imagenet_resnet50.h5]\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:89: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mmdownload -f keras -n resnet50 -o ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_aWz121GvND",
    "outputId": "63c0521d-6c25-4434-e9f8-c1d594827e70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement cntk (from versions: none)\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for cntk\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install cntk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fh0TfNYRBhsN",
    "outputId": "d9491159-5a79-49a0-e393-4bb527c904c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras-nightly 2.5.0.dev2021032900\n",
      "Uninstalling keras-nightly-2.5.0.dev2021032900:\n",
      "  Successfully uninstalled keras-nightly-2.5.0.dev2021032900\n",
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
      "Collecting keras==2.1.6\n",
      "  Using cached Keras-2.1.6-py2.py3-none-any.whl (339 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from keras==2.1.6) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from keras==2.1.6) (1.19.5)\n",
      "Requirement already satisfied: h5py in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from keras==2.1.6) (3.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from keras==2.1.6) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from keras==2.1.6) (5.4.1)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.6.0\n",
      "    Uninstalling keras-2.6.0:\n",
      "      Successfully uninstalled keras-2.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch2keras 0.2.4 requires tensorflow, which is not installed.\u001b[0m\n",
      "Successfully installed keras-2.1.6\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.15.0 (from versions: 2.5.0rc0, 2.5.0rc1, 2.5.0rc2, 2.5.0rc3, 2.5.0, 2.5.1, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow==1.15.0\u001b[0m\n",
      "Collecting h5py==2.10.0\n",
      "  Using cached h5py-2.10.0.tar.gz (301 kB)\n",
      "Requirement already satisfied: numpy>=1.7 in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from h5py==2.10.0) (1.19.5)\n",
      "Requirement already satisfied: six in /store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages (from h5py==2.10.0) (1.15.0)\n",
      "Building wheels for collected packages: h5py\n",
      "  Building wheel for h5py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for h5py: filename=h5py-2.10.0-cp39-cp39-linux_x86_64.whl size=1265349 sha256=50d6b86395acd48ee6f8e3c77a9517152ac4779b4674b89dd94d215c711f3c25\n",
      "  Stored in directory: /home/usagers/opmos/.cache/pip/wheels/91/57/54/aa5901c840e89c1e931141d848b27421f68ad98bd285cc4036\n",
      "Successfully built h5py\n",
      "Installing collected packages: h5py\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "Successfully installed h5py-2.10.0\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-gpu==1.15 (from versions: 2.5.0rc0, 2.5.0rc1, 2.5.0rc2, 2.5.0rc3, 2.5.0, 2.5.1, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow-gpu==1.15\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow --upgrade --force-reinstall\n",
    "!pip3 uninstall keras-nightly -y \n",
    "!pip3 uninstall -y tensorflow -y\n",
    "!pip3 install keras==2.1.6\n",
    "!pip3 install tensorflow==1.15.0\n",
    "!pip3 install h5py==2.10.0\n",
    "!pip install tensorflow-gpu==1.15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YicOdjmnEmeM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04t9VCBuNoZ_",
    "outputId": "126e1a87-cb00-4254-bfb4-17794d645e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: mmdownload: command not found\n"
     ]
    }
   ],
   "source": [
    "!mmdownload -f keras -n resnet50 -o ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfCYJV5kNodu",
    "outputId": "d11ce250-df1c-4473-fb3b-645f92977620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/store/travail/opmos/conda/envs/tf-gpu/bin/mmconvert\", line 8, in <module>\r\n",
      "    sys.exit(_main())\r\n",
      "  File \"/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/mmdnn/conversion/_script/convert.py\", line 102, in _main\r\n",
      "    ret = convertToIR._convert(ir_args)\r\n",
      "  File \"/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/mmdnn/conversion/_script/convertToIR.py\", line 45, in _convert\r\n",
      "    from mmdnn.conversion.keras.keras2_parser import Keras2Parser\r\n",
      "  File \"/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/mmdnn/conversion/keras/keras2_parser.py\", line 8, in <module>\r\n",
      "    import keras as _keras\r\n",
      "  File \"/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/keras/__init__.py\", line 25, in <module>\r\n",
      "    from keras import models\r\n",
      "  File \"/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/keras/models.py\", line 19, in <module>\r\n",
      "    from keras import backend\r\n",
      "  File \"/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/keras/backend.py\", line 37, in <module>\r\n",
      "    from tensorflow.python.eager.context import get_config\r\n",
      "ImportError: cannot import name 'get_config' from 'tensorflow.python.eager.context' (/store/travail/opmos/conda/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/context.py)\r\n"
     ]
    }
   ],
   "source": [
    "#!mmtoir -f keras -d imagenet_densenet.h5 -n imagenet_densenet.json -w imagenet_densenet.h5\n",
    "!mmconvert -sf keras -iw './data/retrain_resnet50-cifar10-v2.h5' -df pytorch -om retrain_resnet50-cifar10.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eczNpWLnNog1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0-tf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbmXWnpCNolf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AR1AdJXEnCvk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7msW7QfNnC1C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkv6_bkfnC5D"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5qH5E2tnI70"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Normalize the test set same as training set without augmentation\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "gqpmcFqOnJCb",
    "outputId": "54407548-d997-4f74-8034-8e7740858ff4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-acc571558a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m trainset = torchvision.datasets.CIFAR10(\n\u001b[0;32m----> 2\u001b[0;31m     root=opt.dataroot, train=True, download=True, transform=transform_train)\n\u001b[0m\u001b[1;32m      3\u001b[0m trainloader = torch.utils.data.DataLoader(\n\u001b[1;32m      4\u001b[0m     trainset, batch_size=opt.batch_size_train, shuffle=True, num_workers=2)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=opt.dataroot, train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=opt.batch_size_train, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=opt.dataroot, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=opt.batch_size_test, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ukFD7MenJSz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doD7QB-QZl_j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2ZF9_QTZl4F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xv8WSNUNZlzF"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "PkQQyzIRZli9",
    "outputId": "a7203b07-cdcb-491e-f47e-4af20042fce9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-dfe2ab70-433a-4c8e-bbe9-e8621bac9417\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-dfe2ab70-433a-4c8e-bbe9-e8621bac9417\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving imagenet_resnet50.py to imagenet_resnet50.py\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "src = list(files.upload().values())[0]\n",
    "open('/content/drive/MyDrive/Colab Notebooks/07-08-2021/imagenet_resnet50.py','wb').write(src)\n",
    "import imagenet_resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "KIusiBxFZlbD"
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "import numpy as np\n",
    "#MainModel = imp.load_source('MainModel', \"/content/drive/MyDrive/Colab Notebooks/07-08-2021/imagenet_resnet50.py\")\n",
    "#resnet_pytorch_model = torch.load(\"/content/drive/MyDrive/Colab Notebooks/07-08-2021/imagenet_resnet50.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "2ec2maowi-xA"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Normalize the test set same as training set without augmentation\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "aeb78e4f6eec4b6691d61e45bcebc70a",
      "a9bf64ff7cda4d6ba030717718d0aa62",
      "c4b23898cbc6454dac91b38c6ed85a07",
      "18fb5a2ac02a4b80a4744a8fd23ea626",
      "c0d0100dab334ffe8596cc0f218f0d87",
      "11da4e37db334a4e982547780ffdde52",
      "90c10f3cdbfc436bb75a7c829ceef16f",
      "a555261ba8c54370abc803e705bc88a4"
     ]
    },
    "id": "lDbZ5gGEi_AB",
    "outputId": "9f650dd9-eca9-4378-cd9b-1b35beda6b7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to ./\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "rSVquMp4ZlVS"
   },
   "outputs": [],
   "source": [
    "resnet_pytorch_model = pytorch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "aGaz9T4Xlu0N"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "NLhGfdj-sX8G"
   },
   "outputs": [],
   "source": [
    "dataloaders = {'train': trainloader, 'val':testloader}\n",
    "dataset_sizes = {'train': len(trainloader.dataset), 'val':len(testloader.dataset) }\n",
    "class_names = trainloader.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xst-OHhUsXt3",
    "outputId": "750bb8ca-f606-412a-a0be-b862ae9966ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "nHr6rtTNlnXP"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "    date = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')\n",
    "\n",
    "    data_file = open('./data/experiment_train_{}.csv'.format(date), mode='w+', newline='', encoding='utf-8')\n",
    "    data_writer = csv.writer(data_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer.writerow(['Model','type', 'Dataset', 'Epoch', 'criterion', 'optimizer', 'scheduler','Train_loss', 'Train_acc', \"val_loss\", \"Val_acc\", 'time','Elapse_time','date'])\n",
    "\n",
    "    val_acc_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        since_1 = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        #data_writer.writerow(['Model','type', 'Dataset', 'Train_loss', 'Train_acc', \"val_loss\", \"Val_acc\"])\n",
    "        rows = [model, 'pytorch','cifar10','{}/{}'.format(epoch, num_epochs - 1) ,criterion, optimizer, scheduler]\n",
    "        #for phase in ['train', 'val']:\n",
    "        #for i, data in enumerate(trainloader, 0):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            #for inputs, labels in dataloaders[phase]:\n",
    "            for i, data in enumerate(dataloaders[phase], 0):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                   # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        #print(criterion)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    #outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    #loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            rows.append(phase)\n",
    "            rows.append('Loss: {:.4f}'.format(epoch_loss))\n",
    "            rows.append('Acc: {:.4f}'.format(epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        time_elapsed_1 = time.time() - since_1\n",
    "        print()\n",
    "        rows.append(time.time())\n",
    "        rows.append('{:.0f}m {:.0f}s'.format(time_elapsed_1 // 60, time_elapsed_1 % 60))\n",
    "        data_writer.writerow(rows)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    data_writer.writerow(['','', '', '', '', '', \"\", 'Best val Acc: {:4f}'.format(best_acc), time.time(),'Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60),''])\n",
    "\n",
    "    data_file.close()\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tPW0OLalltWv",
    "outputId": "0678bb0f-631b-44d3-8562-63418e4f6100"
   },
   "outputs": [],
   "source": [
    "model.last_linear = nn.Sequential(\n",
    "    nn.BatchNorm1d(2048),\n",
    "    nn.Dropout(p=0.25),\n",
    "    nn.Linear(in_features=2048, out_features=2048),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(in_features=2048, out_features=1103),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the model to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpqyOnCju9fa",
    "outputId": "336d16be-8ee1-4e96-d99a-3dbbde6e0396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t Conv_sequential_1/resnet50/conv1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv2_block1_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv2_block1_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv2_block1_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv2_block1_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv2_block1_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv2_block1_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv2_block1_0_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv2_block1_0_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv2_block2_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv2_block2_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv2_block2_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv2_block2_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv2_block2_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv2_block2_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv2_block3_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv2_block3_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv2_block3_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv2_block3_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv2_block3_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv2_block3_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block1_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block1_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block1_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block1_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block1_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block1_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block1_0_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block1_0_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block2_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block2_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block2_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block2_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block2_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block2_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block3_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block3_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block3_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block3_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block3_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block3_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block4_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block4_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block4_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block4_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv3_block4_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv3_block4_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block1_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block1_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block1_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block1_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block1_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block1_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block1_0_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block1_0_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block2_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block2_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block2_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block2_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block2_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block2_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block3_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block3_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block3_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block3_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block3_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block3_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block4_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block4_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block4_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block4_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block4_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block4_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block5_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block5_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block5_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block5_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block5_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block5_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block6_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block6_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block6_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block6_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv4_block6_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv4_block6_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv5_block1_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv5_block1_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv5_block1_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv5_block1_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv5_block1_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv5_block1_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv5_block1_0_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv5_block1_0_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv5_block2_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv5_block2_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv5_block2_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv5_block2_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv5_block2_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv5_block2_3_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv5_block3_1_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv5_block3_1_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv5_block3_2_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv5_block3_2_bn/FusedBatchNormV3:0.bias\n",
      "\t Conv_sequential_1/resnet50/conv5_block3_3_bn/FusedBatchNormV3:0.weight\n",
      "\t Conv_sequential_1/resnet50/conv5_block3_3_bn/FusedBatchNormV3:0.bias\n",
      "\t MatMul_sequential_1/dense_4/BiasAdd:0.weight\n",
      "\t MatMul_sequential_1/dense_4/BiasAdd:0.bias\n",
      "\t MatMul_sequential_1/dense_5/BiasAdd:0.weight\n",
      "\t MatMul_sequential_1/dense_5/BiasAdd:0.bias\n",
      "\t MatMul_sequential_1/dense_6/BiasAdd:0.weight\n",
      "\t MatMul_sequential_1/dense_6/BiasAdd:0.bias\n",
      "\t MatMul_sequential_1/dense_7/BiasAdd:0.weight\n",
      "\t MatMul_sequential_1/dense_7/BiasAdd:0.bias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#resnet_pytorch_model = resnet_pytorch_model.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = resnet_pytorch_model.parameters()\n",
    "feature_extract = False\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in resnet_pytorch_model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in resnet_pytorch_model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbcUBpJLlnmn",
    "outputId": "573eb473-aeef-4a5e-c42f-d8c3d03ea0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-7db4732892db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_pytorch_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"inception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-02b34463bbbc>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, scheduler, num_epochs, is_inception)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "# Setup the loss fxn\n",
    "model_name = 'resnet50'\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(resnet_pytorch_model, dataloaders, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "MP2Cp7aslnsB"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_ft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-d306b51993ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet_pytorch_model_trained.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_ft' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model_ft.state_dict(), 'resnet_pytorch_model_trained.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BigVxOs-lnwv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Transfer-Learning-Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11da4e37db334a4e982547780ffdde52": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18fb5a2ac02a4b80a4744a8fd23ea626": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a555261ba8c54370abc803e705bc88a4",
      "placeholder": "​",
      "style": "IPY_MODEL_90c10f3cdbfc436bb75a7c829ceef16f",
      "value": " 170499072/? [00:21&lt;00:00, 8030120.38it/s]"
     }
    },
    "90c10f3cdbfc436bb75a7c829ceef16f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a555261ba8c54370abc803e705bc88a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9bf64ff7cda4d6ba030717718d0aa62": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aeb78e4f6eec4b6691d61e45bcebc70a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4b23898cbc6454dac91b38c6ed85a07",
       "IPY_MODEL_18fb5a2ac02a4b80a4744a8fd23ea626"
      ],
      "layout": "IPY_MODEL_a9bf64ff7cda4d6ba030717718d0aa62"
     }
    },
    "c0d0100dab334ffe8596cc0f218f0d87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c4b23898cbc6454dac91b38c6ed85a07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11da4e37db334a4e982547780ffdde52",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0d0100dab334ffe8596cc0f218f0d87",
      "value": 170498071
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
