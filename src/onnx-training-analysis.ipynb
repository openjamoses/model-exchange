{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/Cisco/Fall2021/onnx-exchange/Training/'\n",
    "path_output = '/Volumes/Cisco/Summer2022/onnx-exchange/analysis/Training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['lenet5', 'resnet18', 'vgg', 'lstm', 'gru']\n",
    "frameworks = ['Keras', 'pytorch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_1 = datetime.strptime('2021-10-27-17:16:46',\"%H:%M:%S\")\n",
    "#time_2 = datetime.strptime('2021-10-27-17:16:46',\"%H:%M:%S\")\n",
    "#time_interval = time_2 - time_1\n",
    "#print(time_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_list = []\n",
    "#for i in range(1, 11):\n",
    "#    csv_list.append('_{}.csv'.format(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(path_output+'traiing_validation_metrics_keras.csv', mode='w', newline='',\n",
    "                                  encoding='utf-8')\n",
    "data_writer = csv.writer(data_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#data_writer.writerow(['model','Epoch', 'Training_accuracy', 'Validation_Accuracy', \"Training_Loss\", 'Validation_Loss'])\n",
    "data_writer.writerow(['model','Epoch', 'Metrics', 'Value'])\n",
    "\n",
    "\n",
    "data_train_acc = {}\n",
    "data_valid_acc = {}\n",
    "\n",
    "data_train_loss = {}\n",
    "data_valid_loss = {}\n",
    "for model in models: \n",
    "    list_files = [x for x in os.listdir(path+'Keras/{}'.format(model)) if '.csv' in x]\n",
    "    for i in range(1, 11):\n",
    "        for file_ in list_files:\n",
    "            df = pd.read_csv(path+'Keras/{}/{}'.format(model,file_))\n",
    "            Epoch = df.Epoch.values.tolist()\n",
    "            Train_loss = df.Train_loss.values.tolist()\n",
    "            Train_acc = df.Train_acc.values.tolist()\n",
    "            val_loss = df.val_loss.values.tolist()\n",
    "            Val_acc = df.Val_acc.values.tolist()\n",
    "            Epoch = df.Epoch.values.tolist()\n",
    "            for j in range(len(Epoch)):\n",
    "                if model in data_train_acc.keys(): \n",
    "                    if Epoch[j] in data_train_acc[model].keys():\n",
    "                        data_train_acc[model][Epoch[j]].append(Train_acc[j])\n",
    "                        data_valid_acc[model][Epoch[j]].append(Val_acc[j])\n",
    "                        \n",
    "                        data_train_loss[model][Epoch[j]].append(Train_loss[j])\n",
    "                        data_valid_loss[model][Epoch[j]].append(val_loss[j])\n",
    "                    else:\n",
    "                        data_train_acc[model][Epoch[j]] = [Train_acc[j]]\n",
    "                        data_valid_acc[model][Epoch[j]] = [Val_acc[j]]\n",
    "                        \n",
    "                        data_train_loss[model][Epoch[j]] = [Train_loss[j]]\n",
    "                        data_valid_loss[model][Epoch[j]] = [val_loss[j]]\n",
    "                else:\n",
    "                    data_train_acc[model] = {}\n",
    "                    data_train_acc[model][Epoch[j]] = [Train_acc[j]]\n",
    "                    \n",
    "                    data_valid_acc[model] = {}\n",
    "                    data_valid_acc[model][Epoch[j]] = [Val_acc[j]]\n",
    "                    \n",
    "                    data_train_loss[model] = {}\n",
    "                    data_train_loss[model][Epoch[j]] = [Train_loss[j]]\n",
    "                    \n",
    "                    data_valid_loss[model] = {}\n",
    "                    data_valid_loss[model][Epoch[j]] = [val_loss[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_, val in data_train_acc.items():\n",
    "    for epoch_, val2 in val.items():\n",
    "        #data_writer.writerow([model_, epoch_, np.mean(val2), np.mean(data_valid_acc[model_][epoch_]), np.mean(data_train_loss[model_][epoch_]), np.mean(data_valid_loss[model_][epoch_])])\n",
    "        data_writer.writerow([model_, epoch_, 'Training', np.mean(val2)])\n",
    "        data_writer.writerow([model_, epoch_, 'Validation', np.mean(data_valid_acc[model_][epoch_])])\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(path_output+'traiing_validation_metrics_pytorch.csv', mode='w', newline='',\n",
    "                                  encoding='utf-8')\n",
    "data_writer = csv.writer(data_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#data_writer.writerow(['model','Epoch', 'Training_accuracy', 'Validation_Accuracy', \"Training_Loss\", 'Validation_Loss'])\n",
    "data_writer.writerow(['model','Epoch', 'Metrics', 'Value'])\n",
    "\n",
    "\n",
    "data_train_acc = {}\n",
    "data_valid_acc = {}\n",
    "\n",
    "data_train_loss = {}\n",
    "data_valid_loss = {}\n",
    "for model in models: \n",
    "    list_files = [x for x in os.listdir(path+'pytorch/{}'.format(model)) if '.csv' in x]\n",
    "    for i in range(1, 11):\n",
    "        for file_ in list_files:\n",
    "            df = pd.read_csv(path+'pytorch/{}/{}'.format(model,file_))\n",
    "            Epoch = df.Epoch.values.tolist()\n",
    "            Train_loss = df.Train_loss.values.tolist()\n",
    "            Train_acc = df.Train_acc.values.tolist()\n",
    "            val_loss = df.val_loss.values.tolist()\n",
    "            Val_acc = df.Val_acc.values.tolist()\n",
    "            #Epoch = df.Epoch.values.tolist()\n",
    "            #print(file_)\n",
    "            for j in range(len(Epoch)):\n",
    "                train_val = float(str(Train_acc[j]).replace('Acc: ', ''))\n",
    "                valid_val = float(str(Val_acc[j]).replace('Acc: ', ''))\n",
    "                if model in data_train_acc.keys(): \n",
    "                    \n",
    "                    if j in data_train_acc[model].keys():\n",
    "                        data_train_acc[model][j].append(train_val)\n",
    "                        data_valid_acc[model][j].append(valid_val)\n",
    "                        \n",
    "                        data_train_loss[model][j].append(Train_loss[j])\n",
    "                        data_valid_loss[model][j].append(val_loss[j])\n",
    "                    else:\n",
    "                        data_train_acc[model][j] = [train_val]\n",
    "                        data_valid_acc[model][j] = [valid_val]\n",
    "                        \n",
    "                        data_train_loss[model][j] = [Train_loss[j]]\n",
    "                        data_valid_loss[model][j] = [val_loss[j]]\n",
    "                else:\n",
    "                    data_train_acc[model] = {}\n",
    "                    data_train_acc[model][j] = [train_val]\n",
    "                    \n",
    "                    data_valid_acc[model] = {}\n",
    "                    data_valid_acc[model][j] = [valid_val]\n",
    "                    \n",
    "                    data_train_loss[model] = {}\n",
    "                    data_train_loss[model][j] = [Train_loss[j]]\n",
    "                    \n",
    "                    data_valid_loss[model] = {}\n",
    "                    data_valid_loss[model][j] = [val_loss[j]]\n",
    "                    \n",
    "for model_, val in data_train_acc.items():\n",
    "    for epoch_, val2 in val.items():\n",
    "        #print(val2)\n",
    "        #data_writer.writerow([model_, epoch_, np.mean(val2), np.mean(data_valid_acc[model_][epoch_]), np.mean(data_train_loss[model_][epoch_]), np.mean(data_valid_loss[model_][epoch_])])\n",
    "        data_writer.writerow([model_, epoch_, 'Training', np.mean(val2)])\n",
    "        data_writer.writerow([model_, epoch_, 'Validation', np.mean(data_valid_acc[model_][epoch_])])\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = {'lenet5': 'LeNet-5', 'resnet18':'ResNet-18', 'vgg': 'VGG', 'lstm': 'LSTM', 'gru':'GRU'}\n",
    "framework_obj = {'pytorch': 'PyTorch', 'Keras':'Keras'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(path_output+'metrics_training_std.csv', mode='w', newline='',\n",
    "                                  encoding='utf-8')\n",
    "data_writer = csv.writer(data_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#data_writer.writerow(['model','Epoch', 'Training_accuracy', 'Validation_Accuracy', \"Training_Loss\", 'Validation_Loss'])\n",
    "data_writer.writerow(['model','Epoch', 'Framework', 'Framework_mean','Framework_std', 'Value', 'std'])\n",
    "\n",
    "data_file2 = open(path_output+'metrics_validation_std.csv', mode='w', newline='',\n",
    "                                  encoding='utf-8')\n",
    "data_writer2 = csv.writer(data_file2, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#data_writer.writerow(['model','Epoch', 'Training_accuracy', 'Validation_Accuracy', \"Training_Loss\", 'Validation_Loss'])\n",
    "data_writer2.writerow(['model','Epoch', 'Framework','Framework_mean','Framework_std', 'Value', 'std'])\n",
    "\n",
    "\n",
    "for framework in frameworks:\n",
    "    data_train_acc = {}\n",
    "    data_valid_acc = {}\n",
    "    for model in models: \n",
    "        list_files = [x for x in os.listdir(path+'{}/{}'.format(framework, model)) if '.csv' in x]\n",
    "        for i in range(1, 11):\n",
    "            for file_ in list_files:\n",
    "                if '_{}.csv'.format(i) in file_:\n",
    "                    df = pd.read_csv(path+'{}/{}/{}'.format(framework,model,file_))\n",
    "                    Epoch = df.Epoch.values.tolist()\n",
    "                    Train_loss = df.Train_loss.values.tolist()\n",
    "                    Train_acc = df.Train_acc.values.tolist()\n",
    "                    val_loss = df.val_loss.values.tolist()\n",
    "                    Val_acc = df.Val_acc.values.tolist()\n",
    "                    #Epoch = df.Epoch.values.tolist()\n",
    "                    #print(file_)\n",
    "                    for j in range(len(Epoch)):\n",
    "                        train_val = float(str(Train_acc[j]).replace('Acc: ', ''))\n",
    "                        valid_val = float(str(Val_acc[j]).replace('Acc: ', ''))\n",
    "                        if model in data_train_acc.keys(): \n",
    "\n",
    "                            if j in data_train_acc[model].keys():\n",
    "                                data_train_acc[model][j].append(train_val)\n",
    "                                data_valid_acc[model][j].append(valid_val)\n",
    "                            else:\n",
    "                                data_train_acc[model][j] = [train_val]\n",
    "                                data_valid_acc[model][j] = [valid_val]\n",
    "\n",
    "                        else:\n",
    "                            data_train_acc[model] = {}\n",
    "                            data_train_acc[model][j] = [train_val]\n",
    "\n",
    "                            data_valid_acc[model] = {}\n",
    "                            data_valid_acc[model][j] = [valid_val]\n",
    "\n",
    "    for model_, val in data_train_acc.items():\n",
    "        for epoch_, val2 in val.items():\n",
    "            #print(val2)\n",
    "            #data_writer.writerow([model_, epoch_, np.mean(val2), np.mean(data_valid_acc[model_][epoch_]), np.mean(data_train_loss[model_][epoch_]), np.mean(data_valid_loss[model_][epoch_])])\n",
    "            \n",
    "            #model_ = model_obj.get(model_)\n",
    "            #framework = framework_obj.get(framework)\n",
    "            data_writer.writerow([model_obj.get(model_), epoch_+1, framework_obj.get(framework), framework_obj.get(framework)+' (mean)', framework_obj.get(framework)+' (std)', np.mean(val2), np.std(val2)])\n",
    "            data_writer2.writerow([model_obj.get(model_), epoch_+1, framework_obj.get(framework),framework_obj.get(framework)+' (mean)', framework_obj.get(framework)+' (std)', np.mean(data_valid_acc[model_][epoch_]), np.std(data_valid_acc[model_][epoch_])])\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
