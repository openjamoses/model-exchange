{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7ff474ce6d90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "#Import needed packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from onnx_tf.backend import prepare\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.autograd import Variable\n",
    "#from pytorch2keras.converter import pytorch_to_keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "from pathlib import Path\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# used for Alexnet\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 128\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform_train)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform_test)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "     num_workers=num_workers)\n",
    "#valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "#    sampler=valid_sampler, num_workers=num_workers)\n",
    "valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# specify the image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform)\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "# define samplers for obtaining training and validation batches\n",
    "#train_sampler = SubsetRandomSampler(train_idx)\n",
    "#valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "     num_workers=num_workers)\n",
    "#valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "#    sampler=valid_sampler, num_workers=num_workers)\n",
    "valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# specify the image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_id = 1\n",
    "model_short_name = 'vgg'\n",
    "framework = 'pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515298923"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Volumes/Cisco/Fall2021/onnx-exchange/Training/{}/{}/'.format(framework, model_short_name)\n",
    "\n",
    "# Model class must be defined somewhere\n",
    "since_0 = time.time()\n",
    "model_name = 'torch_exp_vgg_2021-11-03_{}'.format(training_id)\n",
    "model = torch.load(path+model_name+'.pth', map_location=torch.device('cpu'))\n",
    "#resnet50_model.eval()\n",
    "t_elapsed_0 = time.time() - since_0\n",
    "size0 = os.path.getsize(path+model_name+'.pth')\n",
    "size0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 1.0.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:TensorFlow version 2.5.0 detected. Last version known to be fully compatible is 2.3.1 .\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "import coremltools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/onnx/'\n",
    "coreml_path = '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/coremltools/'\n",
    "error_path = '/Volumes/Cisco/Fall2021/onnx-exchange/miss-classification/errors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "def model_scores(y_test, test_predict):\n",
    "    correct_ = np.sum(y_test == test_predict)\n",
    "    accuracy  = correct_*100./np.sum(y_test == y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onnx(i, x, y, data_writer_run, batch_size):\n",
    "    \n",
    "    # Input to the model\n",
    "    #device_reset = cuda.get_current_device()\n",
    "    #device_reset.reset()\n",
    "    #x.cuda()\n",
    "    print(\"converting for batch: \", i)\n",
    "    \n",
    "    #torch.random.manual_seed(42)\n",
    "    #x = torch.randn(10000, 3, 32, 32, requires_grad=True)\n",
    "    traced_model = torch.jit.trace(model, x)\n",
    "    \n",
    "    ### Original Model\n",
    "    since_1 = time.time()\n",
    "    torch_out = model(x)\n",
    "    inference_time_original = time.time() - since_1\n",
    "    y0 = torch.argmax(torch_out,1)\n",
    "    accuracy_original = model_scores(to_numpy(y), to_numpy(y0))\n",
    "    # ONNX Model\n",
    "    \n",
    "    t_elapsed_2 = time.time() - since_1\n",
    "    since_1 = time.time()\n",
    "    onnx_model = onnx.load(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    load_time_onnx = time.time() - since_1\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    size_onnx = os.path.getsize(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    #def to_numpy(tensor):\n",
    "    #    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    ort_session = onnxruntime.InferenceSession(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    since_1 = time.time()\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    inference_time_onnx = time.time() - since_1\n",
    "    # compare ONNX Runtime and PyTorch results\n",
    "    print(\"\\n*********\\n\\n\")\n",
    "    #time_diff = t_elapsed_0+t_elapsed_1, t_elapsed_2, t_elapsed_3\n",
    "    \n",
    "    ####### Mis-classification ONNX ######################################\n",
    "    ort_outs_tensor = torch.from_numpy(ort_outs[0]) \n",
    "    y2 = torch.argmax(ort_outs_tensor,1)\n",
    "    #y2 = to_categorical(np.argmax(ort_outs[0], 1), num_classes = 10)\n",
    "    #correct_onnx = np.sum(y2 == y)\n",
    "    accuracy_onnx = model_scores(to_numpy(y), to_numpy(y2))\n",
    "    miss_perc_val_original_runtime = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(to_numpy(torch_out), ort_outs[0])\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        flag = 0\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                miss_perc_val_original_runtime = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                flag += 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            print('Error onnx0: ', e)\n",
    "    encoded_miss_perc_val_original_onnx = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(to_numpy(y0), to_numpy(y2))\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        flag = 0\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                encoded_miss_perc_val_original_onnx = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                flag += 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            print('Error onnx1: ', e)\n",
    "    \n",
    "    miss_perc_val_test_runtime = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(to_numpy(y), to_numpy(y2))\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        flag = 0\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                miss_perc_val_test_runtime = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                flag += 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            print('Error onnx2: ', e)\n",
    "    ####### End of mis-classification ONNX ###################################### \n",
    "    \n",
    "    \n",
    "    ## CoreML\n",
    "    \n",
    "    ## Converting the coremltool\n",
    "    since_1 = time.time()\n",
    "    # Using image_input in the inputs parameter:\n",
    "    # Convert to Core ML using the Unified Conversion API.\n",
    "    coreml_model = coremltools.convert(traced_model,inputs=[coremltools.TensorType(shape=x.shape)])\n",
    "    t_conversion_time_coreml = time.time() - since_1\n",
    "    since_1 = time.time()\n",
    "    coreml_model.save(coreml_path+framework+'/{}/{}-v2.mlmodel'.format(model_short_name, model_name))\n",
    "    t_saving_time_coreml = time.time() - since_1\n",
    "    \n",
    "    \n",
    "    #print(name_1)\n",
    "\n",
    "    size_coreml = os.path.getsize(coreml_path+framework+'/{}/{}-v2.mlmodel'.format(model_short_name, model_name))\n",
    "    \n",
    "    \n",
    "    since_1 = time.time()\n",
    "    coreml_model = coremltools.models.MLModel(coreml_path+framework+\"/{}/{}-v2.mlmodel\".format(model_short_name, model_name))\n",
    "    load_time_coreml = time.time() - since_1\n",
    "    \n",
    "    #spec = coreml_model.get_spec()\n",
    "    #coreml_model = coremltools.models.MLModel(spec)\n",
    "    name_1 = coreml_model.get_spec().description.input[0].name\n",
    "    since_1 = time.time()\n",
    "    output_dict_test = coreml_model.predict({name_1:to_numpy(x)})\n",
    "    inference_time_coreml = time.time() - since_1\n",
    "    ####### Mis-classification coreML ######################################\n",
    "    coreml_array_output = output_dict_test[list(output_dict_test.keys())[0]]\n",
    "    output_tensor = torch.from_numpy(coreml_array_output) \n",
    "    y3 = torch.argmax(output_tensor,1)\n",
    "    #correct_coreml = np.sum(to_numpy(y3) == to_numpy(y))\n",
    "    accuracy_coreml = model_scores(to_numpy(y3), to_numpy(y))\n",
    "    \n",
    "    #print(correct_original, correct_coreml, correct_onnx, np.sum(y == y))\n",
    "    ## Part 1\n",
    "    \n",
    "    miss_perc_val_original_runtime2 = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(to_numpy(torch_out), coreml_array_output)\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        flag = 0\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                miss_perc_val_original_runtime2 = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                flag += 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            print('Error coreml0: ', e)\n",
    "    \n",
    "    ####### Part 2\n",
    "    #print('default-shape: ',k_predict.shape, 'onnx-shape: ',ort_outs[0].shape, 'coreml-shape: ',output_dict_test['Identity'].shape)\n",
    "    miss_perc_val_original_coreml = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(to_numpy(y0), to_numpy(y3))\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        flag = 0\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                miss_perc_val_original_coreml = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                flag += 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            print('Error coreml1: ', e)\n",
    "    miss_perc_val_test_runtime2 = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(to_numpy(y), to_numpy(y3))\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        flag = 0\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                miss_perc_val_test_runtime2 = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                flag += 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            print('Error coreml2: ', e)\n",
    "    ####### End of mis-classification coreML ######################################\n",
    "    data_writer_run.writerow([model_short_name, framework, training_id, model_name, batch_size, i,'onnx',size0, size_onnx,t_elapsed_0, inference_time_original,'', '', load_time_onnx, \n",
    "                          inference_time_onnx,  miss_perc_val_original_runtime,'',  encoded_miss_perc_val_original_onnx, miss_perc_val_test_runtime, '', accuracy_original, accuracy_onnx])\n",
    "\n",
    "\n",
    "    data_writer_run.writerow([model_short_name, framework, training_id, model_name, batch_size, i,'coremltools',size0, size_coreml,t_elapsed_0, inference_time_original,t_conversion_time_coreml, t_saving_time_coreml, load_time_coreml, \n",
    "                          inference_time_coreml,  miss_perc_val_original_runtime2,'',  miss_perc_val_original_coreml, miss_perc_val_test_runtime2, '', accuracy_original, accuracy_coreml])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lets_convert(data,  data_writer_run, batch_size): # for cifar10 etc\n",
    "    since = time.time()\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        to_onnx(i, images,labels, data_writer_run, batch_size)\n",
    "        if i == 50: \n",
    "            break\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Conversion complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ Batch size:  128\n",
      "converting for batch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/onnx/pytorch/vgg/torch_exp_vgg_2021-11-03_1.onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f5bcc272e7ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n\u001b[1;32m     13\u001b[0m     num_workers=num_workers)\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0m_lets_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_writer_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#data_writer_acc.writerow([model_short_name,framework, training_id, model_name, batch_size, correct_original, correct_onnx, correct_coreml])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdata_file_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-299f3932f052>\u001b[0m in \u001b[0;36m_lets_convert\u001b[0;34m(data, data_writer_run, batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msince\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mto_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_writer_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-ef1065f1ce27>\u001b[0m in \u001b[0;36mto_onnx\u001b[0;34m(i, x, y, data_writer_run, batch_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mt_elapsed_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msince_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msince_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/{}/{}.onnx\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_short_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mload_time_onnx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msince_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/onnx/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(f, format, load_external_data)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mLoaded\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0mModelProto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     '''\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/onnx/__init__.py\u001b[0m in \u001b[0;36m_load_bytes\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/onnx/pytorch/vgg/torch_exp_vgg_2021-11-03_1.onnx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "if not os.path.exists(error_path+framework+\"/{}\".format(model_short_name)):\n",
    "        Path(error_path+framework+\"/{}\".format(model_short_name)).mkdir(parents=True, exist_ok=True)\n",
    "data_file_run = open(error_path+framework+\"/{}/runtime_miss-classification_{}.csv\".format(model_short_name,model_name), mode='w', newline='',\n",
    "                                  encoding='utf-8')\n",
    "data_writer_run = csv.writer(data_file_run, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "data_writer_run.writerow(['model','framework', 'training_id', 'model_full', \"batch_size\", 'round','runtime','original_memory_size', 'runtime_memory_size','original_load_time', 'original_infererence_time','runtime_conversion_time', 'runtime_saving_time', 'runtime_load_time', \n",
    "                          'runtime_inference_time',  'miss_classified_original_runtime_percentage','',  'encoded_miss_classified_original_runtime_percentage','encoded_miss_classified_original_test_runtime_percentage', '', 'accuracy_original', 'accuracy_runtime'])\n",
    "\n",
    "for batch_size in [128]:\n",
    "    print(\"################ Batch size: \", batch_size)\n",
    "    valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "    _lets_convert(valloader, data_writer_run, batch_size)\n",
    "    #data_writer_acc.writerow([model_short_name,framework, training_id, model_name, batch_size, correct_original, correct_onnx, correct_coreml])\n",
    "data_file_run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
