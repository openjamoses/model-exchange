{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f9f4a013050>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "#Import needed packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from onnx_tf.backend import prepare\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.autograd import Variable\n",
    "#from pytorch2keras.converter import pytorch_to_keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# used for Alexnet\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 128\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform_train)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform_test)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "     num_workers=num_workers)\n",
    "#valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "#    sampler=valid_sampler, num_workers=num_workers)\n",
    "valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# specify the image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform)\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "# define samplers for obtaining training and validation batches\n",
    "#train_sampler = SubsetRandomSampler(train_idx)\n",
    "#valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "     num_workers=num_workers)\n",
    "#valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "#    sampler=valid_sampler, num_workers=num_workers)\n",
    "valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# specify the image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( \n",
    "       (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010) \n",
    "    )\n",
    "])\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root= './data', train = True,\n",
    "    download =True, transform = transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root= './data', train = False,\n",
    "    download =True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_id =10\n",
    "model_short_name = 'resnet18'\n",
    "framework = 'pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44813453"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Volumes/Cisco/Fall2021/onnx-exchange/Training/pytorch/resnet18/'\n",
    "\n",
    "# Model class must be defined somewhere\n",
    "since_0 = time.time()\n",
    "model_name = 'torch_exp_resnet_2021-11-06_{}'.format(training_id)\n",
    "model = torch.load(path+model_name+'.pth', map_location=torch.device('cpu'))\n",
    "#resnet50_model.eval()\n",
    "t_elapsed_0 = time.time() - since_0\n",
    "size0 = os.path.getsize(path+model_name+'.pth')\n",
    "size0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44813453"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size1 = os.path.getsize(path+model_name+'.pth')\n",
    "size1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 1.0.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:TensorFlow version 2.5.0 detected. Last version known to be fully compatible is 2.3.1 .\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "import coremltools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/onnx/'\n",
    "coreml_path = '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/coremltools/'\n",
    "error_path = '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/errors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onnx(i, x, data_writer_error, data_writer_error2, data_writer_run, batch_size):\n",
    "    # Input to the model\n",
    "    #device_reset = cuda.get_current_device()\n",
    "    #device_reset.reset()\n",
    "    #x.cuda()\n",
    "   \n",
    "    print(\"converting for batch: \", i)\n",
    "    traced_model = torch.jit.trace(model, x)\n",
    "    #torch.random.manual_seed(42)\n",
    "    #x = torch.randn(10000, 3, 32, 32, requires_grad=True)\n",
    "    since_ = time.time()\n",
    "    since_1 = time.time()\n",
    "    torch_out = model(x)\n",
    "    t_elapsed_1 = time.time() - since_1\n",
    "    \n",
    "    # Export the model\n",
    "    if not os.path.exists(onnx_path+framework+\"/{}\".format(model_short_name)):\n",
    "        os.makedirs(onnx_path+framework+\"/{}\".format(model_short_name))\n",
    "    if not os.path.exists(coreml_path+framework+\"/{}\".format(model_short_name)):\n",
    "        os.makedirs(coreml_path+framework+\"/{}\".format(model_short_name))\n",
    "        \n",
    "    since_1 = time.time()\n",
    "    \n",
    "    since_onnx = time.time()\n",
    "    torch.onnx._export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name),   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  #operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK,\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "    \n",
    "    t_elapsed_2 = time.time() - since_1\n",
    "    \n",
    "    \n",
    "    onnx_model = onnx.load(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    size2 = os.path.getsize(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    #def to_numpy(tensor):\n",
    "    #    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    ort_session = onnxruntime.InferenceSession(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    since_1 = time.time()\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    t_elapsed_3 = time.time() - since_1\n",
    "    t_elapsed_ = time.time() - since_\n",
    "    t_elapsed_onnx = time.time() - since_onnx\n",
    "    # compare ONNX Runtime and PyTorch results\n",
    "    print(\"\\n*********\\n\\n\")\n",
    "    #time_diff = t_elapsed_0+t_elapsed_1, t_elapsed_2, t_elapsed_3\n",
    "    \n",
    "    abs_err = np.absolute(to_numpy(torch_out)-ort_outs[0])\n",
    "    rel_err = np.absolute(to_numpy(torch_out)-ort_outs[0])/ np.absolute(ort_outs[0])\n",
    "    #print('Batch: ', i, abs_err, rel_err)\n",
    "    \n",
    "\n",
    "    \n",
    "    ## Converting the coremltool\n",
    "    since_1 = time.time()\n",
    "    # Using image_input in the inputs parameter:\n",
    "    # Convert to Core ML using the Unified Conversion API.\n",
    "    coreml_model = coremltools.convert(traced_model,inputs=[coremltools.TensorType(shape=x.shape)])\n",
    "    t_elapsed_4 = time.time() - since_1\n",
    "    since_1 = time.time()\n",
    "    coreml_model.save(coreml_path+framework+'/{}/{}.mlmodel'.format(model_short_name, model_name))\n",
    "    t_elapsed_5 = time.time() - since_1\n",
    "    \n",
    "    split_ = str(coreml_model.get_spec().description.input[0]).split('\\n')\n",
    "    name_1 = split_[0].replace('name: \"', '')\n",
    "    name_1 = name_1.replace('\"', '')\n",
    "    #print(name_1)\n",
    "\n",
    "    size3 = os.path.getsize(coreml_path+framework+'/{}/{}.mlmodel'.format(model_short_name, model_name))\n",
    "    \n",
    "    since_1 = time.time()\n",
    "    output_dict_test = coreml_model.predict({name_1:to_numpy(x)})\n",
    "    t_elapsed_6 = time.time() - since_1\n",
    "    t_elapsed2_ = time.time() - since_\n",
    "    \n",
    "    coreml_array_output = output_dict_test[list(output_dict_test.keys())[0]]\n",
    "    abs_err2 = np.absolute(to_numpy(torch_out)-coreml_array_output)\n",
    "    rel_err2 = np.absolute(to_numpy(torch_out)-coreml_array_output)/ np.absolute(coreml_array_output)\n",
    "    \n",
    "    for j in range (len(abs_err)):\n",
    "        for k in range(len(abs_err[j])): \n",
    "            data_writer_error.writerow([model_short_name,framework, training_id, model_name, batch_size, i, abs_err[j][k], rel_err[j][k]])\n",
    "    \n",
    "    \n",
    "    for j in range (len(abs_err2)):\n",
    "        for k in range(len(abs_err2[j])): \n",
    "            data_writer_error2.writerow([model_short_name,framework, training_id, model_name, batch_size, i, abs_err2[j][k], rel_err2[j][k]])\n",
    "      \n",
    "    data_writer_run.writerow([model_short_name, framework, training_id, model_name, batch_size, i,'onnx',size0, size2, t_elapsed_1, t_elapsed_3,  t_elapsed_2,'', t_elapsed_, np.mean(abs_err), np.median(abs_err), np.min(abs_err), np.max(abs_err), np.mean(rel_err), np.median(rel_err), np.min(rel_err), np.max(rel_err)])\n",
    "    data_writer_run.writerow([model_short_name, framework, training_id, model_name, batch_size, i,'coremltools',size0, size3, t_elapsed_1, t_elapsed_6, t_elapsed_4, t_elapsed_5, (t_elapsed2_-t_elapsed_onnx), np.mean(abs_err2), np.median(abs_err2), np.min(abs_err2), np.max(abs_err2), np.mean(rel_err2), np.median(rel_err2), np.min(rel_err2), np.max(rel_err2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lets_convert(data, data_writer_error, data_writer_error2, data_writer_run, batch_size): # for cifar10 etc\n",
    "    since = time.time()\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        to_onnx(i, images,data_writer_error, data_writer_error2, data_writer_run, batch_size)\n",
    "        if i == 5: \n",
    "            break\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Conversion complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'letnet5-keras'\n",
    "import pandas as pd \n",
    "def run_experiment(model_short_name, model_name):\n",
    "    if not os.path.exists(error_path+framework+\"/{}\".format(model_short_name)): \n",
    "        os.makedirs(error_path+framework+\"/{}\".format(model_short_name))\n",
    "\n",
    "    data_file_error = open(error_path + framework+'/{}/onnx_error_metrics_{}.csv'.format(model_short_name, model_name), mode='w', newline='',\n",
    "                                      encoding='utf-8')\n",
    "    data_writer_error = csv.writer(data_file_error, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer_error.writerow(['model','framework', 'training_id', 'model_full', \"batch_size\", 'round','absolute_error', 'relative_error'])\n",
    "\n",
    "\n",
    "    data_file_error2 = open(error_path + framework+'/{}/mlmore_error_metrics_{}.csv'.format(model_short_name, model_name), mode='w', newline='',\n",
    "                                      encoding='utf-8')\n",
    "    data_writer_error2 = csv.writer(data_file_error2, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer_error2.writerow(['model','framework', 'training_id', 'model_full', \"batch_size\", 'round','absolute_error', 'relative_error'])\n",
    "\n",
    "\n",
    "    data_file_run = open(error_path + framework+'/{}/runtime_metrics_{}.csv'.format(model_short_name, model_name), mode='w', newline='',\n",
    "                                      encoding='utf-8')\n",
    "    data_writer_run = csv.writer(data_file_run, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer_run.writerow(['model','framework', 'training_id', 'model_full', \"batch_size\", 'round','converter','original_size', 'converted_size', 'original_infererence_time', 'converted_infererence_time', 'conversion_time', 'saving_converted_time', 'overral_time', 'avg_abs_error', 'median_abs_error', 'min_abs_error', 'max_abs_error','avg_rel_error', 'median_rel_error', 'min_rel_error', 'max_rel_error'])\n",
    "    \n",
    "    #for batch_size in [1, 5,10,20,30,40,50,60,70,80,90,100,128, 150,200, 250,300,350, 400, 450, 500]:\n",
    "    for batch_size in [1, 5,10,50,100,128, 150,200, 250,300,350, 400, 450, 500]:\n",
    "        print(\"################ Batch size: \", batch_size)\n",
    "        #trainloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size)\n",
    "        valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "        \n",
    "        _lets_convert(valloader, data_writer_error, data_writer_error2, data_writer_run, batch_size)\n",
    "    data_file_error.close()\n",
    "    data_file_error2.close()\n",
    "    data_file_run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ Batch size:  1\n",
      "converting for batch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1156.47 ops/s]\n",
      "Running MIL Common passes:   0%|          | 0/33 [00:00<?, ? passes/s]/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:101: UserWarning: Input, 'x.1', of the source model, has been renamed to 'x_1' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:129: UserWarning: Output, '313', of the source model, has been renamed to 'var_313' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 47.40 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 56.13 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 55.46 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1065.89 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 70.51 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 62.75 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 69.85 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 820.14 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 71.62 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 61.84 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 54.98 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1299.79 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 99.60 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 65.16 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 67.49 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1352.78 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 96.38 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 67.50 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 72.40 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 835.72 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 76.18 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 53.63 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:04<00:00, 47.48 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 1m 28s\n",
      "################ Batch size:  5\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 821.59 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 69.80 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 59.80 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 62.67 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 579.72 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 34.75 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 39.45 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:04<00:00, 43.73 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1168.64 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 59.44 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 69.77 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 56.81 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 957.82 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 64.08 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 72.73 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 56.55 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1345.14 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 84.12 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 63.00 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 71.18 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1333.58 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 99.84 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 80.11 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 72.46 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 1m 40s\n",
      "################ Batch size:  10\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1149.95 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 59.60 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 66.92 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 51.64 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 917.80 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 47.52 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 51.93 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 53.45 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1256.01 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 105.06 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 66.76 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 64.43 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 628.47 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 67.78 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 48.06 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:04<00:00, 45.93 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1613.34 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 100.27 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 71.22 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 73.55 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1922.11 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 99.19 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 82.71 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 70.96 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 1m 25s\n",
      "################ Batch size:  50\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 851.38 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 52.45 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 56.18 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 63.40 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1454.31 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 54.51 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 47.81 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 53.88 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 771.95 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 67.05 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 39.78 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:04<00:00, 46.59 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 336.51 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 66.60 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 56.02 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 59.65 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1044.56 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 97.43 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 87.37 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 70.34 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 828.65 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 80.11 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 67.65 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 50.85 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 1m 46s\n",
      "################ Batch size:  100\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 852.68 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 73.15 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 31.11 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 56.93 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 840.91 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 81.82 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 75.25 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 68.55 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 658.46 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 77.21 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 72.36 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 57.94 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1328.27 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 94.41 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 82.54 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 76.86 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 935.99 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 56.11 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 56.89 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 62.58 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1233.72 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 92.10 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 66.09 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 60.94 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 1m 40s\n",
      "################ Batch size:  128\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1180.43 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 91.98 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 44.67 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:05<00:00, 34.47 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 941.05 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 97.65 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 76.31 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 77.86 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 800.63 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 61.42 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 64.57 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 52.98 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1393.63 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 91.51 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 75.82 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 69.14 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1127.19 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 77.71 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 37.45 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 63.68 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 863.95 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 62.09 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 73.61 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 58.61 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 1m 51s\n",
      "################ Batch size:  150\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 750.97 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 77.36 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 60.44 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 58.13 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1096.30 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 74.09 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 65.15 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:04<00:00, 41.84 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1326.15 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 46.93 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 56.40 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 56.44 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1004.79 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 81.21 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 48.97 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 50.37 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 923.60 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 53.57 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 74.05 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 50.86 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1621.02 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 93.11 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 53.36 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 74.59 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 1m 52s\n",
      "################ Batch size:  200\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1285.31 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 83.27 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 64.10 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 77.94 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 796.51 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 92.77 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 65.46 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 68.46 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 862.10 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 63.61 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 62.27 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:04<00:00, 45.74 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1789.62 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 99.58 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 85.20 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 85.40 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 702.56 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 66.69 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 48.07 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 64.74 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1698.10 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 91.67 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 33.78 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 67.88 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 1m 54s\n",
      "################ Batch size:  250\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 537.14 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 69.26 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 47.43 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:04<00:00, 47.29 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1348.06 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 80.61 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 34.98 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 68.20 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 993.64 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 84.24 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 66.77 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 60.46 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 671.59 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 73.45 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 62.64 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 58.12 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1126.71 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 68.79 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 59.51 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 66.43 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 948.44 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 46.12 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 49.28 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 57.51 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 2m 4s\n",
      "################ Batch size:  300\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 872.30 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 68.72 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 49.47 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 57.30 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1239.14 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 88.56 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 47.20 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 65.46 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 355.29 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 34.82 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 31.31 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:05<00:00, 35.33 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 779.85 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 76.10 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 48.97 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 50.79 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1113.39 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 88.25 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 74.23 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 75.07 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1024.82 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 79.14 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 45.29 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:04<00:00, 39.14 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 2m 41s\n",
      "################ Batch size:  350\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 2160.65 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 120.16 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 97.32 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:01<00:00, 108.07 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 2113.37 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 68.10 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 61.25 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 83.12 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1926.98 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 91.31 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 72.92 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 86.21 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 929.10 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 67.08 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 36.92 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 51.53 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 789.03 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 60.36 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 44.94 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 70.23 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 792.06 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 83.77 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 67.55 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 56.84 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 2m 19s\n",
      "################ Batch size:  400\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1431.19 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 79.30 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 77.07 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 77.84 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 694.64 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 55.81 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 45.48 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 53.95 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1032.34 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 67.92 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 56.16 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 54.20 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1032.75 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 66.24 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 46.58 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 58.60 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1886.64 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 97.21 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 56.52 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 75.95 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 513.71 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 54.71 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 58.26 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 66.27 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 2m 44s\n",
      "################ Batch size:  450\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1138.07 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 68.33 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 46.37 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 61.87 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1803.72 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 82.43 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 46.08 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 70.34 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 704.02 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 37.60 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 36.16 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 56.44 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1157.34 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 72.96 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 57.06 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 66.90 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1048.46 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 77.98 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 45.20 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 62.85 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1186.66 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 110.22 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 94.40 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 85.05 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 2m 32s\n",
      "################ Batch size:  500\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 2281.27 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 123.23 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 103.08 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 76.64 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 2352.62 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 113.07 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 76.61 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 87.60 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 887.89 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 83.00 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 51.59 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:04<00:00, 45.34 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 821.09 ops/s] \n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 58.75 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 55.45 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:03<00:00, 52.84 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 1411.79 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 114.30 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 106.32 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 74.49 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 2174.23 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 91.39 passes/s] \n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 86.69 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:02<00:00, 81.06 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 2m 42s\n"
     ]
    }
   ],
   "source": [
    "run_experiment(model_short_name, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, labels) in enumerate(valloader):\n",
    "    x_test = images\n",
    "    y_test = labels\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops: 100%|█████████▉| 210/211 [00:00<00:00, 3039.60 ops/s]\n",
      "Running MIL Common passes:   0%|          | 0/33 [00:00<?, ? passes/s]/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:101: UserWarning: Input, 'x.1', of the source model, has been renamed to 'x_1' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:129: UserWarning: Output, '313', of the source model, has been renamed to 'var_313' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 121.21 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 90.07 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 192/192 [00:01<00:00, 130.13 ops/s]\n"
     ]
    }
   ],
   "source": [
    "# Using image_input in the inputs parameter:\n",
    "# Convert to Core ML using the Unified Conversion API.\n",
    "coreml_model = coremltools.convert(\n",
    "    traced_model,\n",
    "    inputs=[coremltools.TensorType(shape=x_test.shape)]\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ = str(coreml_model.get_spec().description.input[0]).split('\\n')\n",
    "name_1 = split_[0].replace('name: \"', '')\n",
    "name_1 = name_1.replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_short_name = 'vgg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515298923"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Volumes/Cisco/Fall2021/onnx-exchange/Training/pytorch/vgg/'\n",
    "\n",
    "# Model class must be defined somewhere\n",
    "since_0 = time.time()\n",
    "model_name = 'torch_exp_vgg_2021-11-04_{}'.format(training_id)\n",
    "model = torch.load(path+model_name+'.pth', map_location=torch.device('cpu'))\n",
    "#resnet50_model.eval()\n",
    "t_elapsed_0 = time.time() - since_0\n",
    "size0 = os.path.getsize(path+model_name+'.pth')\n",
    "size0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515298923"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size1 = os.path.getsize(path+model_name+'.pth')\n",
    "size1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onnx(i, x, data_writer_error2, data_writer_run, batch_size):\n",
    "    # Input to the model\n",
    "    #device_reset = cuda.get_current_device()\n",
    "    #device_reset.reset()\n",
    "    #x.cuda()\n",
    "   \n",
    "    print(\"converting for batch: \", i)\n",
    "    traced_model = torch.jit.trace(model, x)\n",
    "    #torch.random.manual_seed(42)\n",
    "    #x = torch.randn(10000, 3, 32, 32, requires_grad=True)\n",
    "    since_ = time.time()\n",
    "    since_1 = time.time()\n",
    "    torch_out = model(x)\n",
    "    t_elapsed_1 = time.time() - since_1\n",
    "    \n",
    "    # Export the model\n",
    "    if not os.path.exists(onnx_path+framework+\"/{}\".format(model_short_name)):\n",
    "        os.makedirs(onnx_path+framework+\"/{}\".format(model_short_name))\n",
    "    if not os.path.exists(coreml_path+framework+\"/{}\".format(model_short_name)):\n",
    "        os.makedirs(coreml_path+framework+\"/{}\".format(model_short_name))\n",
    "        \n",
    "    since_1 = time.time()\n",
    "    \n",
    "    '''since_onnx = time.time()\n",
    "     torch.onnx._export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name),   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  #operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK,\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "    \n",
    "    t_elapsed_2 = time.time() - since_1\n",
    "    \n",
    "    \n",
    "    onnx_model = onnx.load(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    size2 = os.path.getsize(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    #def to_numpy(tensor):\n",
    "    #    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    ort_session = onnxruntime.InferenceSession(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    since_1 = time.time()\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    t_elapsed_3 = time.time() - since_1\n",
    "    t_elapsed_ = time.time() - since_\n",
    "    t_elapsed_onnx = time.time() - since_onnx\n",
    "    # compare ONNX Runtime and PyTorch results\n",
    "    print(\"\\n*********\\n\\n\")\n",
    "    #time_diff = t_elapsed_0+t_elapsed_1, t_elapsed_2, t_elapsed_3\n",
    "    \n",
    "    abs_err = np.absolute(to_numpy(torch_out)-ort_outs[0])\n",
    "    rel_err = np.absolute(to_numpy(torch_out)-ort_outs[0])/ np.absolute(ort_outs[0])\n",
    "    #print('Batch: ', i, abs_err, rel_err) '''\n",
    "    \n",
    "\n",
    "    \n",
    "    ## Converting the coremltool\n",
    "    since_1 = time.time()\n",
    "    # Using image_input in the inputs parameter:\n",
    "    # Convert to Core ML using the Unified Conversion API.\n",
    "    coreml_model = coremltools.convert(traced_model,inputs=[coremltools.TensorType(shape=x.shape)])\n",
    "    t_elapsed_4 = time.time() - since_1\n",
    "    since_1 = time.time()\n",
    "    coreml_model.save(coreml_path+framework+'/{}/{}.mlmodel'.format(model_short_name, model_name))\n",
    "    t_elapsed_5 = time.time() - since_1\n",
    "    \n",
    "    split_ = str(coreml_model.get_spec().description.input[0]).split('\\n')\n",
    "    name_1 = split_[0].replace('name: \"', '')\n",
    "    name_1 = name_1.replace('\"', '')\n",
    "    #print(name_1)\n",
    "\n",
    "    size3 = os.path.getsize(coreml_path+framework+'/{}/{}.mlmodel'.format(model_short_name, model_name))\n",
    "    \n",
    "    since_1 = time.time()\n",
    "    output_dict_test = coreml_model.predict({name_1:to_numpy(x)})\n",
    "    t_elapsed_6 = time.time() - since_1\n",
    "    t_elapsed2_ = time.time() - since_\n",
    "    \n",
    "    coreml_array_output = output_dict_test[list(output_dict_test.keys())[0]]\n",
    "    abs_err2 = np.absolute(to_numpy(torch_out)-coreml_array_output)\n",
    "    rel_err2 = np.absolute(to_numpy(torch_out)-coreml_array_output)/ np.absolute(coreml_array_output)\n",
    "    \n",
    "    #for j in range (len(abs_err)):\n",
    "    #    for k in range(len(abs_err[j])): \n",
    "    #        data_writer_error.writerow([model_short_name,framework, training_id, model_name, batch_size, i, abs_err[j][k], rel_err[j][k]])\n",
    "    \n",
    "    \n",
    "    for j in range (len(abs_err2)):\n",
    "        for k in range(len(abs_err2[j])): \n",
    "            data_writer_error2.writerow([model_short_name,framework, training_id, model_name, batch_size, i, abs_err2[j][k], rel_err2[j][k]])\n",
    "      \n",
    "    #data_writer_run.writerow([model_short_name, framework, training_id, model_name, batch_size, i,'onnx',size0, size2, t_elapsed_1, t_elapsed_3,  t_elapsed_2,'', t_elapsed_, np.mean(abs_err), np.median(abs_err), np.min(abs_err), np.max(abs_err), np.mean(rel_err), np.median(rel_err), np.min(rel_err), np.max(rel_err)])\n",
    "    data_writer_run.writerow([model_short_name, framework, training_id, model_name, batch_size, i,'coremltools',size0, size3, t_elapsed_1, t_elapsed_6, t_elapsed_4, t_elapsed_5, (t_elapsed2_-t_elapsed_onnx), np.mean(abs_err2), np.median(abs_err2), np.min(abs_err2), np.max(abs_err2), np.mean(rel_err2), np.median(rel_err2), np.min(rel_err2), np.max(rel_err2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lets_convert(data, data_writer_error2, data_writer_run, batch_size): # for cifar10 etc\n",
    "    since = time.time()\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        to_onnx(i, images,data_writer_error2, data_writer_run, batch_size)\n",
    "        if i == 5: \n",
    "            break\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Conversion complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'letnet5-keras'\n",
    "import pandas as pd \n",
    "def run_experiment(model_short_name, model_name):\n",
    "    if not os.path.exists(error_path+framework+\"/{}\".format(model_short_name)): \n",
    "        os.makedirs(error_path+framework+\"/{}\".format(model_short_name))\n",
    "\n",
    "    \n",
    "    data_file_error2 = open(error_path + framework+'/{}/mlmore_error_metrics_{}.csv'.format(model_short_name, model_name), mode='w', newline='',\n",
    "                                      encoding='utf-8')\n",
    "    data_writer_error2 = csv.writer(data_file_error2, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer_error2.writerow(['model','framework', 'training_id', 'model_full', \"batch_size\", 'round','absolute_error', 'relative_error'])\n",
    "\n",
    "\n",
    "    data_file_run = open(error_path + framework+'/{}/runtime_metrics_{}.csv'.format(model_short_name, model_name), mode='w', newline='',\n",
    "                                      encoding='utf-8')\n",
    "    data_writer_run = csv.writer(data_file_run, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer_run.writerow(['model','framework', 'training_id', 'model_full', \"batch_size\", 'round','converter','original_size', 'converted_size', 'original_infererence_time', 'converted_infererence_time', 'conversion_time', 'saving_converted_time', 'overral_time', 'avg_abs_error', 'median_abs_error', 'min_abs_error', 'max_abs_error','avg_rel_error', 'median_rel_error', 'min_rel_error', 'max_rel_error'])\n",
    "    \n",
    "    #for batch_size in [1, 5,10,20,30,40,50,60,70,80,90,100,128, 150,200, 250,300,350, 400, 450, 500]:\n",
    "    for batch_size in [128]:\n",
    "        print(\"################ Batch size: \", batch_size)\n",
    "        #trainloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size)\n",
    "        valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "        \n",
    "        _lets_convert(valloader,data_writer_error2, data_writer_run, batch_size)\n",
    "    data_file_error.close()\n",
    "    data_file_error2.close()\n",
    "    data_file_run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ Batch size:  128\n",
      "converting for batch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Converting Frontend ==> MIL Ops:   0%|          | 0/103 [00:00<?, ? ops/s]/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/ops/defs/_utils.py:248: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  out_shape.append(math.floor((input_shape[r] + pad[r] - effective_ks[r]) / strides[r] + 1))\n",
      "Converting Frontend ==> MIL Ops:  87%|████████▋ | 90/103 [00:00<00:00, 1351.88 ops/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-69c1e9b5efdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_short_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-8b1ebba3c4c4>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model_short_name, model_name)\u001b[0m\n\u001b[1;32m     24\u001b[0m     num_workers=num_workers)\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0m_lets_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_writer_error2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_writer_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mdata_file_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdata_file_error2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-8732c68aeb57>\u001b[0m in \u001b[0;36m_lets_convert\u001b[0;34m(data, data_writer_error2, data_writer_run, batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msince\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mto_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_writer_error2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_writer_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-6ddfd530b30b>\u001b[0m in \u001b[0;36mto_onnx\u001b[0;34m(i, x, data_writer_error2, data_writer_run, batch_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Using image_input in the inputs parameter:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Convert to Core ML using the Unified Conversion API.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mcoreml_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoremltools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraced_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoremltools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mt_elapsed_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msince_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0msince_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/_converters_entry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model, source, inputs, outputs, classifier_config, minimum_deployment_target, convert_to, compute_precision, skip_model_load, compute_units, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mskip_model_load\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_model_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mcompute_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_units\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     )\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36mmil_convert\u001b[0;34m(model, convert_from, convert_to, compute_units, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mcoremltools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_mil_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConverterRegistry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36m_mil_convert\u001b[0;34m(model, convert_from, convert_to, registry, modelClass, compute_units, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                             \u001b[0mconvert_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                             \u001b[0mregistry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m                          )\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36mmil_convert_to_proto\u001b[0;34m(model, convert_from, convert_to, converter_registry, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mfrontend_converter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrontend_converter_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrontend_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconvert_to\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"neuralnetwork\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfrontend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(model_spec, debug, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(model_spec, debug, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"convert function\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/converter.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;31m# Add the rest of the operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mconvert_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mgraph_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/ops.py\u001b[0m in \u001b[0;36mconvert_nodes\u001b[0;34m(context, graph)\u001b[0m\n\u001b[1;32m     68\u001b[0m             )\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# We've generated all the outputs the graph needs, terminate conversion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/ops.py\u001b[0m in \u001b[0;36madaptive_avg_pool2d\u001b[0;34m(context, node)\u001b[0m\n\u001b[1;32m   1092\u001b[0m             \u001b[0mpad_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/ops/registry.py\u001b[0m in \u001b[0;36madd_op\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0madd_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/builder.py\u001b[0m in \u001b[0;36m_add_op\u001b[0;34m(cls, op_cls, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mcurr_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_op_before\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbefore_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_nested_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_value_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/operation.py\u001b[0m in \u001b[0;36mtype_value_inference\u001b[0;34m(self, overwrite_output)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mexisting\u001b[0m \u001b[0m_output_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \"\"\"\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0moutput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0moutput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/ops/defs/pool.py\u001b[0m in \u001b[0;36mtype_inference\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mcustom_pad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mceil_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         )\n\u001b[1;32m     66\u001b[0m         \u001b[0mret_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mD_out_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/ops/defs/_utils.py\u001b[0m in \u001b[0;36mspatial_dimensions_out_shape\u001b[0;34m(pad_type, input_shape, kernel_shape, strides, dilations, custom_pad, ceil_mode)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                 \u001b[0mout_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meffective_ks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0mout_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meffective_ks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "run_experiment(model_short_name, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 224, 224])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(128, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n",
      "      %classifier.0.weight : Float(4096, 25088, strides=[25088, 1], requires_grad=1, device=cpu),\n",
      "      %classifier.0.bias : Float(4096, strides=[1], requires_grad=1, device=cpu),\n",
      "      %classifier.3.weight : Float(4096, 4096, strides=[4096, 1], requires_grad=1, device=cpu),\n",
      "      %classifier.3.bias : Float(4096, strides=[1], requires_grad=1, device=cpu),\n",
      "      %classifier.6.weight : Float(10, 4096, strides=[4096, 1], requires_grad=1, device=cpu),\n",
      "      %classifier.6.bias : Float(10, strides=[1], requires_grad=1, device=cpu),\n",
      "      %100 : Float(64, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %101 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %103 : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %104 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %106 : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %107 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %109 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %110 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %112 : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %113 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %115 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %116 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %118 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %119 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %121 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %122 : Float(512, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %99 : Float(128, 64, 224, 224, strides=[3211264, 50176, 224, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input.1, %100, %101)\n",
      "  %65 : Float(128, 64, 224, 224, strides=[3211264, 50176, 224, 1], requires_grad=1, device=cpu) = onnx::Relu(%99) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1296:0\n",
      "  %66 : Float(128, 64, 112, 112, strides=[802816, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%65) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718:0\n",
      "  %102 : Float(128, 128, 112, 112, strides=[1605632, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%66, %103, %104)\n",
      "  %69 : Float(128, 128, 112, 112, strides=[1605632, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Relu(%102) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1296:0\n",
      "  %70 : Float(128, 128, 56, 56, strides=[401408, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%69) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718:0\n",
      "  %105 : Float(128, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%70, %106, %107)\n",
      "  %73 : Float(128, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Relu(%105) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1296:0\n",
      "  %108 : Float(128, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%73, %109, %110)\n",
      "  %76 : Float(128, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Relu(%108) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1296:0\n",
      "  %77 : Float(128, 256, 28, 28, strides=[200704, 784, 28, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%76) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718:0\n",
      "  %111 : Float(128, 512, 28, 28, strides=[401408, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%77, %112, %113)\n",
      "  %80 : Float(128, 512, 28, 28, strides=[401408, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%111) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1296:0\n",
      "  %114 : Float(128, 512, 28, 28, strides=[401408, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%80, %115, %116)\n",
      "  %83 : Float(128, 512, 28, 28, strides=[401408, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%114) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1296:0\n",
      "  %84 : Float(128, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%83) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718:0\n",
      "  %117 : Float(128, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%84, %118, %119)\n",
      "  %87 : Float(128, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%117) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1296:0\n",
      "  %120 : Float(128, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%87, %121, %122)\n",
      "  %90 : Float(128, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%120) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1296:0\n",
      "  %91 : Float(128, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%90) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718:0\n",
      "  %92 : Float(128, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::AveragePool[kernel_shape=[1, 1], strides=[1, 1]](%91) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1130:0\n",
      "  %93 : Float(128, 25088, strides=[25088, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1](%92) # /opt/anaconda3/lib/python3.7/site-packages/torchvision/models/vgg.py:51:0\n",
      "  %94 : Float(128, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%93, %classifier.0.weight, %classifier.0.bias) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1847:0\n",
      "  %95 : Float(128, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Relu(%94) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1168:0\n",
      "  %96 : Float(128, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%95, %classifier.3.weight, %classifier.3.bias) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1847:0\n",
      "  %97 : Float(128, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Relu(%96) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1168:0\n",
      "  %98 : Float(128, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%97, %classifier.6.weight, %classifier.6.bias) # /opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1847:0\n",
      "  return (%98)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(1, 3, 224, 224))\n",
    "torch.onnx.export(model, x_test, 'vgg16_pytorch.onnx', verbose=True, opset_version=11, operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def torch_pool(inputs, target_size):\n",
    "    start_points = (torch.arange(target_size, dtype=torch.float32) * (inputs.size(-1) / target_size)).long()\n",
    "    end_points = ((torch.arange(target_size, dtype=torch.float32)+1) * (inputs.size(-1) / target_size)).ceil().long()\n",
    "    pooled = []\n",
    "    for idx in range(target_size):\n",
    "        pooled.append(torch.mean(inputs[:, :, start_points[idx]:end_points[idx]], dim=-1, keepdim=False))\n",
    "    pooled = torch.cat(pooled, -1)\n",
    "    pooled = pooled.unsqueeze(0) \n",
    "    return pooled\n",
    "\n",
    "\n",
    "inps = np.array([0, 1, 2, 3, 4, 5, 6], dtype=np.float32)[None, :, None]\n",
    "inps_torch = np.transpose(inps, (0, 2, 1))\n",
    "x = torch_pool(torch.tensor(x_test), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2392,  0.2471,  0.2941,  ...,  0.0745, -0.0118, -0.0902],\n",
       "          [ 0.1922,  0.1843,  0.2471,  ...,  0.0667, -0.0196, -0.0667],\n",
       "          [ 0.1843,  0.1843,  0.2392,  ...,  0.0902,  0.0196, -0.0588],\n",
       "          ...,\n",
       "          [-0.4667, -0.6706, -0.7569,  ..., -0.7020, -0.8980, -0.6863],\n",
       "          [-0.5216, -0.6157, -0.7255,  ..., -0.7961, -0.7725, -0.8431],\n",
       "          [-0.5765, -0.5608, -0.6471,  ..., -0.8118, -0.7333, -0.8353]],\n",
       "\n",
       "         [[-0.1216, -0.1294, -0.0902,  ..., -0.2549, -0.2863, -0.3333],\n",
       "          [-0.1216, -0.1373, -0.1059,  ..., -0.2549, -0.2863, -0.3098],\n",
       "          [-0.1373, -0.1451, -0.1294,  ..., -0.2314, -0.2549, -0.3020],\n",
       "          ...,\n",
       "          [-0.0275, -0.2157, -0.3098,  ..., -0.2392, -0.4980, -0.3333],\n",
       "          [-0.0902, -0.2000, -0.3333,  ..., -0.3569, -0.3569, -0.4980],\n",
       "          [-0.1608, -0.1765, -0.3020,  ..., -0.3961, -0.3412, -0.4745]],\n",
       "\n",
       "         [[-0.6157, -0.6314, -0.6000,  ..., -0.7176, -0.7176, -0.7412],\n",
       "          [-0.6000, -0.6863, -0.6471,  ..., -0.7569, -0.7490, -0.7333],\n",
       "          [-0.6314, -0.7412, -0.7176,  ..., -0.7333, -0.7333, -0.7412],\n",
       "          ...,\n",
       "          [ 0.3882,  0.1608,  0.0745,  ...,  0.1451, -0.1529, -0.0039],\n",
       "          [ 0.3176,  0.1608,  0.0353,  ...,  0.0196, -0.0118, -0.1608],\n",
       "          [ 0.2549,  0.1686,  0.0353,  ..., -0.0275,  0.0118, -0.1373]]],\n",
       "\n",
       "\n",
       "        [[[ 0.8431,  0.8118,  0.8196,  ...,  0.8275,  0.8275,  0.8196],\n",
       "          [ 0.8667,  0.8431,  0.8431,  ...,  0.8510,  0.8510,  0.8431],\n",
       "          [ 0.8588,  0.8353,  0.8353,  ...,  0.8431,  0.8431,  0.8353],\n",
       "          ...,\n",
       "          [-0.3176, -0.6627, -0.8510,  ...,  0.3255,  0.4275,  0.4745],\n",
       "          [-0.3569, -0.6392, -0.7176,  ...,  0.3647,  0.4510,  0.4667],\n",
       "          [-0.3333, -0.5137, -0.5451,  ...,  0.3176,  0.4118,  0.4588]],\n",
       "\n",
       "         [[ 0.8431,  0.8118,  0.8196,  ...,  0.8275,  0.8275,  0.8196],\n",
       "          [ 0.8667,  0.8431,  0.8431,  ...,  0.8510,  0.8510,  0.8431],\n",
       "          [ 0.8588,  0.8353,  0.8353,  ...,  0.8431,  0.8431,  0.8353],\n",
       "          ...,\n",
       "          [-0.2235, -0.6000, -0.8196,  ...,  0.4431,  0.5451,  0.5843],\n",
       "          [-0.2471, -0.5529, -0.6549,  ...,  0.4824,  0.5686,  0.5843],\n",
       "          [-0.2078, -0.4118, -0.4745,  ...,  0.4353,  0.5294,  0.5686]],\n",
       "\n",
       "         [[ 0.8431,  0.8118,  0.8196,  ...,  0.8275,  0.8275,  0.8196],\n",
       "          [ 0.8667,  0.8431,  0.8431,  ...,  0.8510,  0.8510,  0.8431],\n",
       "          [ 0.8588,  0.8353,  0.8353,  ...,  0.8431,  0.8431,  0.8353],\n",
       "          ...,\n",
       "          [-0.3020, -0.7098, -0.9137,  ...,  0.4039,  0.5137,  0.5765],\n",
       "          [-0.3569, -0.7176, -0.8275,  ...,  0.4353,  0.5373,  0.5686],\n",
       "          [-0.3490, -0.6235, -0.7020,  ...,  0.3961,  0.4980,  0.5608]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2392,  0.2392,  0.0902,  ...,  0.7882,  0.8588,  0.8667],\n",
       "          [ 0.3333,  0.3490,  0.1843,  ...,  0.8196,  0.9294,  0.9294],\n",
       "          [ 0.3647,  0.3804,  0.2314,  ...,  0.8039,  0.9608,  0.9216],\n",
       "          ...,\n",
       "          [-0.7569, -0.7647, -0.7961,  ..., -0.7098, -0.9294, -0.9686],\n",
       "          [-0.8196, -0.7882, -0.8039,  ..., -0.8510, -0.9686, -0.9608],\n",
       "          [-0.7804, -0.7647, -0.7490,  ..., -0.9608, -0.9686, -0.9451]],\n",
       "\n",
       "         [[ 0.4902,  0.4667,  0.3020,  ...,  0.8118,  0.8745,  0.8902],\n",
       "          [ 0.5686,  0.5608,  0.3804,  ...,  0.8196,  0.9294,  0.9373],\n",
       "          [ 0.5765,  0.5686,  0.4039,  ...,  0.7961,  0.9529,  0.9137],\n",
       "          ...,\n",
       "          [-0.6863, -0.6941, -0.7255,  ..., -0.6863, -0.8980, -0.9451],\n",
       "          [-0.7333, -0.7020, -0.7176,  ..., -0.8431, -0.9529, -0.9451],\n",
       "          [-0.6784, -0.6627, -0.6471,  ..., -0.9529, -0.9608, -0.9373]],\n",
       "\n",
       "         [[ 0.7412,  0.7098,  0.5216,  ...,  0.8353,  0.9059,  0.9294],\n",
       "          [ 0.7961,  0.7725,  0.5765,  ...,  0.8510,  0.9608,  0.9686],\n",
       "          [ 0.7647,  0.7412,  0.5608,  ...,  0.8196,  0.9686,  0.9373],\n",
       "          ...,\n",
       "          [-0.6471, -0.6549, -0.6863,  ..., -0.6392, -0.8902, -0.9608],\n",
       "          [-0.6941, -0.6627, -0.6784,  ..., -0.8118, -0.9765, -0.9765],\n",
       "          [-0.6314, -0.6078, -0.5922,  ..., -0.9373, -0.9765, -0.9451]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.4667,  0.4510,  0.4510,  ...,  0.2627,  0.2471,  0.2314],\n",
       "          [ 0.4667,  0.4588,  0.4588,  ...,  0.2941,  0.2706,  0.2549],\n",
       "          [ 0.4431,  0.4353,  0.4353,  ...,  0.2941,  0.2706,  0.2549],\n",
       "          ...,\n",
       "          [-0.7882, -0.7333, -0.6627,  ..., -0.5373, -0.4745, -0.4275],\n",
       "          [-0.5294, -0.4980, -0.4588,  ..., -0.5922, -0.5216, -0.5843],\n",
       "          [-0.4824, -0.4902, -0.4667,  ..., -0.6314, -0.5529, -0.5843]],\n",
       "\n",
       "         [[ 0.5059,  0.5059,  0.5059,  ...,  0.3412,  0.3255,  0.3020],\n",
       "          [ 0.5137,  0.5137,  0.5137,  ...,  0.3725,  0.3490,  0.3333],\n",
       "          [ 0.4902,  0.4902,  0.4902,  ...,  0.3647,  0.3490,  0.3255],\n",
       "          ...,\n",
       "          [-0.7725, -0.7176, -0.6392,  ..., -0.5137, -0.4510, -0.3804],\n",
       "          [-0.5137, -0.4824, -0.4353,  ..., -0.5765, -0.5216, -0.5765],\n",
       "          [-0.4824, -0.4745, -0.4510,  ..., -0.6078, -0.5529, -0.5686]],\n",
       "\n",
       "         [[ 0.4510,  0.4431,  0.4431,  ...,  0.2784,  0.2627,  0.2392],\n",
       "          [ 0.4588,  0.4510,  0.4510,  ...,  0.3098,  0.2863,  0.2706],\n",
       "          [ 0.4275,  0.4275,  0.4275,  ...,  0.3020,  0.2863,  0.2627],\n",
       "          ...,\n",
       "          [-0.8510, -0.8039, -0.7647,  ..., -0.6078, -0.5137, -0.4353],\n",
       "          [-0.6784, -0.6627, -0.6392,  ..., -0.6627, -0.6941, -0.7098],\n",
       "          [-0.7020, -0.7098, -0.6941,  ..., -0.6784, -0.6549, -0.6392]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3333,  0.2863,  0.1529,  ...,  0.1373,  0.0902,  0.0353],\n",
       "          [ 0.1608,  0.0275, -0.1059,  ..., -0.2314, -0.2392, -0.3333],\n",
       "          [-0.2157, -0.2549, -0.2392,  ..., -0.2941, -0.4510, -0.4588],\n",
       "          ...,\n",
       "          [ 0.3647,  0.3020, -0.0118,  ..., -0.3020, -0.0039, -0.0039],\n",
       "          [ 0.1294,  0.4667,  0.1137,  ..., -0.3961, -0.2157, -0.0431],\n",
       "          [-0.2627,  0.4431,  0.2392,  ..., -0.5216, -0.5137, -0.4039]],\n",
       "\n",
       "         [[ 0.3647,  0.3333,  0.2157,  ...,  0.3255,  0.2549,  0.1294],\n",
       "          [ 0.2392,  0.1216,  0.0118,  ..., -0.0353, -0.0824, -0.2706],\n",
       "          [-0.0980, -0.1216, -0.0824,  ..., -0.1529, -0.3804, -0.4824],\n",
       "          ...,\n",
       "          [ 0.4039,  0.3882,  0.1216,  ..., -0.3098, -0.0118, -0.0118],\n",
       "          [ 0.1608,  0.5451,  0.2471,  ..., -0.4039, -0.2235, -0.0510],\n",
       "          [-0.2314,  0.5216,  0.3647,  ..., -0.5294, -0.5216, -0.4118]],\n",
       "\n",
       "         [[-0.1686, -0.1922, -0.2941,  ..., -0.2157, -0.2863, -0.2549],\n",
       "          [-0.1373, -0.2314, -0.3176,  ..., -0.3020, -0.3176, -0.4039],\n",
       "          [-0.2706, -0.3098, -0.2863,  ..., -0.2314, -0.4039, -0.4745],\n",
       "          ...,\n",
       "          [ 0.3020,  0.2157, -0.0745,  ..., -0.2471,  0.0510,  0.0510],\n",
       "          [ 0.0824,  0.3882,  0.0667,  ..., -0.3412, -0.1608,  0.0118],\n",
       "          [-0.2784,  0.3961,  0.2078,  ..., -0.4667, -0.4588, -0.3490]]],\n",
       "\n",
       "\n",
       "        [[[-0.9608, -0.9059, -0.9216,  ..., -0.8980, -0.9059, -0.9137],\n",
       "          [-0.9137, -0.8745, -0.8824,  ..., -0.8745, -0.8667, -0.8667],\n",
       "          [-0.9137, -0.8745, -0.8902,  ..., -0.8902, -0.8902, -0.8745],\n",
       "          ...,\n",
       "          [-0.6078, -0.5059, -0.6392,  ..., -0.8824, -0.8824, -0.8588],\n",
       "          [-0.7882, -0.6157, -0.6706,  ..., -0.8824, -0.8824, -0.8588],\n",
       "          [-0.9137, -0.7961, -0.7569,  ..., -0.8824, -0.8824, -0.8902]],\n",
       "\n",
       "         [[-0.9608, -0.9059, -0.9216,  ..., -0.9137, -0.9216, -0.9137],\n",
       "          [-0.9137, -0.8745, -0.8824,  ..., -0.8824, -0.8745, -0.8667],\n",
       "          [-0.9137, -0.8745, -0.8902,  ..., -0.8667, -0.8824, -0.8745],\n",
       "          ...,\n",
       "          [-0.7098, -0.6471, -0.7020,  ..., -0.8824, -0.8824, -0.8588],\n",
       "          [-0.8588, -0.7098, -0.7098,  ..., -0.8824, -0.8824, -0.8588],\n",
       "          [-0.9294, -0.8196, -0.7647,  ..., -0.8824, -0.8824, -0.8902]],\n",
       "\n",
       "         [[-0.9608, -0.9059, -0.9216,  ..., -0.9608, -0.9373, -0.9059],\n",
       "          [-0.9137, -0.8745, -0.8824,  ..., -0.9059, -0.8980, -0.8667],\n",
       "          [-0.9137, -0.8745, -0.8902,  ..., -0.8745, -0.8902, -0.8667],\n",
       "          ...,\n",
       "          [-0.7882, -0.7647, -0.7882,  ..., -0.8824, -0.8824, -0.8588],\n",
       "          [-0.9137, -0.8118, -0.7882,  ..., -0.8824, -0.8824, -0.8588],\n",
       "          [-0.9529, -0.8588, -0.8196,  ..., -0.8824, -0.8824, -0.8902]]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2098,  0.1983,  0.1444,  ..., -0.6252, -0.6179, -0.6404],\n",
       "          [-0.1485, -0.1505, -0.1828,  ..., -0.2529, -0.2549, -0.2885],\n",
       "          [-0.6610, -0.6586, -0.6547,  ...,  0.0696,  0.0566,  0.0096]],\n",
       "\n",
       "         [[ 0.8221,  0.8468,  0.8350,  ..., -0.4262, -0.3434, -0.2150],\n",
       "          [ 0.8223,  0.8466,  0.8360,  ..., -0.4255, -0.3169, -0.1740],\n",
       "          [ 0.8233,  0.8461,  0.8368,  ..., -0.4836, -0.4088, -0.3061]],\n",
       "\n",
       "         [[ 0.6515,  0.7032,  0.7132,  ..., -0.7505, -0.7635, -0.7939],\n",
       "          [ 0.7483,  0.7833,  0.7730,  ..., -0.6502, -0.6676, -0.7167],\n",
       "          [ 0.8529,  0.8674,  0.8321,  ..., -0.5985, -0.6150, -0.6650]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3934,  0.4203,  0.4118,  ..., -0.5547, -0.5679, -0.6069],\n",
       "          [ 0.4578,  0.4789,  0.4676,  ..., -0.5630, -0.5961, -0.6010],\n",
       "          [ 0.4064,  0.4255,  0.4120,  ..., -0.6917, -0.7292, -0.7348]],\n",
       "\n",
       "         [[ 0.0931, -0.0721, -0.1287,  ..., -0.1404, -0.1551, -0.2324],\n",
       "          [ 0.1821,  0.0453, -0.0088,  ..., -0.1277, -0.1488, -0.2314],\n",
       "          [-0.1850, -0.2358, -0.2392,  ..., -0.1221, -0.1402, -0.2377]],\n",
       "\n",
       "         [[-0.7564, -0.7924, -0.8010,  ..., -0.8022, -0.8169, -0.8395],\n",
       "          [-0.7865, -0.8017, -0.8137,  ..., -0.7924, -0.8096, -0.8223],\n",
       "          [-0.8718, -0.8544, -0.8495,  ..., -0.8299, -0.8461, -0.8498]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 3, 3], expected input[1, 250, 3, 32] to have 3 channels, but got 250 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-fb033af0bf66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                   \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# the model's output names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                   dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n\u001b[0;32m---> 11\u001b[0;31m                                 'output' : {0 : 'batch_size'}})\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, enable_onnx_checker, use_external_data_format, onnx_shape_inference)\u001b[0m\n\u001b[1;32m    693\u001b[0m                                 \u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                                 dynamic_axes=dynamic_axes)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     graph, params, torch_out, module = _create_jit_graph(model, args,\n\u001b[0;32m--> 459\u001b[0;31m                                                          _retain_param_name)\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_named_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args, _retain_param_name)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0mtrace_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_states\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m     \u001b[0mwarn_on_static_input_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mONNXTracedModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0m_create_interpreter_name_lookup_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 3, 3], expected input[1, 250, 3, 32] to have 3 channels, but got 250 channels instead"
     ]
    }
   ],
   "source": [
    "torch.onnx._export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name),   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  #operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK,\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, labels) in enumerate(valloader):\n",
    "    x_test = images\n",
    "    y_test = labels\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops:  87%|████████▋ | 90/103 [00:00<00:00, 2727.04 ops/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ed9cf6b00920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                        \u001b[0mimage_output_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'186'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                        \u001b[0mpreprocessing_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'image_scale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                        deprocessing_args={'image_scale':255.0})\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/_converters_entry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model, source, inputs, outputs, classifier_config, minimum_deployment_target, convert_to, compute_precision, skip_model_load, compute_units, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mskip_model_load\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_model_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mcompute_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_units\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     )\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36mmil_convert\u001b[0;34m(model, convert_from, convert_to, compute_units, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mcoremltools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_mil_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConverterRegistry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36m_mil_convert\u001b[0;34m(model, convert_from, convert_to, registry, modelClass, compute_units, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                             \u001b[0mconvert_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                             \u001b[0mregistry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m                          )\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36mmil_convert_to_proto\u001b[0;34m(model, convert_from, convert_to, converter_registry, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mfrontend_converter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrontend_converter_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrontend_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconvert_to\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"neuralnetwork\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/converter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfrontend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(model_spec, debug, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(model_spec, debug, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"convert function\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/converter.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;31m# Add the rest of the operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mconvert_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mgraph_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/ops.py\u001b[0m in \u001b[0;36mconvert_nodes\u001b[0;34m(context, graph)\u001b[0m\n\u001b[1;32m     68\u001b[0m             )\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# We've generated all the outputs the graph needs, terminate conversion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/ops.py\u001b[0m in \u001b[0;36madaptive_avg_pool2d\u001b[0;34m(context, node)\u001b[0m\n\u001b[1;32m   1092\u001b[0m             \u001b[0mpad_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/ops/registry.py\u001b[0m in \u001b[0;36madd_op\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0madd_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/builder.py\u001b[0m in \u001b[0;36m_add_op\u001b[0;34m(cls, op_cls, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mcurr_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_op_before\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbefore_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_nested_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_value_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/operation.py\u001b[0m in \u001b[0;36mtype_value_inference\u001b[0;34m(self, overwrite_output)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mexisting\u001b[0m \u001b[0m_output_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \"\"\"\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0moutput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0moutput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/ops/defs/pool.py\u001b[0m in \u001b[0;36mtype_inference\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mcustom_pad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mceil_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         )\n\u001b[1;32m     66\u001b[0m         \u001b[0mret_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mD_out_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/ops/defs/_utils.py\u001b[0m in \u001b[0;36mspatial_dimensions_out_shape\u001b[0;34m(pad_type, input_shape, kernel_shape, strides, dilations, custom_pad, ceil_mode)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                 \u001b[0mout_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meffective_ks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0mout_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meffective_ks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "# Using image_input in the inputs parameter:\n",
    "# Convert to Core ML using the Unified Conversion API.\n",
    "#coreml_model = coremltools.convert(\n",
    "#    traced_model,\n",
    "#    inputs=[coremltools.TensorType(shape=x_test.shape)]\n",
    "#)\n",
    "\n",
    "coreml_model = coremltools.convert(traced_model, inputs=[coremltools.TensorType(shape=x_test.shape)],\n",
    "                       image_input_names=['0'], \n",
    "                       image_output_names=['186'],\n",
    "                       preprocessing_args={'image_scale':1.0/255.0},\n",
    "                       deprocessing_args={'image_scale':255.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
