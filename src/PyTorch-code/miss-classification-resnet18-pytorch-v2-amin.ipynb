{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fc807820310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "#Import needed packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from onnx_tf.backend import prepare\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.autograd import Variable\n",
    "#from pytorch2keras.converter import pytorch_to_keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "from pathlib import Path\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# used for Alexnet\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 128\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform_train)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform_test)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "     num_workers=num_workers)\n",
    "#valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "#    sampler=valid_sampler, num_workers=num_workers)\n",
    "valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# specify the image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Resize(224),normalize,])), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 1.0.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:TensorFlow version 2.5.0 detected. Last version known to be fully compatible is 2.3.1 .\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "import coremltools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/onnx/'\n",
    "coreml_path = '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/coremltools/'\n",
    "error_path = '/Volumes/Cisco/Summer2022/onnx-exchange/Train2/miss-classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "def model_scores(y_test, test_predict):\n",
    "    correct_ = np.sum(y_test == test_predict)\n",
    "    accuracy  = correct_ #*100./np.sum(y_test == y_test)\n",
    "    return accuracy\n",
    "def get_miss_classification(y1, y2):\n",
    "    miss_perc_val_original_coreml = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(y1, y2)\n",
    "    except Exception as e:\n",
    "        miss_perc_val_original_coreml = 1\n",
    "    return miss_perc_val_original_coreml #, precision2, recall2, f12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onnx(i, x, y, batch_size):\n",
    "    \n",
    "    # Input to the model\n",
    "    #device_reset = cuda.get_current_device()\n",
    "    #device_reset.reset()\n",
    "    #x.cuda()\n",
    "    #print(\"converting for batch: \", i)\n",
    "    \n",
    "    #torch.random.manual_seed(42)\n",
    "    #x = torch.randn(10000, 3, 32, 32, requires_grad=True)\n",
    "    traced_model = torch.jit.trace(model, x)\n",
    "    \n",
    "    ### Original Model\n",
    "    since_1 = time.time()\n",
    "    with torch.no_grad():\n",
    "        torch_out = model(x)\n",
    "    inference_time_original = time.time() - since_1\n",
    "    #_, predicted = torch.max(outputs.data, 1)\n",
    "    y0 = torch.argmax(torch_out.data,1)\n",
    "    accuracy_original = model_scores(to_numpy(y), to_numpy(y0))\n",
    "    # ONNX Model\n",
    "    \n",
    "    #t_elapsed_2 = time.time() - since_1\n",
    "    #since_1 = time.time()\n",
    "    #onnx_model = onnx.load(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    #load_time_onnx = time.time() - since_1\n",
    "    #onnx.checker.check_model(onnx_model)\n",
    "    #size_onnx = os.path.getsize(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    #def to_numpy(tensor):\n",
    "    #    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    #ort_session = onnxruntime.InferenceSession(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    since_1 = time.time()\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    inference_time_onnx = time.time() - since_1\n",
    "    # compare ONNX Runtime and PyTorch results\n",
    "    #print(\"\\n*********\\n\\n\")\n",
    "    #time_diff = t_elapsed_0+t_elapsed_1, t_elapsed_2, t_elapsed_3\n",
    "    \n",
    "    ####### Mis-classification ONNX ######################################\n",
    "    ort_outs_tensor = torch.from_numpy(ort_outs[0]) \n",
    "    y2 = torch.argmax(ort_outs_tensor.data,1)\n",
    "    #y2 = to_categorical(np.argmax(ort_outs[0], 1), num_classes = 10)\n",
    "    #correct_onnx = np.sum(y2 == y)\n",
    "    accuracy_onnx = model_scores(to_numpy(y), to_numpy(y2))\n",
    "    miss_original_onnx = get_miss_classification(to_numpy(y0), to_numpy(y2))\n",
    "    \n",
    "    ####### End of mis-classification ONNX ###################################### \n",
    "    \n",
    "    \n",
    "    ## CoreML\n",
    "    \n",
    "    ## Converting the coremltool\n",
    "    #since_1 = time.time()\n",
    "    # Using image_input in the inputs parameter:\n",
    "    # Convert to Core ML using the Unified Conversion API.\n",
    "    #coreml_model = coremltools.convert(traced_model,inputs=[coremltools.TensorType(shape=x.shape)])\n",
    "    #t_conversion_time_coreml = time.time() - since_1\n",
    "    #since_1 = time.time()\n",
    "    #coreml_model.save(coreml_path+framework+'/{}/{}-v2.mlmodel'.format(model_short_name, model_name))\n",
    "    #t_saving_time_coreml = time.time() - since_1\n",
    "    \n",
    "    \n",
    "    #print(name_1)\n",
    "\n",
    "    #size_coreml = os.path.getsize(coreml_path+framework+'/{}/{}-v2.mlmodel'.format(model_short_name, model_name))\n",
    "    \n",
    "    \n",
    "    #since_1 = time.time()\n",
    "    #coreml_model = coremltools.models.MLModel(coreml_path+framework+\"/{}/{}-v2.mlmodel\".format(model_short_name, model_name))\n",
    "    #load_time_coreml = time.time() - since_1\n",
    "    \n",
    "    #spec = coreml_model.get_spec()\n",
    "    #coreml_model = coremltools.models.MLModel(spec)\n",
    "    name_1 = coreml_model.get_spec().description.input[0].name\n",
    "    since_1 = time.time()\n",
    "    output_dict_test = coreml_model.predict({name_1:to_numpy(x)})\n",
    "    inference_time_coreml = time.time() - since_1\n",
    "    ####### Mis-classification coreML ######################################\n",
    "    coreml_array_output = output_dict_test[list(output_dict_test.keys())[0]]\n",
    "    output_tensor = torch.from_numpy(coreml_array_output) \n",
    "    y3 = torch.argmax(output_tensor.data,1)\n",
    "    #correct_coreml = np.sum(to_numpy(y3) == to_numpy(y))\n",
    "    accuracy_coreml = model_scores(to_numpy(y3), to_numpy(y))\n",
    "    miss_original_coreml = get_miss_classification(to_numpy(y0), to_numpy(y3))\n",
    "    \n",
    "    #print(correct_original, correct_coreml, correct_onnx, np.sum(y == y))\n",
    "    ## Part 1\n",
    "    \n",
    "    ####### End of mis-classification coreML ######################################\n",
    "    \n",
    "    list_val = [accuracy_original, accuracy_onnx, accuracy_coreml, miss_original_onnx, miss_original_coreml,inference_time_original, inference_time_onnx, inference_time_coreml]\n",
    "    return list_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lets_convert(data,  data_writer_run, batch_size): # for cifar10 etc\n",
    "    since = time.time()\n",
    "    accuracy_original = 0.0\n",
    "    accuracy_onnx = 0.0\n",
    "    accuracy_coreml = 0.0\n",
    "    #miss_test_original = 0\n",
    "    miss_original_onnx = 0\n",
    "    #miss_test_onnx = 0\n",
    "    miss_original_coreml = 0\n",
    "    #miss_test_coreml = 0\n",
    "    \n",
    "    inference_time_original = 0.0\n",
    "    inference_time_onnx = 0.0\n",
    "    inference_time_coreml = 0.0\n",
    "    \n",
    "    total_ = 0.0\n",
    "    total_datasets = 0\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        list_val = to_onnx(i, images,labels, batch_size)\n",
    "        if i%50 == 0:\n",
    "            print(i, list_val)\n",
    "        accuracy_original += list_val[0]\n",
    "        accuracy_onnx += list_val[1]\n",
    "        accuracy_coreml += list_val[2]\n",
    "\n",
    "        miss_original_onnx += list_val[3]\n",
    "        miss_original_coreml += list_val[4]\n",
    "\n",
    "        inference_time_original += list_val[5]\n",
    "        inference_time_onnx += list_val[6]\n",
    "        inference_time_coreml += list_val[7]\n",
    "        total_ += np.sum(to_numpy(labels) == to_numpy(labels))\n",
    "        total_datasets += labels.shape[0]\n",
    "        if i == 1:\n",
    "            break\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Conversion complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60) )\n",
    "    data_writer_run.writerow([model_short_name,framework, training_id, model_name, round(accuracy_original*100/total_,2), round(accuracy_onnx*100/total_,2), round(accuracy_coreml*100/total_,2),  round(miss_original_onnx*100/total_datasets,2),  round(miss_original_coreml*100/total_datasets,2),'', inference_time_original/total_datasets, inference_time_onnx/total_datasets, inference_time_coreml/total_datasets, '',\n",
    "                              '{:.0f}m {:.0f}s'.format((inference_time_original/total_datasets) // 60, (inference_time_original/total_datasets) % 60),\n",
    "                              '{:.0f}m {:.0f}s'.format((inference_time_onnx/total_datasets) // 60, (inference_time_onnx/total_datasets) % 60),\n",
    "                              '{:.0f}m {:.0f}s'.format((inference_time_coreml/total_datasets) // 60, (inference_time_coreml/total_datasets) % 60),\n",
    "                              '{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Converting Frontend ==> MIL Ops:  99%|█████████▉| 102/103 [00:00<00:00, 1448.23 ops/s]\n",
      "Running MIL Common passes:   0%|          | 0/33 [00:00<?, ? passes/s]/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:101: UserWarning: Input, 'x.1', of the source model, has been renamed to 'x_1' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:129: UserWarning: Output, '157', of the source model, has been renamed to 'var_157' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:01<00:00, 30.00 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00,  9.11 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 115/115 [00:30<00:00,  3.80 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  1\n",
      "0 [25, 25, 25, 0, 0, 86.51746082305908, 52.79322600364685, 60.2737340927124]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "{\n    NSLocalizedDescription = \"Error computing NN outputs.\";\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-be2dd5405488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m#valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m#num_workers=num_workers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0m_lets_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_writer_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mdata_file_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-72b23d6f4dfc>\u001b[0m in \u001b[0;36m_lets_convert\u001b[0;34m(data, data_writer_run, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtotal_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlist_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9261023e6c94>\u001b[0m in \u001b[0;36mto_onnx\u001b[0;34m(i, x, y, batch_size)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mname_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoreml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0msince_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0moutput_dict_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoreml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0minference_time_coreml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msince_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m####### Mis-classification coreML ######################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/coremltools/models/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, useCPUOnly)\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;31m# return a more verbose error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_input_name_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__proxy__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museCPUOnly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_macos_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: {\n    NSLocalizedDescription = \"Error computing NN outputs.\";\n}"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "#data_file_run = open(error_path+framework+\"/{}/runtime_miss-classification_{}.csv\".format(model_short_name,model_name), mode='w', newline='',\n",
    "#                                  encoding='utf-8')\n",
    "#data_writer_run = csv.writer(data_file_run, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#data_writer_run.writerow(['model','framework', 'training_id', 'model_full', \"batch_size\", 'round','runtime','original_load_time', 'original_infererence_time', 'runtime_load_time', \n",
    "#                          'runtime_inference_time',  'miss_classified_original_runtime_percentage','',  'encoded_miss_classified_original_runtime_percentage','encoded_miss_classified_original_test_runtime_percentage', '', 'accuracy_original', 'accuracy_runtime'])\n",
    "batch_size = 128\n",
    "#valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "#    num_workers=num_workers)\n",
    "for i, (images, labels) in enumerate(testloader):\n",
    "    images_ = images\n",
    "    labels_ = labels \n",
    "    break\n",
    "shape_ = images_.shape\n",
    "for round_ in [1,2,3]: #,4,5,6,7,8,9,10\n",
    "    training_id = round_\n",
    "    model_short_name = 'vgg'\n",
    "    framework = 'pytorch'\n",
    "    path = '/Volumes/Cisco/Fall2021/onnx-exchange/Training/{}/{}/'.format(framework, model_short_name)\n",
    "\n",
    "    # Model class must be defined somewhere\n",
    "    since_0 = time.time()\n",
    "    model_name = 'torch_exp_vgg_2021-11-03_{}'.format(training_id)\n",
    "    #model_name = 'torch_lenet5-mnist_2021-11-01_{}'.format(training_id)\n",
    "    model = torch.load(path+model_name+'.pth', map_location=torch.device('cpu'))\n",
    "    #resnet50_model.eval()\n",
    "    t_elapsed_0 = time.time() - since_0\n",
    "    size0 = os.path.getsize(path+model_name+'.pth')\n",
    "    size0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    since_1 = time.time()\n",
    "    onnx_model = onnx.load(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    load_time_onnx = time.time() - since_1\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    size_onnx = os.path.getsize(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    #def to_numpy(tensor):\n",
    "    #    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    ort_session = onnxruntime.InferenceSession(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    \n",
    "    \n",
    "    # Convert to Core ML using the Unified Conversion API.\n",
    "    traced_model = torch.jit.trace(model, images_)\n",
    "    coreml_model = coremltools.convert(traced_model,inputs=[coremltools.TensorType(shape=images_.shape)])\n",
    "    #t_conversion_time_coreml = time.time() - since_1\n",
    "    \n",
    "    #since_1 = time.time()\n",
    "    #coreml_model = coremltools.models.MLModel(coreml_path+framework+\"/{}/{}-v2.mlmodel\".format(model_short_name, model_name))\n",
    "    #load_time_coreml = time.time() - since_1\n",
    "    \n",
    "    if not os.path.exists(error_path+framework):\n",
    "        Path(error_path+framework).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print('round: ', round_)\n",
    "    flag = 0\n",
    "    if not os.path.exists(error_path+framework+\"/runtime_accuracy_{}.csv\".format(model_short_name)):\n",
    "        data_file_run = open(error_path+framework+\"/runtime_accuracy_{}.csv\".format(model_short_name), mode='w', newline='', encoding='utf-8')\n",
    "    else:\n",
    "        data_file_run = open(error_path+framework+\"/runtime_accuracy_{}.csv\".format(model_short_name), mode='a+', newline='', encoding='utf-8')\n",
    "        flag = 1\n",
    "    data_writer_run = csv.writer(data_file_run, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    if flag == 0: \n",
    "        data_writer_run.writerow(['model','framework', 'training_id', 'model_full', 'accuracy_original', 'accuracy_onnx', 'accuracy_coreml', 'miss_original_onnx', 'miss_original_coreml','', 'inference_time_original', 'inference_time_onnx', 'inference_time_coreml', '', 'inference_time_original2', 'inference_time_onnx2', 'inference_time_coreml2', 'overral_time'])\n",
    "    # dataloaders\n",
    "    \n",
    "    #valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    #num_workers=num_workers)\n",
    "    _lets_convert(testloader, data_writer_run, batch_size)\n",
    "    \n",
    "    data_file_run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
