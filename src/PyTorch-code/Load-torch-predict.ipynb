{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall onnx==1.8.1 -y\n",
    "#!pip uninstall mxnet -y\n",
    "#!pip uninstall numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install 'h5py==2.10.0' --force-reinstall\n",
    "#!pip install numpy\n",
    "#!pip install onnx==1.8.1\n",
    "#!pip install mxnet\n",
    "#!pip install pytorch2keras\n",
    "#!pip install caffe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fcc0e521210>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "#Import needed packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from onnx_tf.backend import prepare\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.autograd import Variable\n",
    "from pytorch2keras.converter import pytorch_to_keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usagers3/opmos/anaconda3/lib/python3.8/site-packages/numba/core/errors.py:154: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda \n",
    "device_reset = cuda.get_current_device()\n",
    "device_reset.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# used for Alexnet\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 250\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform_train)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform_test)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "     num_workers=num_workers)\n",
    "#valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "#    sampler=valid_sampler, num_workers=num_workers)\n",
    "valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# specify the image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform)\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "# define samplers for obtaining training and validation batches\n",
    "#train_sampler = SubsetRandomSampler(train_idx)\n",
    "#valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "     num_workers=num_workers)\n",
    "#valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "#    sampler=valid_sampler, num_workers=num_workers)\n",
    "valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# specify the image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( \n",
    "       (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010) \n",
    "    )\n",
    "])\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root= './data', train = True,\n",
    "    download =True, transform = transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root= './data', train = False,\n",
    "    download =True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usagers3/opmos/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Mnist dataset fpr Lenet\n",
    "batch_size = 500\n",
    "T = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "train_data = torchvision.datasets.MNIST('mnist_data', train=True, download=True, transform=T)\n",
    "val_data = torchvision.datasets.MNIST('mnist_data', train=False, download=True, transform=T)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size)\n",
    "valloader = torch.utils.data.DataLoader(val_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dl(model, data):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        images = images.cuda()\n",
    "        x = model(images)\n",
    "        value, pred = torch.max(x, 1)\n",
    "        pred = pred.data.cpu()\n",
    "        y_pred.extend(list(pred.numpy()))\n",
    "        y_true.extend(list(labels.numpy()))\n",
    "    return np.array(y_pred), np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_predict_dl(model, data, n=10):\n",
    "    pred_dict = {}\n",
    "    for i in range (n):\n",
    "        y_pred, y_true = predict_dl(resnet50_model, valloader)\n",
    "        print('predict: {}/{}'.format(i, n))\n",
    "        for x in range (len(y_pred)):\n",
    "            if y_true[x] in pred_dict.keys():\n",
    "                val = pred_dict.get(y_true[x])\n",
    "                if len(val) < n: \n",
    "                    val.append(y_pred[x])\n",
    "                pred_dict[y_true[x]] = val\n",
    "            else:\n",
    "                pred_dict[y_true[x]] = [y_pred[x]]\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "    for key, val in pred_dict.items():\n",
    "        y_true.append(key)\n",
    "        y_scores.append(val)\n",
    "    return pred_dict, y_true, y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        images = images.cuda()\n",
    "        x = model(images)\n",
    "        value, pred = torch.max(x,1)\n",
    "        pred = pred.data.cpu()\n",
    "        total += x.size(0)\n",
    "        correct += torch.sum(pred == labels)\n",
    "    return correct*100./total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/19-08-2021/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515298923"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model class must be defined somewhere\n",
    "since_0 = time.time()\n",
    "#model_name = 'torch_resnet50-cifar10_2021-08-19-15:05:17'\n",
    "#model_name = 'torch_resnet18_cifar10_2021-08-20-15:17:40'\n",
    "model_name = 'torch_vgg_cifar10_2021-08-23-17:19:32'\n",
    "#model_name = 'torch_alexnet_cifar10_2021-08-20-15:26:26'\n",
    "#model_name = 'torch_alexnet_cifar10_2021-08-20-15:26:26'\n",
    "#model_name = 'torch_Lenet5-mnist_2021-09-03-13:54:37'\n",
    "model = torch.load(path+model_name+'.pth')\n",
    "#resnet50_model.eval()\n",
    "t_elapsed_0 = time.time() - since_0\n",
    "size0 = os.path.getsize(path+model_name+'.pth')\n",
    "size0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515298923"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size1 = os.path.getsize(path+model_name+'.pth')\n",
    "size1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_true = predict_dl(model, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_dict, y_true_, y_scores = top_n_predict_dl(resnet50_model, valloader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top5_scores = metrics.top_k_accuracy_score(y_pred, y_scores, k=10)\n",
    "#print('Top5 score: %f' % top5_scores)\n",
    "\n",
    "#top5_scores_normalised = metrics.top_k_accuracy_score(y_pred, y_scores, k=5, normalize=False)\n",
    "#print('Top5 score normalised: %f' % top5_scores_normalised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.523300\n",
      "Precision: 0.522173\n",
      "Recall: 0.523300\n",
      "F1 score: 0.521615\n"
     ]
    }
   ],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = metrics.recall_score(y_true, y_pred, average='macro')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = validate(resnet50_model, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(52.3300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets export the model to onnx format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_np = np.random.uniform(0, 1, (1, 3, 224, 224))\n",
    "#input_var = Variable(torch.FloatTensor(input_np))\n",
    "#k_resnet50_model = pytorch_to_keras(resnet50_model, input_var.cuda(), [(3, 224, 224,)], verbose=True, change_ordering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping onnxruntime as it is not installed.\u001b[0m\n",
      "Found existing installation: onnxruntime-gpu 1.9.0\n",
      "Uninstalling onnxruntime-gpu-1.9.0:\n",
      "  Successfully uninstalled onnxruntime-gpu-1.9.0\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8 MB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /home/usagers/opmos/anaconda3/lib/python3.8/site-packages (from onnxruntime) (1.19.5)\n",
      "Requirement already satisfied: flatbuffers in /home/usagers/opmos/anaconda3/lib/python3.8/site-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: protobuf in /home/usagers/opmos/anaconda3/lib/python3.8/site-packages (from onnxruntime) (3.17.3)\n",
      "Requirement already satisfied: six>=1.9 in /home/usagers/opmos/anaconda3/lib/python3.8/site-packages (from protobuf->onnxruntime) (1.15.0)\n",
      "Installing collected packages: onnxruntime\n",
      "Successfully installed onnxruntime-1.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall onnxruntime -y\n",
    "!pip uninstall onnxruntime-gpu -y\n",
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe2.python.onnx.backend as onnx_caffe2_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onnx(i, x, abs_errors,rel_errors, t0_list, t1_list, t2_list, t3_list, s_list):\n",
    "    # Input to the model\n",
    "    #device_reset = cuda.get_current_device()\n",
    "    #device_reset.reset()\n",
    "    #x.cuda()\n",
    "   \n",
    "    print(\"converting for batch: \", i)\n",
    "    \n",
    "    torch.random.manual_seed(42)\n",
    "    #x = torch.randn(10000, 3, 32, 32, requires_grad=True)\n",
    "    since_1 = time.time()\n",
    "    #model = torch.load(path+model_name+'.pth')\n",
    "    torch_out = model(x)\n",
    "    t_elapsed_1 = time.time() - since_1\n",
    "    # Export the model\n",
    "    since_1 = time.time()\n",
    "    torch.onnx._export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"./data/ONNX/torch/model_ft-{}.onnx\".format(model_name),   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  #operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK,\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "    t_elapsed_2 = time.time() - since_1\n",
    "    \n",
    "    \n",
    "    onnx_model = onnx.load(\"./data/ONNX/torch/model_ft-{}.onnx\".format(model_name))\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    \n",
    "    size2 = os.path.getsize(\"./data/ONNX/torch/model_ft-{}.onnx\".format(model_name))\n",
    "    s_list.append(size2)\n",
    "    \n",
    "    def to_numpy(tensor):\n",
    "        return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    try:\n",
    "        ort_session = onnxruntime.InferenceSession(\"./data/ONNX/torch/model_ft-{}.onnx\".format(model_name))\n",
    "        since_1 = time.time()\n",
    "        ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "        ort_outs = ort_session.run(None, ort_inputs)\n",
    "    except:\n",
    "        prepared_backend = onnx_caffe2_backend.prepare(onnx_model)\n",
    "        since_1 = time.time()\n",
    "        W = {model.graph.input[0].name: to_numpy(x)}\n",
    "        ort_outs = prepared_backend.run(W)\n",
    "        \n",
    "   \n",
    "    t_elapsed_3 = time.time() - since_1\n",
    "    # compare ONNX Runtime and PyTorch results\n",
    "    print(\"\\n*********\\n\\n\")\n",
    "    #time_diff = t_elapsed_0+t_elapsed_1, t_elapsed_2, t_elapsed_3\n",
    "    t0_list.append(t_elapsed_0)\n",
    "    t1_list.append(t_elapsed_1)\n",
    "    t2_list.append(t_elapsed_2)\n",
    "    t3_list.append(t_elapsed_3)\n",
    "    \n",
    "    abs_err = np.absolute(to_numpy(torch_out)-ort_outs[0])\n",
    "    rel_err = np.absolute(to_numpy(torch_out)-ort_outs[0])/ np.absolute(ort_outs[0])\n",
    "    abs_errors.append(abs_err)\n",
    "    rel_errors.append(rel_err)\n",
    "    \n",
    "    return (abs_err, rel_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lets_convert(data):\n",
    "    since = time.time()\n",
    "    list_converted = []\n",
    "    t0_list = []\n",
    "    t1_list = []\n",
    "    t2_list = []\n",
    "    t3_list = []\n",
    "    s_list = []\n",
    "    abs_errors = []\n",
    "    rel_errors = []\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        torch.cuda.empty_cache()\n",
    "        images = images.cuda()\n",
    "        list_converted.append(to_onnx(i, images, abs_errors,rel_errors, t0_list, t1_list, t2_list, t3_list, s_list))\n",
    "        if i == 15:\n",
    "            break\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Conversion complete in {:.0f}m {:.0f}s,  Loading Pytorch: {}, Pytorch time: {:.4f}, conversion time: {:.4f}, onnx runtime: {:.4f}'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60, np.mean(np.array(t0_list)), np.mean(np.array(t1_list)), np.mean(np.array(t2_list)), np.mean(np.array(t3_list))) )\n",
    "    \n",
    "    #return list_converted\n",
    "    return list_converted, abs_errors, rel_errors, 'Conversion complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60), np.mean(np.array(t0_list)), np.mean(np.array(t1_list)), np.mean(np.array(t2_list)), np.mean(np.array(t3_list)), np.mean(np.array(s_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ Batch size:  1\n",
      "converting for batch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usagers3/opmos/anaconda3/lib/python3.8/site-packages/caffe2/python/onnx/backend.py:688: UserWarning: This version of onnx-caffe2 targets ONNX operator set version 9, but the model we are trying to import uses version 10.  We will try to import it anyway, but if the model uses operators which had BC-breaking changes in the intervening versions, import will fail.\n",
      "  warnings.warn(\"This version of onnx-caffe2 targets ONNX operator set version {}, but the model we are trying to import uses version {}.  We will try to import it anyway, but if the model uses operators which had BC-breaking changes in the intervening versions, import will fail.\".format(cls._known_opset_version, imp.version))\n",
      "/usagers3/opmos/anaconda3/lib/python3.8/site-packages/caffe2/python/onnx/backend.py:690: UserWarning: Unrecognized operator set org.pytorch.aten\n",
      "  warnings.warn(\"Unrecognized operator set {}\".format(imp.domain))\n",
      "ONNX FATAL: Error while processing node: input: \"91\"\n",
      "input: \"92\"\n",
      "output: \"93\"\n",
      "op_type: \"adaptive_avg_pool2d\"\n",
      "domain: \"org.pytorch.aten\"\n",
      ". Exception: Don't know how to translate op adaptive_avg_pool2d\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ONNX conversion failed, encountered 1 errors:\n\nError while processing node: input: \"91\"\ninput: \"92\"\noutput: \"93\"\nop_type: \"adaptive_avg_pool2d\"\ndomain: \"org.pytorch.aten\"\n. Exception: Don't know how to translate op adaptive_avg_pool2d",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFail\u001b[0m                                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b679c6f94cbe>\u001b[0m in \u001b[0;36mto_onnx\u001b[0;34m(i, x, abs_errors, rel_errors, t0_list, t1_list, t2_list, t3_list, s_list)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mort_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/ONNX/torch/model_ft-{}.onnx\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0msince_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_inference_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled_optimizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m_create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_config_from_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFail\u001b[0m: [ONNXRuntimeError] : 1 : FAIL : Load model from ./data/ONNX/torch/model_ft-VGG-torch.onnx failed:Fatal error: adaptive_avg_pool2d is not a registered function/op",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-33091f7978b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m            'dog', 'frog', 'horse', 'ship', 'truck']\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mlist_converted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lets_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-b7ac5b7b618b>\u001b[0m in \u001b[0;36m_lets_convert\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlist_converted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrel_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt3_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-b679c6f94cbe>\u001b[0m in \u001b[0;36mto_onnx\u001b[0;34m(i, x, abs_errors, rel_errors, t0_list, t1_list, t2_list, t3_list, s_list)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mort_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mort_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mort_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mprepared_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx_caffe2_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0msince_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/caffe2/python/onnx/backend.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(cls, model, device, raw_values_dict, **kwargs)\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mdevice_option\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0minit_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_onnx_model_to_caffe2_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_values_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/caffe2/python/onnx/backend.py\u001b[0m in \u001b[0;36m_onnx_model_to_caffe2_net\u001b[0;34m(cls, onnx_model, device, opset_version, include_initializers)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    914\u001b[0m                 \"ONNX conversion failed, encountered {} errors:\\n\\n{}\".format(\n\u001b[1;32m    915\u001b[0m                     len(errors), \"\\n\\n\".join(errors)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ONNX conversion failed, encountered 1 errors:\n\nError while processing node: input: \"91\"\ninput: \"92\"\noutput: \"93\"\nop_type: \"adaptive_avg_pool2d\"\ndomain: \"org.pytorch.aten\"\n. Exception: Don't know how to translate op adaptive_avg_pool2d"
     ]
    }
   ],
   "source": [
    "#list_converted = _lets_convert(valloader)\n",
    "#list_converted = _lets_convert(test_ds)\n",
    "model_name = 'VGG-torch'\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "import pandas as pd \n",
    "for batch_size in [1, 5,10,20,30,40,50,60,70,80,90,100,128, 150, 200, 250,300,350, 400, 450, 500]:\n",
    "    print(\"################ Batch size: \", batch_size)\n",
    "    # prepare data loaders (combine dataset and sampler)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "     num_workers=num_workers)\n",
    "    #valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "    #    sampler=valid_sampler, num_workers=num_workers)\n",
    "    valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "    \n",
    "    # specify the image classes\n",
    "    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    list_converted, abs_errors, rel_errors, total_time, t0, t1, t2, t3, file_size = _lets_convert(valloader)\n",
    "    for i in range(len(abs_errors)):\n",
    "        if i == 0:\n",
    "            abs_array = abs_errors[i]\n",
    "            rel_array = rel_errors[i]\n",
    "        else:\n",
    "            np.append(abs_array, abs_errors[i])\n",
    "            np.append(rel_array, rel_errors[i])\n",
    "            \n",
    "    abs_list = []\n",
    "    rel_list = []\n",
    "    model_list = []\n",
    "    batch_list = []\n",
    "    summary_list = ['Modelsize:{}, Conversion: {}, Loading: {}, t1: {}, conversion time: {}, onnx runtime: {}, onnx filesize: {}'.format(size0, total_time, t0, t1, t2, t3, file_size)]\n",
    "    for i in range(len(abs_array)):\n",
    "        abs_list.append(abs_array[i][0])\n",
    "        rel = rel_array[i][0]\n",
    "        if rel == np.inf or rel == -np.inf:\n",
    "            rel = 0.0\n",
    "        rel_list.append(rel)\n",
    "        batch_list.append(batch_size)\n",
    "        model_list.append(model_name)\n",
    "        if i >= len(summary_list):\n",
    "            summary_list.append('')\n",
    "    print(len(summary_list), len(rel_list))\n",
    "    data = pd.DataFrame({'model':model_list,'batch_size': batch_list, 'abs_errors':abs_list, 'rel_errors':rel_list, 'summary': summary_list})\n",
    "    data.to_csv('./data/errors/torch2/tf_errors_{}_{}.csv'.format(model_name, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ Batch size:  1\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 1s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0024, conversion time: 0.0966, onnx runtime: 0.0007\n",
      "1 1\n",
      "################ Batch size:  5\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 1s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0014, conversion time: 0.0913, onnx runtime: 0.0007\n",
      "5 5\n",
      "################ Batch size:  10\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 1s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0014, conversion time: 0.0923, onnx runtime: 0.0009\n",
      "10 10\n",
      "################ Batch size:  20\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 1s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0015, conversion time: 0.0924, onnx runtime: 0.0013\n",
      "20 20\n",
      "################ Batch size:  30\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 1s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0018, conversion time: 0.0928, onnx runtime: 0.0017\n",
      "30 30\n",
      "################ Batch size:  40\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 1s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0018, conversion time: 0.0928, onnx runtime: 0.0021\n",
      "40 40\n",
      "################ Batch size:  50\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 1s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0022, conversion time: 0.0946, onnx runtime: 0.0025\n",
      "50 50\n",
      "################ Batch size:  60\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 1s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0015, conversion time: 0.0924, onnx runtime: 0.0031\n",
      "60 60\n",
      "################ Batch size:  70\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 1s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0015, conversion time: 0.0930, onnx runtime: 0.0035\n",
      "70 70\n",
      "################ Batch size:  80\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 1s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0019, conversion time: 0.0930, onnx runtime: 0.0035\n",
      "80 80\n",
      "################ Batch size:  90\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 1s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0019, conversion time: 0.0934, onnx runtime: 0.0042\n",
      "90 90\n",
      "################ Batch size:  100\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 1s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0019, conversion time: 0.0945, onnx runtime: 0.0045\n",
      "100 100\n",
      "################ Batch size:  150\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 2s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0019, conversion time: 0.0951, onnx runtime: 0.0061\n",
      "150 150\n",
      "################ Batch size:  200\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 2s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0017, conversion time: 0.0911, onnx runtime: 0.0080\n",
      "200 200\n",
      "################ Batch size:  250\n",
      "converting for batch:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 2s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0018, conversion time: 0.0893, onnx runtime: 0.0093\n",
      "250 250\n",
      "################ Batch size:  300\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 2s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0019, conversion time: 0.0889, onnx runtime: 0.0111\n",
      "300 300\n",
      "################ Batch size:  350\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 2s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0018, conversion time: 0.0899, onnx runtime: 0.0166\n",
      "350 350\n",
      "################ Batch size:  400\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 2s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0018, conversion time: 0.0891, onnx runtime: 0.0187\n",
      "400 400\n",
      "################ Batch size:  450\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 2s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0019, conversion time: 0.0890, onnx runtime: 0.0207\n",
      "450 450\n",
      "################ Batch size:  500\n",
      "converting for batch:  0\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Conversion complete in 0m 2s,  Loading Pytorch: 0.00800633430480957, Pytorch time: 0.0022, conversion time: 0.0887, onnx runtime: 0.0241\n",
      "500 500\n"
     ]
    }
   ],
   "source": [
    "#list_converted = _lets_convert(valloader)\n",
    "#list_converted = _lets_convert(test_ds)\n",
    "model_name = 'lenet5-torch'\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "import pandas as pd \n",
    "for batch_size in [1, 5,10,20,30,40,50,60,70,80,90,100,28, 150,200, 250,300,350, 400, 450, 500]:\n",
    "    print(\"################ Batch size: \", batch_size)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size)\n",
    "    valloader = torch.utils.data.DataLoader(val_data, batch_size = batch_size)\n",
    "    \n",
    "    # specify the image classes\n",
    "    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    list_converted, abs_errors, rel_errors, total_time, t0, t1, t2, t3, file_size = _lets_convert(valloader)\n",
    "    for i in range(len(abs_errors)):\n",
    "        if i == 0:\n",
    "            abs_array = abs_errors[i]\n",
    "            rel_array = rel_errors[i]\n",
    "        else:\n",
    "            np.append(abs_array, abs_errors[i])\n",
    "            np.append(rel_array, rel_errors[i])\n",
    "            \n",
    "    abs_list = []\n",
    "    rel_list = []\n",
    "    model_list = []\n",
    "    batch_list = []\n",
    "    summary_list = ['Modelsize:{}, Conversion: {}, Loading: {}, t1: {}, conversion time: {}, onnx runtime: {}, onnx filesize: {}'.format(size0, total_time, t0, t1, t2, t3, file_size)]\n",
    "    for i in range(len(abs_array)):\n",
    "        abs_list.append(abs_array[i][0])\n",
    "        rel = rel_array[i][0]\n",
    "        if rel == np.inf or rel == -np.inf:\n",
    "            rel = 0.0\n",
    "        rel_list.append(rel)\n",
    "        batch_list.append(batch_size)\n",
    "        model_list.append(model_name)\n",
    "        if i >= len(summary_list):\n",
    "            summary_list.append('')\n",
    "    print(len(summary_list), len(rel_list))\n",
    "    data = pd.DataFrame({'model':model_list,'batch_size': batch_list, 'abs_errors':abs_list, 'rel_errors':rel_list, 'summary': summary_list})\n",
    "    data.to_csv('./data/errors/torch2/tf_errors_{}_{}.csv'.format(model_name, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported: ONNX export of operator adaptive_avg_pool2d, since output size is not factor of input size. Please feel free to request support or submit a pull request on PyTorch GitHub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a2d053b4fa4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist_converted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lets_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#list_converted = _lets_convert(test_ds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'VGG-torch'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-b7ac5b7b618b>\u001b[0m in \u001b[0;36m_lets_convert\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlist_converted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrel_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt3_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-bcb8968668a9>\u001b[0m in \u001b[0;36mto_onnx\u001b[0;34m(i, x, abs_errors, rel_errors, t0_list, t1_list, t2_list, t3_list, s_list)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Export the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msince_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     torch.onnx._export(model,               # model being run\n\u001b[0m\u001b[1;32m     18\u001b[0m                   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m                         \u001b[0;31m# model input (or a tuple for multiple inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                   \u001b[0;34m\"./data/ONNX/torch/model_ft-{}.onnx\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# where to save the model (can be a file or file-like object)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, enable_onnx_checker, use_external_data_format, onnx_shape_inference)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 _model_to_graph(model, args, verbose, input_names,\n\u001b[0m\u001b[1;32m    690\u001b[0m                                 \u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                                 \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_retain_param_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_named_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     graph = _optimize_graph(graph, operator_export_type,\n\u001b[0m\u001b[1;32m    464\u001b[0m                             \u001b[0m_disable_torch_constant_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_disable_torch_constant_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                             \u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mdynamic_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdynamic_axes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx_set_dynamic_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_lint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m_run_symbolic_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_run_symbolic_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_symbolic_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_run_symbolic_function\u001b[0;34m(g, block, n, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m    992\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m                 \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributeNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msymbolic_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mns\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"prim\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py\u001b[0m in \u001b[0;36msymbolic_fn\u001b[0;34m(g, input, output_size)\u001b[0m\n\u001b[1;32m    980\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_unimplemented\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output size that are not factor of input size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msym_help\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_onnx_unsupported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', since output size is not factor of input size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m# call max_poolxd_with_indices to get indices in the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py\u001b[0m in \u001b[0;36m_onnx_unsupported\u001b[0;34m(op_name)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_onnx_unsupported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     raise RuntimeError('Unsupported: ONNX export of operator {}. '\n\u001b[0m\u001b[1;32m    248\u001b[0m                        'Please feel free to request support or submit a pull request on PyTorch GitHub.'.format(op_name))\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unsupported: ONNX export of operator adaptive_avg_pool2d, since output size is not factor of input size. Please feel free to request support or submit a pull request on PyTorch GitHub."
     ]
    }
   ],
   "source": [
    "list_converted = _lets_convert(valloader)\n",
    "#list_converted = _lets_convert(test_ds)\n",
    "model_name = 'VGG-torch'\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "import pandas as pd \n",
    "for batch_size in [1, 5,10,20,30,40,50,60,70,80,90,100,28, 150,200, 250,300,350, 400, 450, 500]:\n",
    "    print(\"################ Batch size: \", batch_size)\n",
    "    #trainloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size)\n",
    "    #valloader = torch.utils.data.DataLoader(val_data, batch_size = batch_size)\n",
    "    \n",
    "    #train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = True)\n",
    "    \n",
    "    # specify the image classes\n",
    "    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    list_converted, abs_errors, rel_errors, total_time, t0, t1, t2, t3, file_size = _lets_convert(test_loader)\n",
    "    for i in range(len(abs_errors)):\n",
    "        if i == 0:\n",
    "            abs_array = abs_errors[i]\n",
    "            rel_array = rel_errors[i]\n",
    "        else:\n",
    "            np.append(abs_array, abs_errors[i])\n",
    "            np.append(rel_array, rel_errors[i])\n",
    "            \n",
    "    abs_list = []\n",
    "    rel_list = []\n",
    "    model_list = []\n",
    "    batch_list = []\n",
    "    summary_list = ['Modelsize:{}, Conversion: {}, Loading: {}, t1: {}, conversion time: {}, onnx runtime: {}, onnx filesize: {}'.format(size0, total_time, t0, t1, t2, t3, file_size)]\n",
    "    for i in range(len(abs_array)):\n",
    "        abs_list.append(abs_array[i][0])\n",
    "        rel = rel_array[i][0]\n",
    "        if rel == np.inf or rel == -np.inf:\n",
    "            rel = 0.0\n",
    "        rel_list.append(rel)\n",
    "        batch_list.append(batch_size)\n",
    "        model_list.append(model_name)\n",
    "        if i >= len(summary_list):\n",
    "            summary_list.append('')\n",
    "    print(len(summary_list), len(rel_list))\n",
    "    data = pd.DataFrame({'model':model_list,'batch_size': batch_list, 'abs_errors':abs_list, 'rel_errors':rel_list, 'summary': summary_list})\n",
    "    data.to_csv('./data/errors/torch2/tf_errors_{}_{}.csv'.format(model_name, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.testing.assert_equal(to_numpy(torch_out), ort_outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
