{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fb9ac814310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "#Import needed packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from onnx_tf.backend import prepare\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.autograd import Variable\n",
    "#from pytorch2keras.converter import pytorch_to_keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "from pathlib import Path\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# used for Alexnet\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 128\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform_train)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform_test)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "     num_workers=num_workers)\n",
    "#valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "#    sampler=valid_sampler, num_workers=num_workers)\n",
    "valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# specify the image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_id = 10\n",
    "model_short_name = 'vgg'\n",
    "framework = 'pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515298923"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Volumes/Cisco/Fall2021/onnx-exchange/Training/{}/{}/'.format(framework, model_short_name)\n",
    "\n",
    "# Model class must be defined somewhere\n",
    "since_0 = time.time()\n",
    "model_name = 'torch_exp_vgg_2021-11-04_{}'.format(training_id)\n",
    "model = torch.load(path+model_name+'.pth', map_location=torch.device('cpu'))\n",
    "#resnet50_model.eval()\n",
    "t_elapsed_0 = time.time() - since_0\n",
    "size0 = os.path.getsize(path+model_name+'.pth')\n",
    "size0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515298923"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size1 = os.path.getsize(path+model_name+'.pth')\n",
    "size1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 1.0.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:TensorFlow version 2.5.0 detected. Last version known to be fully compatible is 2.3.1 .\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "import coremltools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/onnx/'\n",
    "coreml_path = '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/coremltools/'\n",
    "error_path = '/Volumes/Cisco/Fall2021/onnx-exchange/conversion/errors/'\n",
    "error_path_miss = '/Volumes/Cisco/Fall2021/onnx-exchange/miss-classification/errors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "def model_scores(y_test, test_predict):\n",
    "    correct_ = np.sum(y_test == test_predict)\n",
    "    accuracy  = correct_*100./np.sum(y_test == y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onnx(i, x, y, data_writer_error, data_writer_error2, data_writer_run, data_writer_run_miss, batch_size):\n",
    "    # Input to the model\n",
    "    #device_reset = cuda.get_current_device()\n",
    "    #device_reset.reset()\n",
    "    #x.cuda()\n",
    "    \n",
    "    y = to_numpy(y)\n",
    "    print(\"converting for batch: \", i)\n",
    "    traced_model = torch.jit.trace(model, x)\n",
    "    #torch.random.manual_seed(42)\n",
    "    #x = torch.randn(10000, 3, 32, 32, requires_grad=True)\n",
    "    since_ = time.time()\n",
    "    since_1 = time.time()\n",
    "    torch_out = model(x)\n",
    "    t_elapsed_1 = time.time() - since_1\n",
    "    inference_time_original = time.time() - since_1\n",
    "    \n",
    "    y0 = to_numpy(torch.argmax(torch_out,1))\n",
    "    accuracy_original = model_scores(y, y0)\n",
    "    \n",
    "    \n",
    "    # Export the model\n",
    "    if not os.path.exists(onnx_path+framework+\"/{}\".format(model_short_name)):\n",
    "        os.makedirs(onnx_path+framework+\"/{}\".format(model_short_name))\n",
    "    if not os.path.exists(coreml_path+framework+\"/{}\".format(model_short_name)):\n",
    "        os.makedirs(coreml_path+framework+\"/{}\".format(model_short_name))\n",
    "        \n",
    "    since_1 = time.time()\n",
    "    \n",
    "    since_onnx = time.time()\n",
    "    torch.onnx._export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name),   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  #operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK,\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "    \n",
    "    t_elapsed_2 = time.time() - since_1\n",
    "    t_conversion_time_onnx = t_elapsed_2\n",
    "    \n",
    "    since_1 = time.time()\n",
    "    onnx_model = onnx.load(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    load_time_onnx = time.time() - since_1\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    size2 = os.path.getsize(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    size_onnx = size2\n",
    "    #def to_numpy(tensor):\n",
    "    #    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    ort_session = onnxruntime.InferenceSession(onnx_path+framework+\"/{}/{}.onnx\".format(model_short_name, model_name))\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "    since_1 = time.time()\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    inference_time_onnx = time.time() - since_1\n",
    "    t_elapsed_3 = time.time() - since_1\n",
    "    t_elapsed_ = time.time() - since_\n",
    "    t_elapsed_onnx = time.time() - since_onnx\n",
    "    # compare ONNX Runtime and PyTorch results\n",
    "    print(\"\\n*********\\n\\n\")\n",
    "    #time_diff = t_elapsed_0+t_elapsed_1, t_elapsed_2, t_elapsed_3\n",
    "    \n",
    "    abs_err = np.absolute(to_numpy(torch_out)-ort_outs[0])\n",
    "    rel_err = np.absolute(to_numpy(torch_out)-ort_outs[0])/ np.absolute(ort_outs[0])\n",
    "    #print('Batch: ', i, abs_err, rel_err)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####### Mis-classification ONNX ######################################\n",
    "    ort_outs_tensor = torch.from_numpy(ort_outs[0]) \n",
    "    y2 = to_numpy(torch.argmax(ort_outs_tensor,1))\n",
    "    accuracy_onnx = model_scores(y, y2)\n",
    "    miss_perc_val_original_runtime = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(to_numpy(torch_out), ort_outs[0])\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        flag = 0\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                miss_perc_val_original_runtime = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                flag += 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            print('Error onnx0: ', e)\n",
    "    encoded_miss_perc_val_original_onnx = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(y0, y2)\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        flag = 0\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                encoded_miss_perc_val_original_onnx = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                flag += 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            print('Error onnx1: ', e)\n",
    "    \n",
    "    miss_perc_val_test_runtime = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(y, y2)\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        flag = 0\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                miss_perc_val_test_runtime = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                flag += 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            print('Error onnx2: ', e)\n",
    "    ####### End of mis-classification ONNX ######################################\n",
    "    \n",
    "\n",
    "    \n",
    "    ## Converting the coremltool\n",
    "    since_1 = time.time()\n",
    "    # Using image_input in the inputs parameter:\n",
    "    # Convert to Core ML using the Unified Conversion API.\n",
    "    coreml_model = coremltools.convert(traced_model,inputs=[coremltools.TensorType(shape=x.shape)])\n",
    "    t_elapsed_4 = time.time() - since_1\n",
    "    t_conversion_time_coreml = t_elapsed_4\n",
    "    since_1 = time.time()\n",
    "    coreml_model.save(coreml_path+framework+'/{}/{}.mlmodel'.format(model_short_name, model_name))\n",
    "    t_elapsed_5 = time.time() - since_1\n",
    "    t_saving_time_coreml = t_elapsed_5\n",
    "    \n",
    "    \n",
    "    #print(name_1)\n",
    "\n",
    "    size3 = os.path.getsize(coreml_path+framework+'/{}/{}.mlmodel'.format(model_short_name, model_name))\n",
    "    size_coreml = size3\n",
    "    \n",
    "    since_1 = time.time()\n",
    "    coreml_model = coremltools.models.MLModel(coreml_path+framework+\"/{}/{}.mlmodel\".format(model_short_name, model_name), compute_units=coremltools.ComputeUnit.CPU_ONLY)\n",
    "    load_time_coreml = time.time() - since_1\n",
    "    \n",
    "    name_1 = coreml_model.get_spec().description.input[0].name\n",
    "    \n",
    "    since_1 = time.time()\n",
    "    output_dict_test = coreml_model.predict({name_1:to_numpy(x)})\n",
    "    t_elapsed_6 = time.time() - since_1\n",
    "    t_elapsed2_ = time.time() - since_\n",
    "    inference_time_coreml = t_elapsed_6\n",
    "    \n",
    "    \n",
    "    coreml_array_output = output_dict_test[list(output_dict_test.keys())[0]]\n",
    "    output_tensor = torch.from_numpy(coreml_array_output) \n",
    "    y3 = to_numpy(torch.argmax(output_tensor,1))\n",
    "    #correct_coreml = np.sum(to_numpy(y3) == to_numpy(y))\n",
    "    accuracy_coreml = model_scores(y3, y)\n",
    "    \n",
    "    \n",
    "    miss_perc_val_original_runtime2 = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(to_numpy(torch_out), coreml_array_output)\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        flag = 0\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                miss_perc_val_original_runtime2 = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                flag += 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            print('Error coreml0: ', e)\n",
    "    \n",
    "    ####### Part 2\n",
    "    #print('default-shape: ',k_predict.shape, 'onnx-shape: ',ort_outs[0].shape, 'coreml-shape: ',output_dict_test['Identity'].shape)\n",
    "    miss_perc_val_original_coreml = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(y0, y3)\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        flag = 0\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                miss_perc_val_original_coreml = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                flag += 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            print('Error coreml1: ', e)\n",
    "    miss_perc_val_test_runtime2 = 0\n",
    "    try:\n",
    "        np.testing.assert_array_equal(y, y3)\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        flag = 0\n",
    "        for line_ in str(e).split('\\n'):\n",
    "            #print(' ---- : ', line_)\n",
    "            if 'Mismatched elements' in line_:\n",
    "                value = line_.replace('Mismatched elements: ', '').strip()\n",
    "                miss_perc_val_test_runtime2 = value[value.find(\"(\")+1:value.find(\")\")]\n",
    "                #print(value, perc_val)\n",
    "                flag += 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            print('Error coreml2: ', e)\n",
    "    ####### End of mis-classification coreML ######################################\n",
    "    \n",
    "    \n",
    "    ####### Mis-classification coreML ######################################\n",
    "    abs_err2 = np.absolute(to_numpy(torch_out)-coreml_array_output)\n",
    "    rel_err2 = np.absolute(to_numpy(torch_out)-coreml_array_output)/ np.absolute(coreml_array_output)\n",
    "    \n",
    "    for j in range (len(abs_err)):\n",
    "        for k in range(len(abs_err[j])): \n",
    "            data_writer_error.writerow([model_short_name,framework, training_id, model_name, batch_size, i, abs_err[j][k], rel_err[j][k]])\n",
    "    \n",
    "    \n",
    "    for j in range (len(abs_err2)):\n",
    "        for k in range(len(abs_err2[j])): \n",
    "            data_writer_error2.writerow([model_short_name,framework, training_id, model_name, batch_size, i, abs_err2[j][k], rel_err2[j][k]])\n",
    "      \n",
    "    data_writer_run.writerow([model_short_name, framework, training_id, model_name, batch_size, i,'onnx',size0, size2, t_elapsed_1, t_elapsed_3,  t_elapsed_2,'', t_elapsed_, np.mean(abs_err), np.median(abs_err), np.min(abs_err), np.max(abs_err), np.mean(rel_err), np.median(rel_err), np.min(rel_err), np.max(rel_err)])\n",
    "    data_writer_run.writerow([model_short_name, framework, training_id, model_name, batch_size, i,'coremltools',size0, size3, t_elapsed_1, t_elapsed_6, t_elapsed_4, t_elapsed_5, (t_elapsed2_-t_elapsed_onnx), np.mean(abs_err2), np.median(abs_err2), np.min(abs_err2), np.max(abs_err2), np.mean(rel_err2), np.median(rel_err2), np.min(rel_err2), np.max(rel_err2)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    data_writer_run_miss.writerow([model_short_name, framework, training_id, model_name, batch_size, i,'onnx',size0, size_onnx,t_elapsed_0, inference_time_original,t_conversion_time_onnx, '', load_time_onnx, \n",
    "                          inference_time_onnx,  miss_perc_val_original_runtime,'',  encoded_miss_perc_val_original_onnx, miss_perc_val_test_runtime, '', accuracy_original, accuracy_onnx])\n",
    "\n",
    "\n",
    "    data_writer_run_miss.writerow([model_short_name, framework, training_id, model_name, batch_size, i,'coremltools',size0, size_coreml,t_elapsed_0, inference_time_original,t_conversion_time_coreml, t_saving_time_coreml, load_time_coreml, \n",
    "                          inference_time_coreml,  miss_perc_val_original_runtime2,'',  miss_perc_val_original_coreml, miss_perc_val_test_runtime2, '', accuracy_original, accuracy_coreml])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lets_convert(data, data_writer_error, data_writer_error2, data_writer_run, data_writer_run_miss, batch_size): # for cifar10 etc\n",
    "    since = time.time()\n",
    "    for i, (images, labels) in enumerate(data):\n",
    "        to_onnx(i, images, labels, data_writer_error, data_writer_error2, data_writer_run, data_writer_run_miss, batch_size)\n",
    "        if i == 10: \n",
    "            break\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Conversion complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'letnet5-keras'\n",
    "import pandas as pd \n",
    "def run_experiment(model_short_name, model_name):\n",
    "    if not os.path.exists(error_path_miss+framework+\"/{}\".format(model_short_name)):\n",
    "        Path(error_path_miss+framework+\"/{}\".format(model_short_name)).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    if not os.path.exists(error_path+framework+\"/{}\".format(model_short_name)): \n",
    "        os.makedirs(error_path+framework+\"/{}\".format(model_short_name))\n",
    "    data_file_run_miss = open(error_path_miss+framework+\"/{}/runtime_miss-classification_{}.csv\".format(model_short_name,model_name), mode='w', newline='',\n",
    "                                  encoding='utf-8')\n",
    "    data_writer_run_miss = csv.writer(data_file_run_miss, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer_run_miss.writerow(['model','framework', 'training_id', 'model_full', \"batch_size\", 'round','runtime','original_memory_size', 'runtime_memory_size','original_load_time', 'original_infererence_time','runtime_conversion_time', 'runtime_saving_time', 'runtime_load_time', \n",
    "                              'runtime_inference_time',  'miss_classified_original_runtime_percentage','',  'encoded_miss_classified_original_runtime_percentage','encoded_miss_classified_original_test_runtime_percentage', '', 'accuracy_original', 'accuracy_runtime'])\n",
    "\n",
    "\n",
    "\n",
    "    data_file_error = open(error_path + framework+'/{}/onnx_error_metrics_{}.csv'.format(model_short_name, model_name), mode='w', newline='',\n",
    "                                      encoding='utf-8')\n",
    "    data_writer_error = csv.writer(data_file_error, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer_error.writerow(['model','framework', 'training_id', 'model_full', \"batch_size\", 'round','absolute_error', 'relative_error'])\n",
    "\n",
    "\n",
    "    data_file_error2 = open(error_path + framework+'/{}/mlmore_error_metrics_{}.csv'.format(model_short_name, model_name), mode='w', newline='',\n",
    "                                      encoding='utf-8')\n",
    "    data_writer_error2 = csv.writer(data_file_error2, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer_error2.writerow(['model','framework', 'training_id', 'model_full', \"batch_size\", 'round','absolute_error', 'relative_error'])\n",
    "\n",
    "\n",
    "    data_file_run = open(error_path + framework+'/{}/runtime_metrics_{}.csv'.format(model_short_name, model_name), mode='w', newline='',\n",
    "                                      encoding='utf-8')\n",
    "    data_writer_run = csv.writer(data_file_run, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer_run.writerow(['model','framework', 'training_id', 'model_full', \"batch_size\", 'round','converter','original_size', 'converted_size', 'original_infererence_time', 'converted_infererence_time', 'conversion_time', 'saving_converted_time', 'overral_time', 'avg_abs_error', 'median_abs_error', 'min_abs_error', 'max_abs_error','avg_rel_error', 'median_rel_error', 'min_rel_error', 'max_rel_error'])\n",
    "    \n",
    "    #for batch_size in [1, 5,10,20,30,40,50,60,70,80,90,100,128, 150,200, 250,300,350, 400, 450, 500]:\n",
    "    for batch_size in [128]:\n",
    "        print(\"################ Batch size: \", batch_size)\n",
    "        #trainloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size)\n",
    "        valloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "        \n",
    "        _lets_convert(valloader, data_writer_error, data_writer_error2, data_writer_run, data_writer_run_miss, batch_size)\n",
    "    data_file_error.close()\n",
    "    data_file_error2.close()\n",
    "    data_file_run.close()\n",
    "    data_file_run_miss.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ Batch size:  128\n",
      "converting for batch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops:  99%|█████████▉| 102/103 [00:00<00:00, 1541.48 ops/s]\n",
      "Running MIL Common passes:   0%|          | 0/33 [00:00<?, ? passes/s]/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:101: UserWarning: Input, 'x.1', of the source model, has been renamed to 'x_1' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:129: UserWarning: Output, '157', of the source model, has been renamed to 'var_157' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:01<00:00, 21.24 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:01<00:00,  6.41 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 115/115 [00:25<00:00,  4.56 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  1\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops:  99%|█████████▉| 102/103 [00:00<00:00, 1822.11 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:01<00:00, 32.27 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00,  9.33 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 115/115 [00:23<00:00,  4.86 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  2\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops:  99%|█████████▉| 102/103 [00:00<00:00, 2125.32 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 34.34 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00,  9.86 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 115/115 [00:22<00:00,  5.07 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  3\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops:  99%|█████████▉| 102/103 [00:00<00:00, 1184.79 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:01<00:00, 29.54 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00,  9.32 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 115/115 [00:24<00:00,  4.74 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  4\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops:  99%|█████████▉| 102/103 [00:00<00:00, 2172.46 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 36.34 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00,  9.73 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 115/115 [00:25<00:00,  4.51 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  5\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops:  99%|█████████▉| 102/103 [00:00<00:00, 1867.08 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:01<00:00, 31.04 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00,  9.56 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 115/115 [01:03<00:00,  1.80 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  6\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops:  99%|█████████▉| 102/103 [00:00<00:00, 1284.68 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:01<00:00, 24.70 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:01<00:00,  7.15 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 115/115 [00:34<00:00,  3.34 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  7\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops:  99%|█████████▉| 102/103 [00:00<00:00, 400.64 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:02<00:00, 13.92 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:01<00:00,  6.64 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 115/115 [00:35<00:00,  3.21 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  8\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops:  99%|█████████▉| 102/103 [00:00<00:00, 1791.84 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:01<00:00, 32.65 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00,  9.46 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 115/115 [00:21<00:00,  5.34 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  9\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops:  99%|█████████▉| 102/103 [00:00<00:00, 1899.79 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 33.17 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00,  9.41 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 115/115 [00:20<00:00,  5.53 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting for batch:  10\n",
      "\n",
      "*********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Frontend ==> MIL Ops:  99%|█████████▉| 102/103 [00:00<00:00, 2451.98 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 34.62 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00,  9.78 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 115/115 [00:23<00:00,  4.84 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete in 96m 43s\n"
     ]
    }
   ],
   "source": [
    "run_experiment(model_short_name, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
